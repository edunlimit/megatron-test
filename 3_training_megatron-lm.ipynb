{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3_training_megatron-lm\n",
    "\n",
    "- https://github.com/NVIDIA/Megatron-LM 에서 파일을 다운로드 받은 후 3_training_megatron-lm 폴더의 코드를 덮어쓰기하여 학습을 하시면 됩니다.\n",
    "- 샘플 데이터셋은 https://github.com/huggingface/blog/blob/main/megatron-training.md#data-preprocessing 를 참고해서 만들 수 있습니다. \n",
    "- 시작 전 docker 폴더에서 Dockerfile을 이용하여 custom_docker를 만들어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_needed = True\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "\n",
    "DAEMON_PATH=$PWD/docker\"\n",
    "MEMORY_SIZE=10G\n",
    "\n",
    "FLAG=$(cat $DAEMON_PATH/daemon.json | jq 'has(\"data-root\")')\n",
    "#echo $PWD/\"3_training_megatron-lm/docker\"\n",
    "\n",
    "if [ \"$FLAG\" == true ]; then\n",
    "    echo \"Already revised\"\n",
    "else\n",
    "    echo \"Add data-root and default-shm-size=$MEMORY_SIZE\"\n",
    "    sudo cp $DAEMON_PATH/daemon.json $DAEMON_PATH/daemon.json.bak\n",
    "    sudo cat $DAEMON_PATH/daemon.json.bak | jq '. += {\"data-root\":\"/home/ec2-user/SageMaker/.container/docker\",\"default-shm-size\":\"'$MEMORY_SIZE'\"}' | sudo tee $DAEMON_PATH/daemon.json > /dev/null\n",
    "    sudo launchctl restart docker\n",
    "    echo \"Docker Restart\"\n",
    "fi\n",
    "\n",
    "sudo curl -L \"https://github.com/docker/compose/releases/download/v2.7.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n",
    "sudo chmod +x /usr/local/bin/docker-compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing deps and restarting kernel\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 2.19.1 requires dill<0.3.9,>=0.3.0, but you have dill 0.3.9 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install --upgrade pip --quiet\n",
    "    !{sys.executable} -m pip install -U sagemaker --quiet\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and registering the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Login Succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0 building with \"desktop-linux\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 1.54kB done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [auth] sharing credentials for 763104351884.dkr.ecr.us-east-1.amazonaws.com\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [linux/arm64 internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker\n",
      "#3 ...\n",
      "\n",
      "#4 [linux/amd64 internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker\n",
      "#4 DONE 1.0s\n",
      "\n",
      "#5 [internal] load .dockerignore\n",
      "#5 transferring context: 2B done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#3 [linux/arm64 internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker\n",
      "#3 DONE 1.4s\n",
      "\n",
      "#6 [linux/amd64 1/6] FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker@sha256:981b1ce0d1099ffba1f8842b7632c69413922e35d190cced42e1ce45c2fd6ddf\n",
      "#6 resolve 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker@sha256:981b1ce0d1099ffba1f8842b7632c69413922e35d190cced42e1ce45c2fd6ddf 0.0s done\n",
      "#6 DONE 0.0s\n",
      "\n",
      "#7 [linux/arm64 1/6] FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker@sha256:981b1ce0d1099ffba1f8842b7632c69413922e35d190cced42e1ce45c2fd6ddf\n",
      "#7 resolve 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker@sha256:981b1ce0d1099ffba1f8842b7632c69413922e35d190cced42e1ce45c2fd6ddf 0.0s done\n",
      "#7 DONE 0.0s\n",
      "\n",
      "#8 [linux/arm64 2/6] RUN apt-get update && apt-get install -y     build-essential     cmake     git     curl     vim     wget     ca-certificates     libjpeg-dev     libpng-dev     librdmacm1     libibverbs1     ibverbs-providers     && rm -rf /var/lib/apt/lists/*\n",
      "#8 CACHED\n",
      "\n",
      "#9 [linux/amd64 2/6] RUN apt-get update && apt-get install -y     build-essential     cmake     git     curl     vim     wget     ca-certificates     libjpeg-dev     libpng-dev     librdmacm1     libibverbs1     ibverbs-providers     && rm -rf /var/lib/apt/lists/*\n",
      "#9 CACHED\n",
      "\n",
      "#10 [linux/arm64 3/6] RUN pip install --no-cache-dir     regex     einops     flask-restful     nltk     pytest     transformers     pytest_asyncio     pytest-cov     pytest_mock     pytest-random-order     sentencepiece     tiktoken     wrapt     zarr     wandb     datasets\n",
      "#10 CACHED\n",
      "\n",
      "#11 [linux/amd64 3/6] RUN pip install --no-cache-dir     regex     einops     flask-restful     nltk     pytest     transformers     pytest_asyncio     pytest-cov     pytest_mock     pytest-random-order     sentencepiece     tiktoken     wrapt     zarr     wandb     datasets\n",
      "#11 CACHED\n",
      "\n",
      "#12 [linux/amd64 4/6] RUN pip uninstall -y apex || true\n",
      "#12 0.444 Found existing installation: apex 0.1\n",
      "#12 0.457 Uninstalling apex-0.1:\n",
      "#12 1.267   Successfully uninstalled apex-0.1\n",
      "#12 1.273 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "#12 DONE 1.3s\n",
      "\n",
      "#13 [linux/arm64 4/6] RUN pip uninstall -y apex || true\n",
      "#13 0.449 Found existing installation: apex 0.1\n",
      "#13 0.462 Uninstalling apex-0.1:\n",
      "#13 1.272   Successfully uninstalled apex-0.1\n",
      "#13 1.278 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "#13 DONE 1.3s\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 0.258 Cloning into '/tmp/apex'...\n",
      "#14 7.148 Using pip 25.0.1 from /opt/conda/lib/python3.11/site-packages/pip (python 3.11)\n",
      "#14 7.221 Processing /tmp/apex\n",
      "#14 7.224   Preparing metadata (pyproject.toml): started\n",
      "#14 7.225   Running command Preparing metadata (pyproject.toml)\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 0.260 Cloning into '/tmp/apex'...\n",
      "#15 9.408 Using pip 25.0.1 from /opt/conda/lib/python3.11/site-packages/pip (python 3.11)\n",
      "#15 9.525 Processing /tmp/apex\n",
      "#15 9.528   Preparing metadata (pyproject.toml): started\n",
      "#15 9.528   Running command Preparing metadata (pyproject.toml)\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 11.17   No CUDA runtime is found, using CUDA_HOME='/opt/conda'\n",
      "#14 11.17 \n",
      "#14 11.17   Warning: Torch did not find available GPUs on this system.\n",
      "#14 11.17    If your intention is to cross-compile, this is not an error.\n",
      "#14 11.17   By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n",
      "#14 11.17   Volta (compute capability 7.0), Turing (compute capability 7.5),\n",
      "#14 11.17   and, if the CUDA version is >= 11.0, Ampere (compute capability 8.0).\n",
      "#14 11.17   If you wish to cross-compile for a single specific architecture,\n",
      "#14 11.17   export TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\n",
      "#14 11.17 \n",
      "#14 11.17 \n",
      "#14 11.17 \n",
      "#14 11.17   torch.__version__  = 2.3.0\n",
      "#14 11.17 \n",
      "#14 11.17 \n",
      "#14 11.24   running dist_info\n",
      "#14 11.25   creating /tmp/pip-modern-metadata-4owcj4qb/apex.egg-info\n",
      "#14 11.25   writing /tmp/pip-modern-metadata-4owcj4qb/apex.egg-info/PKG-INFO\n",
      "#14 11.25   writing dependency_links to /tmp/pip-modern-metadata-4owcj4qb/apex.egg-info/dependency_links.txt\n",
      "#14 11.25   writing requirements to /tmp/pip-modern-metadata-4owcj4qb/apex.egg-info/requires.txt\n",
      "#14 11.25   writing top-level names to /tmp/pip-modern-metadata-4owcj4qb/apex.egg-info/top_level.txt\n",
      "#14 11.25   writing manifest file '/tmp/pip-modern-metadata-4owcj4qb/apex.egg-info/SOURCES.txt'\n",
      "#14 11.27   reading manifest file '/tmp/pip-modern-metadata-4owcj4qb/apex.egg-info/SOURCES.txt'\n",
      "#14 11.27   adding license file 'LICENSE'\n",
      "#14 11.27   writing manifest file '/tmp/pip-modern-metadata-4owcj4qb/apex.egg-info/SOURCES.txt'\n",
      "#14 11.27   creating '/tmp/pip-modern-metadata-4owcj4qb/apex-0.1.dist-info'\n",
      "#14 11.88   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "#14 11.88 Requirement already satisfied: packaging>20.6 in /opt/conda/lib/python3.11/site-packages (from apex==0.1) (23.2)\n",
      "#14 11.89 Building wheels for collected packages: apex\n",
      "#14 11.89   Building wheel for apex (pyproject.toml): started\n",
      "#14 11.89   Running command Building wheel for apex (pyproject.toml)\n",
      "#14 14.19   No CUDA runtime is found, using CUDA_HOME='/opt/conda'\n",
      "#14 14.19 \n",
      "#14 14.19   Warning: Torch did not find available GPUs on this system.\n",
      "#14 14.19    If your intention is to cross-compile, this is not an error.\n",
      "#14 14.19   By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n",
      "#14 14.19   Volta (compute capability 7.0), Turing (compute capability 7.5),\n",
      "#14 14.19   and, if the CUDA version is >= 11.0, Ampere (compute capability 8.0).\n",
      "#14 14.19   If you wish to cross-compile for a single specific architecture,\n",
      "#14 14.19   export TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\n",
      "#14 14.19 \n",
      "#14 14.19 \n",
      "#14 14.19 \n",
      "#14 14.19   torch.__version__  = 2.3.0\n",
      "#14 14.19 \n",
      "#14 14.19 \n",
      "#14 14.25 \n",
      "#14 14.25   Compiling cuda extensions with\n",
      "#14 14.25   nvcc: NVIDIA (R) Cuda compiler driver\n",
      "#14 14.25   Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "#14 14.25   Built on Mon_Apr__3_17:16:06_PDT_2023\n",
      "#14 14.25   Cuda compilation tools, release 12.1, V12.1.105\n",
      "#14 14.25   Build cuda_12.1.r12.1/compiler.32688072_0\n",
      "#14 14.25   from /opt/conda/bin\n",
      "#14 14.25 \n",
      "#14 14.28   running bdist_wheel\n",
      "#14 14.51   running build\n",
      "#14 14.51   running build_py\n",
      "#14 14.52   creating build/lib.linux-x86_64-cpython-311/apex\n",
      "#14 14.52   copying apex/_autocast_utils.py -> build/lib.linux-x86_64-cpython-311/apex\n",
      "#14 14.52   copying apex/__init__.py -> build/lib.linux-x86_64-cpython-311/apex\n",
      "#14 14.52   creating build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.52   copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.52   copying apex/amp/scaler.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.52   copying apex/amp/__version__.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.52   copying apex/amp/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.52   copying apex/amp/utils.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.52   copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.52   copying apex/amp/opt.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.53   copying apex/amp/_initialize.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.53   copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.53   copying apex/amp/wrap.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.53   copying apex/amp/frontend.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.53   copying apex/amp/amp.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.53   copying apex/amp/handle.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.53   copying apex/amp/compat.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#14 14.53   creating build/lib.linux-x86_64-cpython-311/apex/RNN\n",
      "#14 14.53   copying apex/RNN/models.py -> build/lib.linux-x86_64-cpython-311/apex/RNN\n",
      "#14 14.53   copying apex/RNN/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/RNN\n",
      "#14 14.53   copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-cpython-311/apex/RNN\n",
      "#14 14.53   copying apex/RNN/cells.py -> build/lib.linux-x86_64-cpython-311/apex/RNN\n",
      "#14 14.53   creating build/lib.linux-x86_64-cpython-311/apex/mlp\n",
      "#14 14.53   copying apex/mlp/mlp.py -> build/lib.linux-x86_64-cpython-311/apex/mlp\n",
      "#14 14.53   copying apex/mlp/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/mlp\n",
      "#14 14.53   creating build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply\n",
      "#14 14.53   copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply\n",
      "#14 14.53   copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply\n",
      "#14 14.53   creating build/lib.linux-x86_64-cpython-311/apex/contrib\n",
      "#14 14.53   copying apex/contrib/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib\n",
      "#14 14.53   creating build/lib.linux-x86_64-cpython-311/apex/fused_dense\n",
      "#14 14.53   copying apex/fused_dense/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/fused_dense\n",
      "#14 14.54   copying apex/fused_dense/fused_dense.py -> build/lib.linux-x86_64-cpython-311/apex/fused_dense\n",
      "#14 14.54   creating build/lib.linux-x86_64-cpython-311/apex/normalization\n",
      "#14 14.54   copying apex/normalization/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/normalization\n",
      "#14 14.54   copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/normalization\n",
      "#14 14.54   creating build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#14 14.54   copying apex/transformer/enums.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#14 14.54   copying apex/transformer/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#14 14.54   copying apex/transformer/utils.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#14 14.54   copying apex/transformer/log_util.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#14 14.54   copying apex/transformer/parallel_state.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#14 14.54   copying apex/transformer/_ucc_util.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#14 14.54   copying apex/transformer/microbatches.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#14 14.54   creating build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#14 14.54   copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#14 14.54   copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#14 14.54   copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#14 14.54   copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#14 14.54   copying apex/optimizers/fused_mixed_precision_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#14 14.54   copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#14 14.54   copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#14 14.54   creating build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#14 14.54   copying apex/parallel/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#14 14.54   copying apex/parallel/distributed.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#14 14.54   copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#14 14.55   copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#14 14.55   copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#14 14.55   copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#14 14.55   copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#14 14.55   copying apex/parallel/LARC.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#14 14.55   creating build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n",
      "#14 14.55   copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n",
      "#14 14.55   copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n",
      "#14 14.55   copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n",
      "#14 14.55   copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n",
      "#14 14.55   creating build/lib.linux-x86_64-cpython-311/apex/amp/lists\n",
      "#14 14.55   copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/amp/lists\n",
      "#14 14.55   copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-cpython-311/apex/amp/lists\n",
      "#14 14.55   copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-cpython-311/apex/amp/lists\n",
      "#14 14.55   copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-cpython-311/apex/amp/lists\n",
      "#14 14.55   creating build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu\n",
      "#14 14.55   copying apex/contrib/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu\n",
      "#14 14.55   copying apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu\n",
      "#14 14.55   creating build/lib.linux-x86_64-cpython-311/apex/contrib/nccl_allocator\n",
      "#14 14.55   copying apex/contrib/nccl_allocator/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/nccl_allocator\n",
      "#14 14.55   copying apex/contrib/nccl_allocator/nccl_allocator.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/nccl_allocator\n",
      "#14 14.55   creating build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad\n",
      "#14 14.55   copying apex/contrib/clip_grad/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad\n",
      "#14 14.55   copying apex/contrib/clip_grad/clip_grad.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad\n",
      "#14 14.55   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test\n",
      "#14 14.55   copying apex/contrib/test/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test\n",
      "#14 14.55   creating build/lib.linux-x86_64-cpython-311/apex/contrib/transducer\n",
      "#14 14.55   copying apex/contrib/transducer/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/transducer\n",
      "#14 14.55   copying apex/contrib/transducer/transducer.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/transducer\n",
      "#14 14.55   copying apex/contrib/transducer/_transducer_ref.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/transducer\n",
      "#14 14.55   creating build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n",
      "#14 14.55   copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n",
      "#14 14.55   copying apex/contrib/sparsity/permutation_lib.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n",
      "#14 14.55   copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n",
      "#14 14.55   copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n",
      "#14 14.55   creating build/lib.linux-x86_64-cpython-311/apex/contrib/gpu_direct_storage\n",
      "#14 14.55   copying apex/contrib/gpu_direct_storage/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/gpu_direct_storage\n",
      "#14 14.55   creating build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm\n",
      "#14 14.55   copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm\n",
      "#14 14.55   copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm\n",
      "#14 14.55   creating build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n",
      "#14 14.55   copying apex/contrib/bottleneck/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n",
      "#14 14.56   copying apex/contrib/bottleneck/test.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n",
      "#14 14.56   copying apex/contrib/bottleneck/bottleneck.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n",
      "#14 14.56   copying apex/contrib/bottleneck/halo_exchangers.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n",
      "#14 14.56   creating build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm\n",
      "#14 14.56   copying apex/contrib/group_norm/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm\n",
      "#14 14.56   copying apex/contrib/group_norm/group_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm\n",
      "#14 14.56   creating build/lib.linux-x86_64-cpython-311/apex/contrib/fmha\n",
      "#14 14.56   copying apex/contrib/fmha/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/fmha\n",
      "#14 14.56   copying apex/contrib/fmha/fmha.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/fmha\n",
      "#14 14.56   creating build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn\n",
      "#14 14.56   copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn\n",
      "#14 14.56   copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn\n",
      "#14 14.56   creating build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory\n",
      "#14 14.56   copying apex/contrib/peer_memory/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory\n",
      "#14 14.56   copying apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory\n",
      "#14 14.56   copying apex/contrib/peer_memory/peer_memory.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory\n",
      "#14 14.56   creating build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d\n",
      "#14 14.56   copying apex/contrib/index_mul_2d/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d\n",
      "#14 14.56   copying apex/contrib/index_mul_2d/index_mul_2d.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d\n",
      "#14 14.56   creating build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy\n",
      "#14 14.56   copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy\n",
      "#14 14.56   copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy\n",
      "#14 14.56   creating build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn\n",
      "#14 14.56   copying apex/contrib/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn\n",
      "#14 14.56   copying apex/contrib/cudnn_gbn/batch_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn\n",
      "#14 14.56   creating build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#14 14.56   copying apex/contrib/openfold_triton/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#14 14.56   copying apex/contrib/openfold_triton/_mha_kernel.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#14 14.56   copying apex/contrib/openfold_triton/_layer_norm_config_hopper.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#14 14.56   copying apex/contrib/openfold_triton/fused_adam_swa.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#14 14.56   copying apex/contrib/openfold_triton/layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#14 14.56   copying apex/contrib/openfold_triton/_layer_norm_forward_kernels.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#14 14.56   copying apex/contrib/openfold_triton/mha.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#14 14.56   copying apex/contrib/openfold_triton/_layer_norm_backward_kernels.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#14 14.56   copying apex/contrib/openfold_triton/_layer_norm_config_ampere.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#14 14.56   creating build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#14 14.56   copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#14 14.56   copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#14 14.56   copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#14 14.57   copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#14 14.57   copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#14 14.57   copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#14 14.57   copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#14 14.57   creating build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss\n",
      "#14 14.57   copying apex/contrib/focal_loss/focal_loss.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss\n",
      "#14 14.57   copying apex/contrib/focal_loss/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss\n",
      "#14 14.57   creating build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#14 14.57   copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#14 14.57   copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#14 14.57   copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#14 14.57   copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#14 14.57   copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#14 14.57   copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#14 14.57   copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#14 14.57   copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#14 14.57   copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#14 14.57   copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#14 14.57   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu\n",
      "#14 14.57   copying apex/contrib/test/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu\n",
      "#14 14.57   copying apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu\n",
      "#14 14.57   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad\n",
      "#14 14.57   copying apex/contrib/test/clip_grad/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad\n",
      "#14 14.57   copying apex/contrib/test/clip_grad/test_clip_grad.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad\n",
      "#14 14.57   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer\n",
      "#14 14.57   copying apex/contrib/test/transducer/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer\n",
      "#14 14.57   copying apex/contrib/test/transducer/test_transducer_joint.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer\n",
      "#14 14.57   copying apex/contrib/test/transducer/test_transducer_loss.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer\n",
      "#14 14.57   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm\n",
      "#14 14.57   copying apex/contrib/test/layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm\n",
      "#14 14.57   copying apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm\n",
      "#14 14.57   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck\n",
      "#14 14.57   copying apex/contrib/test/bottleneck/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck\n",
      "#14 14.57   copying apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck\n",
      "#14 14.57   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm\n",
      "#14 14.57   copying apex/contrib/test/group_norm/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm\n",
      "#14 14.57   copying apex/contrib/test/group_norm/test_group_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm\n",
      "#14 14.57   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha\n",
      "#14 14.57   copying apex/contrib/test/fmha/test_fmha.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha\n",
      "#14 14.57   copying apex/contrib/test/fmha/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha\n",
      "#14 14.57   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory\n",
      "#14 14.57   copying apex/contrib/test/peer_memory/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory\n",
      "#14 14.57   copying apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory\n",
      "#14 14.58   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d\n",
      "#14 14.58   copying apex/contrib/test/index_mul_2d/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d\n",
      "#14 14.58   copying apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d\n",
      "#14 14.58   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy\n",
      "#14 14.58   copying apex/contrib/test/xentropy/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy\n",
      "#14 14.58   copying apex/contrib/test/xentropy/test_label_smoothing.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy\n",
      "#14 14.58   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn\n",
      "#14 14.58   copying apex/contrib/test/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn\n",
      "#14 14.58   copying apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn\n",
      "#14 14.58   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers\n",
      "#14 14.58   copying apex/contrib/test/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers\n",
      "#14 14.58   copying apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers\n",
      "#14 14.58   copying apex/contrib/test/optimizers/test_dist_adam.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers\n",
      "#14 14.58   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss\n",
      "#14 14.58   copying apex/contrib/test/focal_loss/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss\n",
      "#14 14.58   copying apex/contrib/test/focal_loss/test_focal_loss.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss\n",
      "#14 14.58   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#14 14.58   copying apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#14 14.58   copying apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#14 14.58   copying apex/contrib/test/multihead_attn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#14 14.58   copying apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#14 14.58   copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#14 14.58   copying apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#14 14.58   copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#14 14.58   creating build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n",
      "#14 14.58   copying apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n",
      "#14 14.58   copying apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n",
      "#14 14.58   copying apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n",
      "#14 14.58   copying apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n",
      "#14 14.58   copying apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n",
      "#14 14.58   creating build/lib.linux-x86_64-cpython-311/apex/transformer/layers\n",
      "#14 14.58   copying apex/transformer/layers/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/layers\n",
      "#14 14.58   copying apex/transformer/layers/layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/layers\n",
      "#14 14.58   creating build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#14 14.58   copying apex/transformer/tensor_parallel/random.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#14 14.58   copying apex/transformer/tensor_parallel/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#14 14.58   copying apex/transformer/tensor_parallel/data.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#14 14.58   copying apex/transformer/tensor_parallel/utils.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#14 14.58   copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#14 14.58   copying apex/transformer/tensor_parallel/mappings.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#14 14.58   copying apex/transformer/tensor_parallel/memory.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#14 14.58   copying apex/transformer/tensor_parallel/layers.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#14 14.58   creating build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n",
      "#14 14.58   copying apex/transformer/pipeline_parallel/p2p_communication.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n",
      "#14 14.58   copying apex/transformer/pipeline_parallel/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n",
      "#14 14.58   copying apex/transformer/pipeline_parallel/utils.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n",
      "#14 14.58   copying apex/transformer/pipeline_parallel/_timers.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n",
      "#14 14.58   creating build/lib.linux-x86_64-cpython-311/apex/transformer/amp\n",
      "#14 14.58   copying apex/transformer/amp/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/amp\n",
      "#14 14.58   copying apex/transformer/amp/grad_scaler.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/amp\n",
      "#14 14.58   creating build/lib.linux-x86_64-cpython-311/apex/transformer/_data\n",
      "#14 14.59   copying apex/transformer/_data/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/_data\n",
      "#14 14.59   copying apex/transformer/_data/_batchsampler.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/_data\n",
      "#14 14.59   creating build/lib.linux-x86_64-cpython-311/apex/transformer/functional\n",
      "#14 14.59   copying apex/transformer/functional/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/functional\n",
      "#14 14.59   copying apex/transformer/functional/fused_rope.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/functional\n",
      "#14 14.59   copying apex/transformer/functional/fused_softmax.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/functional\n",
      "#14 14.59   creating build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#14 14.59   copying apex/transformer/testing/standalone_transformer_lm.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#14 14.59   copying apex/transformer/testing/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#14 14.59   copying apex/transformer/testing/standalone_gpt.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#14 14.59   copying apex/transformer/testing/global_vars.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#14 14.59   copying apex/transformer/testing/commons.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#14 14.59   copying apex/transformer/testing/arguments.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#14 14.59   copying apex/transformer/testing/standalone_bert.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#14 14.59   copying apex/transformer/testing/distributed_test_base.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#14 14.59   creating build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n",
      "#14 14.59   copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n",
      "#14 14.59   copying apex/transformer/pipeline_parallel/schedules/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n",
      "#14 14.59   copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n",
      "#14 14.59   copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n",
      "#14 14.59   copying apex/transformer/pipeline_parallel/schedules/common.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n",
      "#14 14.59   warning: build_py: byte-compiling is disabled, skipping.\n",
      "#14 14.59 \n",
      "#14 14.59   running build_ext\n",
      "#14 14.73   /opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:428: UserWarning: There are no g++ version bounds defined for CUDA version 12.1\n",
      "#14 14.73     warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
      "#14 14.95   building 'apex_C' extension\n",
      "#14 14.95   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/apex_C/csrc\n",
      "#14 15.29   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/apex_C/build.ninja...\n",
      "#14 15.29   Compiling objects...\n",
      "#14 15.29   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 12.99   No CUDA runtime is found, using CUDA_HOME='/opt/conda'\n",
      "#15 12.99 \n",
      "#15 12.99   Warning: Torch did not find available GPUs on this system.\n",
      "#15 12.99    If your intention is to cross-compile, this is not an error.\n",
      "#15 12.99   By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n",
      "#15 12.99   Volta (compute capability 7.0), Turing (compute capability 7.5),\n",
      "#15 12.99   and, if the CUDA version is >= 11.0, Ampere (compute capability 8.0).\n",
      "#15 12.99   If you wish to cross-compile for a single specific architecture,\n",
      "#15 12.99   export TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\n",
      "#15 12.99 \n",
      "#15 12.99 \n",
      "#15 12.99 \n",
      "#15 12.99   torch.__version__  = 2.3.0\n",
      "#15 12.99 \n",
      "#15 12.99 \n",
      "#15 13.04   running dist_info\n",
      "#15 13.05   creating /tmp/pip-modern-metadata-zihkr9su/apex.egg-info\n",
      "#15 13.05   writing /tmp/pip-modern-metadata-zihkr9su/apex.egg-info/PKG-INFO\n",
      "#15 13.05   writing dependency_links to /tmp/pip-modern-metadata-zihkr9su/apex.egg-info/dependency_links.txt\n",
      "#15 13.05   writing requirements to /tmp/pip-modern-metadata-zihkr9su/apex.egg-info/requires.txt\n",
      "#15 13.05   writing top-level names to /tmp/pip-modern-metadata-zihkr9su/apex.egg-info/top_level.txt\n",
      "#15 13.05   writing manifest file '/tmp/pip-modern-metadata-zihkr9su/apex.egg-info/SOURCES.txt'\n",
      "#15 13.07   reading manifest file '/tmp/pip-modern-metadata-zihkr9su/apex.egg-info/SOURCES.txt'\n",
      "#15 13.07   adding license file 'LICENSE'\n",
      "#15 13.08   writing manifest file '/tmp/pip-modern-metadata-zihkr9su/apex.egg-info/SOURCES.txt'\n",
      "#15 13.08   creating '/tmp/pip-modern-metadata-zihkr9su/apex-0.1.dist-info'\n",
      "#15 13.36   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "#15 13.36 Requirement already satisfied: packaging>20.6 in /opt/conda/lib/python3.11/site-packages (from apex==0.1) (23.2)\n",
      "#15 13.36 Building wheels for collected packages: apex\n",
      "#15 13.36   Building wheel for apex (pyproject.toml): started\n",
      "#15 13.36   Running command Building wheel for apex (pyproject.toml)\n",
      "#15 16.66   No CUDA runtime is found, using CUDA_HOME='/opt/conda'\n",
      "#15 16.66 \n",
      "#15 16.66   Warning: Torch did not find available GPUs on this system.\n",
      "#15 16.66    If your intention is to cross-compile, this is not an error.\n",
      "#15 16.66   By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n",
      "#15 16.66   Volta (compute capability 7.0), Turing (compute capability 7.5),\n",
      "#15 16.67   and, if the CUDA version is >= 11.0, Ampere (compute capability 8.0).\n",
      "#15 16.67   If you wish to cross-compile for a single specific architecture,\n",
      "#15 16.67   export TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\n",
      "#15 16.67 \n",
      "#15 16.67 \n",
      "#15 16.67 \n",
      "#15 16.67   torch.__version__  = 2.3.0\n",
      "#15 16.67 \n",
      "#15 16.67 \n",
      "#15 16.71 \n",
      "#15 16.71   Compiling cuda extensions with\n",
      "#15 16.71   nvcc: NVIDIA (R) Cuda compiler driver\n",
      "#15 16.71   Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "#15 16.71   Built on Mon_Apr__3_17:16:06_PDT_2023\n",
      "#15 16.71   Cuda compilation tools, release 12.1, V12.1.105\n",
      "#15 16.71   Build cuda_12.1.r12.1/compiler.32688072_0\n",
      "#15 16.71   from /opt/conda/bin\n",
      "#15 16.71 \n",
      "#15 16.74   running bdist_wheel\n",
      "#15 16.91   running build\n",
      "#15 16.91   running build_py\n",
      "#15 16.92   creating build/lib.linux-x86_64-cpython-311/apex\n",
      "#15 16.92   copying apex/_autocast_utils.py -> build/lib.linux-x86_64-cpython-311/apex\n",
      "#15 16.92   copying apex/__init__.py -> build/lib.linux-x86_64-cpython-311/apex\n",
      "#15 16.92   creating build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/scaler.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/__version__.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/utils.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/opt.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/_initialize.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/wrap.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/frontend.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/amp.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/handle.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   copying apex/amp/compat.py -> build/lib.linux-x86_64-cpython-311/apex/amp\n",
      "#15 16.92   creating build/lib.linux-x86_64-cpython-311/apex/RNN\n",
      "#15 16.92   copying apex/RNN/models.py -> build/lib.linux-x86_64-cpython-311/apex/RNN\n",
      "#15 16.92   copying apex/RNN/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/RNN\n",
      "#15 16.92   copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-cpython-311/apex/RNN\n",
      "#15 16.92   copying apex/RNN/cells.py -> build/lib.linux-x86_64-cpython-311/apex/RNN\n",
      "#15 16.92   creating build/lib.linux-x86_64-cpython-311/apex/mlp\n",
      "#15 16.92   copying apex/mlp/mlp.py -> build/lib.linux-x86_64-cpython-311/apex/mlp\n",
      "#15 16.92   copying apex/mlp/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/mlp\n",
      "#15 16.92   creating build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply\n",
      "#15 16.92   copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply\n",
      "#15 16.92   copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply\n",
      "#15 16.92   creating build/lib.linux-x86_64-cpython-311/apex/contrib\n",
      "#15 16.92   copying apex/contrib/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib\n",
      "#15 16.92   creating build/lib.linux-x86_64-cpython-311/apex/fused_dense\n",
      "#15 16.92   copying apex/fused_dense/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/fused_dense\n",
      "#15 16.92   copying apex/fused_dense/fused_dense.py -> build/lib.linux-x86_64-cpython-311/apex/fused_dense\n",
      "#15 16.92   creating build/lib.linux-x86_64-cpython-311/apex/normalization\n",
      "#15 16.92   copying apex/normalization/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/normalization\n",
      "#15 16.92   copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/normalization\n",
      "#15 16.92   creating build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#15 16.92   copying apex/transformer/enums.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#15 16.92   copying apex/transformer/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#15 16.92   copying apex/transformer/utils.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#15 16.92   copying apex/transformer/log_util.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#15 16.92   copying apex/transformer/parallel_state.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#15 16.92   copying apex/transformer/_ucc_util.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#15 16.92   copying apex/transformer/microbatches.py -> build/lib.linux-x86_64-cpython-311/apex/transformer\n",
      "#15 16.92   creating build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#15 16.92   copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#15 16.92   copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#15 16.92   copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#15 16.92   copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#15 16.92   copying apex/optimizers/fused_mixed_precision_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#15 16.92   copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#15 16.92   copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/optimizers\n",
      "#15 16.92   creating build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#15 16.92   copying apex/parallel/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#15 16.92   copying apex/parallel/distributed.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#15 16.92   copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#15 16.92   copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#15 16.92   copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#15 16.92   copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#15 16.93   copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#15 16.93   copying apex/parallel/LARC.py -> build/lib.linux-x86_64-cpython-311/apex/parallel\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n",
      "#15 16.93   copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n",
      "#15 16.93   copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n",
      "#15 16.93   copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n",
      "#15 16.93   copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-cpython-311/apex/fp16_utils\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/amp/lists\n",
      "#15 16.93   copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/amp/lists\n",
      "#15 16.93   copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-cpython-311/apex/amp/lists\n",
      "#15 16.93   copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-cpython-311/apex/amp/lists\n",
      "#15 16.93   copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-cpython-311/apex/amp/lists\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu\n",
      "#15 16.93   copying apex/contrib/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu\n",
      "#15 16.93   copying apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/nccl_allocator\n",
      "#15 16.93   copying apex/contrib/nccl_allocator/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/nccl_allocator\n",
      "#15 16.93   copying apex/contrib/nccl_allocator/nccl_allocator.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/nccl_allocator\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad\n",
      "#15 16.93   copying apex/contrib/clip_grad/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad\n",
      "#15 16.93   copying apex/contrib/clip_grad/clip_grad.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test\n",
      "#15 16.93   copying apex/contrib/test/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/transducer\n",
      "#15 16.93   copying apex/contrib/transducer/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/transducer\n",
      "#15 16.93   copying apex/contrib/transducer/transducer.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/transducer\n",
      "#15 16.93   copying apex/contrib/transducer/_transducer_ref.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/transducer\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n",
      "#15 16.93   copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n",
      "#15 16.93   copying apex/contrib/sparsity/permutation_lib.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n",
      "#15 16.93   copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n",
      "#15 16.93   copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/gpu_direct_storage\n",
      "#15 16.93   copying apex/contrib/gpu_direct_storage/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/gpu_direct_storage\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm\n",
      "#15 16.93   copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm\n",
      "#15 16.93   copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n",
      "#15 16.93   copying apex/contrib/bottleneck/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n",
      "#15 16.93   copying apex/contrib/bottleneck/test.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n",
      "#15 16.93   copying apex/contrib/bottleneck/bottleneck.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n",
      "#15 16.93   copying apex/contrib/bottleneck/halo_exchangers.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm\n",
      "#15 16.93   copying apex/contrib/group_norm/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm\n",
      "#15 16.93   copying apex/contrib/group_norm/group_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/fmha\n",
      "#15 16.93   copying apex/contrib/fmha/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/fmha\n",
      "#15 16.93   copying apex/contrib/fmha/fmha.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/fmha\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn\n",
      "#15 16.93   copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn\n",
      "#15 16.93   copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory\n",
      "#15 16.93   copying apex/contrib/peer_memory/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory\n",
      "#15 16.93   copying apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory\n",
      "#15 16.93   copying apex/contrib/peer_memory/peer_memory.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d\n",
      "#15 16.93   copying apex/contrib/index_mul_2d/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d\n",
      "#15 16.93   copying apex/contrib/index_mul_2d/index_mul_2d.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d\n",
      "#15 16.93   creating build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy\n",
      "#15 16.93   copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy\n",
      "#15 16.93   copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy\n",
      "#15 16.94   creating build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn\n",
      "#15 16.94   copying apex/contrib/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn\n",
      "#15 16.94   copying apex/contrib/cudnn_gbn/batch_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn\n",
      "#15 16.94   creating build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#15 16.94   copying apex/contrib/openfold_triton/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#15 16.94   copying apex/contrib/openfold_triton/_mha_kernel.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#15 16.94   copying apex/contrib/openfold_triton/_layer_norm_config_hopper.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#15 16.94   copying apex/contrib/openfold_triton/fused_adam_swa.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#15 16.94   copying apex/contrib/openfold_triton/layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#15 16.94   copying apex/contrib/openfold_triton/_layer_norm_forward_kernels.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#15 16.94   copying apex/contrib/openfold_triton/mha.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#15 16.94   copying apex/contrib/openfold_triton/_layer_norm_backward_kernels.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#15 16.94   copying apex/contrib/openfold_triton/_layer_norm_config_ampere.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton\n",
      "#15 16.94   creating build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#15 16.94   copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#15 16.94   copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#15 16.95   copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#15 16.95   copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#15 16.95   copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#15 16.95   copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#15 16.95   copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss\n",
      "#15 16.95   copying apex/contrib/focal_loss/focal_loss.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss\n",
      "#15 16.95   copying apex/contrib/focal_loss/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#15 16.95   copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#15 16.95   copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#15 16.95   copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#15 16.95   copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#15 16.95   copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#15 16.95   copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#15 16.95   copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#15 16.95   copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#15 16.95   copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#15 16.95   copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu\n",
      "#15 16.95   copying apex/contrib/test/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu\n",
      "#15 16.95   copying apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad\n",
      "#15 16.95   copying apex/contrib/test/clip_grad/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad\n",
      "#15 16.95   copying apex/contrib/test/clip_grad/test_clip_grad.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer\n",
      "#15 16.95   copying apex/contrib/test/transducer/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer\n",
      "#15 16.95   copying apex/contrib/test/transducer/test_transducer_joint.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer\n",
      "#15 16.95   copying apex/contrib/test/transducer/test_transducer_loss.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm\n",
      "#15 16.95   copying apex/contrib/test/layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm\n",
      "#15 16.95   copying apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck\n",
      "#15 16.95   copying apex/contrib/test/bottleneck/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck\n",
      "#15 16.95   copying apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm\n",
      "#15 16.95   copying apex/contrib/test/group_norm/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm\n",
      "#15 16.95   copying apex/contrib/test/group_norm/test_group_norm.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha\n",
      "#15 16.95   copying apex/contrib/test/fmha/test_fmha.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha\n",
      "#15 16.95   copying apex/contrib/test/fmha/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory\n",
      "#15 16.95   copying apex/contrib/test/peer_memory/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory\n",
      "#15 16.95   copying apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d\n",
      "#15 16.95   copying apex/contrib/test/index_mul_2d/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d\n",
      "#15 16.95   copying apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy\n",
      "#15 16.95   copying apex/contrib/test/xentropy/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy\n",
      "#15 16.95   copying apex/contrib/test/xentropy/test_label_smoothing.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn\n",
      "#15 16.95   copying apex/contrib/test/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn\n",
      "#15 16.95   copying apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers\n",
      "#15 16.95   copying apex/contrib/test/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers\n",
      "#15 16.95   copying apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers\n",
      "#15 16.95   copying apex/contrib/test/optimizers/test_dist_adam.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers\n",
      "#15 16.95   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss\n",
      "#15 16.95   copying apex/contrib/test/focal_loss/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss\n",
      "#15 16.95   copying apex/contrib/test/focal_loss/test_focal_loss.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss\n",
      "#15 16.96   creating build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#15 16.96   copying apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#15 16.96   copying apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#15 16.96   copying apex/contrib/test/multihead_attn/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#15 16.96   copying apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#15 16.96   copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#15 16.96   copying apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#15 16.96   copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn\n",
      "#15 16.96   creating build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n",
      "#15 16.96   copying apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n",
      "#15 16.96   copying apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n",
      "#15 16.96   copying apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n",
      "#15 16.96   copying apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n",
      "#15 16.96   copying apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels\n",
      "#15 16.96   creating build/lib.linux-x86_64-cpython-311/apex/transformer/layers\n",
      "#15 16.96   copying apex/transformer/layers/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/layers\n",
      "#15 16.96   copying apex/transformer/layers/layer_norm.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/layers\n",
      "#15 16.96   creating build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#15 16.96   copying apex/transformer/tensor_parallel/random.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#15 16.96   copying apex/transformer/tensor_parallel/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#15 16.96   copying apex/transformer/tensor_parallel/data.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#15 16.96   copying apex/transformer/tensor_parallel/utils.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#15 16.96   copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#15 16.96   copying apex/transformer/tensor_parallel/mappings.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#15 16.96   copying apex/transformer/tensor_parallel/memory.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#15 16.96   copying apex/transformer/tensor_parallel/layers.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel\n",
      "#15 16.96   creating build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n",
      "#15 16.96   copying apex/transformer/pipeline_parallel/p2p_communication.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n",
      "#15 16.96   copying apex/transformer/pipeline_parallel/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n",
      "#15 16.96   copying apex/transformer/pipeline_parallel/utils.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n",
      "#15 16.96   copying apex/transformer/pipeline_parallel/_timers.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel\n",
      "#15 16.96   creating build/lib.linux-x86_64-cpython-311/apex/transformer/amp\n",
      "#15 16.96   copying apex/transformer/amp/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/amp\n",
      "#15 16.96   copying apex/transformer/amp/grad_scaler.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/amp\n",
      "#15 16.96   creating build/lib.linux-x86_64-cpython-311/apex/transformer/_data\n",
      "#15 16.96   copying apex/transformer/_data/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/_data\n",
      "#15 16.96   copying apex/transformer/_data/_batchsampler.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/_data\n",
      "#15 16.96   creating build/lib.linux-x86_64-cpython-311/apex/transformer/functional\n",
      "#15 16.96   copying apex/transformer/functional/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/functional\n",
      "#15 16.96   copying apex/transformer/functional/fused_rope.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/functional\n",
      "#15 16.96   copying apex/transformer/functional/fused_softmax.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/functional\n",
      "#15 16.96   creating build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#15 16.96   copying apex/transformer/testing/standalone_transformer_lm.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#15 16.96   copying apex/transformer/testing/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#15 16.96   copying apex/transformer/testing/standalone_gpt.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#15 16.96   copying apex/transformer/testing/global_vars.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#15 16.96   copying apex/transformer/testing/commons.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#15 16.96   copying apex/transformer/testing/arguments.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#15 16.96   copying apex/transformer/testing/standalone_bert.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#15 16.96   copying apex/transformer/testing/distributed_test_base.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/testing\n",
      "#15 16.96   creating build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n",
      "#15 16.96   copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n",
      "#15 16.96   copying apex/transformer/pipeline_parallel/schedules/__init__.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n",
      "#15 16.96   copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n",
      "#15 16.96   copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n",
      "#15 16.96   copying apex/transformer/pipeline_parallel/schedules/common.py -> build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules\n",
      "#15 16.97   warning: build_py: byte-compiling is disabled, skipping.\n",
      "#15 16.97 \n",
      "#15 16.97   running build_ext\n",
      "#15 17.03   /opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py:428: UserWarning: There are no g++ version bounds defined for CUDA version 12.1\n",
      "#15 17.03     warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
      "#15 17.14   building 'apex_C' extension\n",
      "#15 17.14   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/apex_C/csrc\n",
      "#15 17.43   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/apex_C/build.ninja...\n",
      "#15 17.43   Compiling objects...\n",
      "#15 17.43   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 41.74   [1/1] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/apex_C/csrc/flatten_unflatten.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/flatten_unflatten.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/apex_C/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 41.75   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/apex_C/csrc/flatten_unflatten.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-311/apex_C.cpython-311-x86_64-linux-gnu.so\n",
      "#14 42.09   building 'amp_C' extension\n",
      "#14 42.09   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc\n",
      "#14 42.28   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/build.ninja...\n",
      "#14 42.28   Compiling objects...\n",
      "#14 42.28   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 44.24   [1/1] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/apex_C/csrc/flatten_unflatten.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/flatten_unflatten.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/apex_C/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 44.28   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/apex_C/csrc/flatten_unflatten.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-311/apex_C.cpython-311-x86_64-linux-gnu.so\n",
      "#15 44.77   building 'amp_C' extension\n",
      "#15 44.79   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc\n",
      "#15 45.06   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/build.ninja...\n",
      "#15 45.06   Compiling objects...\n",
      "#15 45.06   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#15 235.0   [1/15] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/amp_C_frontend.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/amp_C_frontend.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 239.3   [1/15] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/amp_C_frontend.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/amp_C_frontend.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 1085.3   [2/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_adam.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_adam.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1131.1   [3/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_stage_2.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_lamb_stage_2.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1201.6   [4/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_axpby_kernel.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_axpby_kernel.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1216.9   [5/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_scale_kernel.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_l2norm_scale_kernel.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1218.5   [6/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_kernel.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_l2norm_kernel.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1221.0   [2/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_stage_2.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_lamb_stage_2.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 1222.0   [7/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_sgd_kernel.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_sgd_kernel.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1223.9   [8/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_scale_kernel.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_scale_kernel.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1228.1   [9/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_lamb.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1229.0   [10/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_kernel_mp.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_l2norm_kernel_mp.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_kernel_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1232.4   [11/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_mp.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_lamb_mp.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1233.7   [3/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_kernel_mp.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_l2norm_kernel_mp.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_kernel_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1236.5   [4/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_sgd_kernel.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_sgd_kernel.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1237.5   [5/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_lamb.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1237.6   [6/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_adagrad.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_adagrad.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 1238.9   [12/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_adagrad.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_adagrad.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1243.5   [13/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_novograd.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_novograd.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1243.8   [14/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_stage_1.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_lamb_stage_1.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1239.2   [7/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_novograd.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_novograd.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1247.7   [8/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_scale_kernel.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_l2norm_scale_kernel.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1248.1   [9/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_mp.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_lamb_mp.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1249.2   [10/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_axpby_kernel.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_axpby_kernel.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1249.6   [11/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_stage_1.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_lamb_stage_1.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1249.8   [12/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_adam.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_adam.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1250.1   [13/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_scale_kernel.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_scale_kernel.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1250.2   [14/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_kernel.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/multi_tensor_l2norm_kernel.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 1253.5   [15/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/update_scale_hysteresis.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/update_scale_hysteresis.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/update_scale_hysteresis.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1253.5   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/amp_C_frontend.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_adagrad.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_adam.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_axpby_kernel.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_kernel.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_kernel_mp.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_scale_kernel.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_mp.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_stage_1.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_stage_2.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_novograd.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_scale_kernel.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_sgd_kernel.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/update_scale_hysteresis.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/amp_C.cpython-311-x86_64-linux-gnu.so\n",
      "#14 1253.9   building 'syncbn' extension\n",
      "#14 1253.9   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc\n",
      "#14 1254.1   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/build.ninja...\n",
      "#14 1254.1   Compiling objects...\n",
      "#14 1254.1   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1258.8   [15/15] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/update_scale_hysteresis.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/update_scale_hysteresis.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/update_scale_hysteresis.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1258.8   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/amp_C_frontend.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_adagrad.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_adam.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_axpby_kernel.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_kernel.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_kernel_mp.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_l2norm_scale_kernel.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_mp.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_stage_1.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_lamb_stage_2.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_novograd.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_scale_kernel.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/multi_tensor_sgd_kernel.o /tmp/apex/build/temp.linux-x86_64-cpython-311/amp_C/csrc/update_scale_hysteresis.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/amp_C.cpython-311-x86_64-linux-gnu.so\n",
      "#15 1259.2   building 'syncbn' extension\n",
      "#15 1259.2   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc\n",
      "#15 1259.4   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/build.ninja...\n",
      "#15 1259.4   Compiling objects...\n",
      "#15 1259.4   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 1271.0   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc/syncbn.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/syncbn.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1276.0   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc/syncbn.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/syncbn.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 1318.9   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc/welford.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/welford.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1319.0   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc/syncbn.o /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc/welford.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/syncbn.cpython-311-x86_64-linux-gnu.so\n",
      "#14 1319.3   building 'fused_layer_norm_cuda' extension\n",
      "#14 1319.3   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc\n",
      "#14 1319.5   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/build.ninja...\n",
      "#14 1319.5   Compiling objects...\n",
      "#14 1319.5   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1324.1   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc/welford.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/welford.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1324.1   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc/syncbn.o /tmp/apex/build/temp.linux-x86_64-cpython-311/syncbn/csrc/welford.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/syncbn.cpython-311-x86_64-linux-gnu.so\n",
      "#15 1324.4   building 'fused_layer_norm_cuda' extension\n",
      "#15 1324.4   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc\n",
      "#15 1324.6   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/build.ninja...\n",
      "#15 1324.6   Compiling objects...\n",
      "#15 1324.6   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 1335.7   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc/layer_norm_cuda.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/layer_norm_cuda.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1340.8   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc/layer_norm_cuda.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/layer_norm_cuda.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 1407.8   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc/layer_norm_cuda_kernel.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/layer_norm_cuda_kernel.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1407.9   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc/layer_norm_cuda.o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc/layer_norm_cuda_kernel.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/fused_layer_norm_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#14 1408.3   building 'mlp_cuda' extension\n",
      "#14 1408.3   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc\n",
      "#14 1408.5   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/build.ninja...\n",
      "#14 1408.5   Compiling objects...\n",
      "#14 1408.5   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1412.2   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc/layer_norm_cuda_kernel.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/layer_norm_cuda_kernel.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1412.2   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc/layer_norm_cuda.o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_layer_norm_cuda/csrc/layer_norm_cuda_kernel.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/fused_layer_norm_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#15 1412.6   building 'mlp_cuda' extension\n",
      "#15 1412.6   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc\n",
      "#15 1412.7   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/build.ninja...\n",
      "#15 1412.7   Compiling objects...\n",
      "#15 1412.7   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 1424.0   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc/mlp.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/mlp.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:57:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#14 1424.0      57 |   for (int i = 0; i < num_layers; i++) {\n",
      "#14 1424.0         |                   ~~^~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1424.0      64 |   auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
      "#14 1424.0         |                                                                             ^\n",
      "#14 1424.0   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1424.0                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1424.0     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1424.0         |                              ^~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:65:86: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1424.0      65 |   auto reserved_space = at::empty({static_cast<long>(reserved_size)}, inputs[0].type());\n",
      "#14 1424.0         |                                                                                      ^\n",
      "#14 1424.0   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1424.0                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1424.0     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1424.0         |                              ^~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:67:59: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1424.0      67 |   auto lt_workspace = at::empty({1 << 22}, inputs[0].type());\n",
      "#14 1424.0         |                                                           ^\n",
      "#14 1424.0   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1424.0                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1424.0     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1424.0         |                              ^~~~\n",
      "#14 1424.0   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1424.0                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp: In lambda function:\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#14 1424.0      72 |     for (int i = 0; i < num_layers; i++) {\n",
      "#14 1424.0         |                     ~~^~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0      69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_forward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1424.0      78 |     auto result = mlp_fp<scalar_t>(\n",
      "#14 1424.0         |          ^~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0      69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_forward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp: In lambda function:\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#14 1424.0      72 |     for (int i = 0; i < num_layers; i++) {\n",
      "#14 1424.0         |                     ~~^~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0      69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_forward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1424.0      78 |     auto result = mlp_fp<scalar_t>(\n",
      "#14 1424.0         |          ^~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0      69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_forward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp: In lambda function:\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#14 1424.0      72 |     for (int i = 0; i < num_layers; i++) {\n",
      "#14 1424.0         |                     ~~^~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0      69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_forward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1424.0      78 |     auto result = mlp_fp<scalar_t>(\n",
      "#14 1424.0         |          ^~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0      69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_forward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:115:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#14 1424.0     115 |   for (int i = 0; i < num_layers; i++) {\n",
      "#14 1424.0         |                   ~~^~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:120:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
      "#14 1424.0     120 |   for (int i = 0; i < inputs.size(); i++) {\n",
      "#14 1424.0         |                   ~~^~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:121:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1424.0     121 |     outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
      "#14 1424.0         |                                                                   ^\n",
      "#14 1424.0   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1424.0                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1424.0     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1424.0         |                              ^~~~\n",
      "#14 1424.0   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1424.0                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp: In lambda function:\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#14 1424.0     126 |     for (int i = 0; i < num_layers; i++) {\n",
      "#14 1424.0         |                     ~~^~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
      "#14 1424.0     130 |     for (int i = 0; i < inputs.size(); i++) {\n",
      "#14 1424.0         |                     ~~^~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1424.0     138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
      "#14 1424.0         |                                                                                                   ^\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1424.0                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1424.0     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1424.0         |                              ^~~~\n",
      "#14 1424.0   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1424.0                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1424.0     140 |     auto result = mlp_bp<scalar_t>(\n",
      "#14 1424.0         |          ^~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp: In lambda function:\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#14 1424.0     126 |     for (int i = 0; i < num_layers; i++) {\n",
      "#14 1424.0         |                     ~~^~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
      "#14 1424.0     130 |     for (int i = 0; i < inputs.size(); i++) {\n",
      "#14 1424.0         |                     ~~^~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1424.0     138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
      "#14 1424.0         |                                                                                                   ^\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1424.0                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1424.0     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1424.0         |                              ^~~~\n",
      "#14 1424.0   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#14 1424.0                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1424.0                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1424.0     140 |     auto result = mlp_bp<scalar_t>(\n",
      "#14 1424.0         |          ^~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp: In lambda function:\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#14 1424.0     126 |     for (int i = 0; i < num_layers; i++) {\n",
      "#14 1424.0         |                     ~~^~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
      "#14 1424.0     130 |     for (int i = 0; i < inputs.size(); i++) {\n",
      "#14 1424.0         |                     ~~^~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.0     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.0         |       ^~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.0      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.0     242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.0         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.0     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#14 1424.0         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.0   /tmp/apex/csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1424.0     138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
      "#14 1424.1         |                                                                                                   ^\n",
      "#14 1424.1   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.1     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.1         |       ^~~~~~~~~~~\n",
      "#14 1424.1   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.1      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.1         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.1   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.1     242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
      "#14 1424.1         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.1   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.1     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.1         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.1   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.1     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#14 1424.1         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.1   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1424.1                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#14 1424.1   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1424.1     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1424.1         |                              ^~~~\n",
      "#14 1424.1   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#14 1424.1                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1424.1                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#14 1424.1   /tmp/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1424.1     140 |     auto result = mlp_bp<scalar_t>(\n",
      "#14 1424.1         |          ^~~~~~\n",
      "#14 1424.1   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1424.1     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1424.1         |       ^~~~~~~~~~~\n",
      "#14 1424.1   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1424.1      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1424.1         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.1   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1424.1     242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
      "#14 1424.1         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1424.1   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.1     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#14 1424.1         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1424.1   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#14 1424.1     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#14 1424.1         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1429.8   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc/mlp.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/mlp.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:57:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#15 1429.8      57 |   for (int i = 0; i < num_layers; i++) {\n",
      "#15 1429.8         |                   ~~^~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1429.8      64 |   auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
      "#15 1429.8         |                                                                             ^\n",
      "#15 1429.8   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1429.8                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1429.8     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1429.8         |                              ^~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:65:86: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1429.8      65 |   auto reserved_space = at::empty({static_cast<long>(reserved_size)}, inputs[0].type());\n",
      "#15 1429.8         |                                                                                      ^\n",
      "#15 1429.8   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1429.8                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1429.8     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1429.8         |                              ^~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:67:59: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1429.8      67 |   auto lt_workspace = at::empty({1 << 22}, inputs[0].type());\n",
      "#15 1429.8         |                                                           ^\n",
      "#15 1429.8   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1429.8                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1429.8     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1429.8         |                              ^~~~\n",
      "#15 1429.8   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1429.8                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp: In lambda function:\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#15 1429.8      72 |     for (int i = 0; i < num_layers; i++) {\n",
      "#15 1429.8         |                     ~~^~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.8     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.8         |       ^~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.8      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.8     240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.8     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.8         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.8      69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_forward\", [&] {\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1429.8      78 |     auto result = mlp_fp<scalar_t>(\n",
      "#15 1429.8         |          ^~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.8     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.8         |       ^~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.8      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.8     240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.8     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.8         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.8      69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_forward\", [&] {\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp: In lambda function:\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#15 1429.8      72 |     for (int i = 0; i < num_layers; i++) {\n",
      "#15 1429.8         |                     ~~^~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.8     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.8         |       ^~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.8      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.8     241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.8     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.8         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.8      69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_forward\", [&] {\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1429.8      78 |     auto result = mlp_fp<scalar_t>(\n",
      "#15 1429.8         |          ^~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.8     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.8         |       ^~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.8      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.8     241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.8     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.8         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.8      69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_forward\", [&] {\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp: In lambda function:\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#15 1429.8      72 |     for (int i = 0; i < num_layers; i++) {\n",
      "#15 1429.8         |                     ~~^~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.8     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.8         |       ^~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.8      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.8     242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.8     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.8         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.8      69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_forward\", [&] {\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1429.8      78 |     auto result = mlp_fp<scalar_t>(\n",
      "#15 1429.8         |          ^~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.8     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.8         |       ^~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.8      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.8     242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.8     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.8         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.8      69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_forward\", [&] {\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:115:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#15 1429.8     115 |   for (int i = 0; i < num_layers; i++) {\n",
      "#15 1429.8         |                   ~~^~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:120:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
      "#15 1429.8     120 |   for (int i = 0; i < inputs.size(); i++) {\n",
      "#15 1429.8         |                   ~~^~~~~~~~~~~~~~~\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:121:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1429.8     121 |     outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
      "#15 1429.8         |                                                                   ^\n",
      "#15 1429.8   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1429.8                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1429.8     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1429.8         |                              ^~~~\n",
      "#15 1429.8   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#15 1429.8                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1429.8                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp: In lambda function:\n",
      "#15 1429.8   /tmp/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#15 1429.8     126 |     for (int i = 0; i < num_layers; i++) {\n",
      "#15 1429.8         |                     ~~^~~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.8     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.8         |       ^~~~~~~~~~~\n",
      "#15 1429.8   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.8      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.8         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.9     240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.9         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
      "#15 1429.9     130 |     for (int i = 0; i < inputs.size(); i++) {\n",
      "#15 1429.9         |                     ~~^~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.9     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.9         |       ^~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.9      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.9     240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.9         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1429.9     138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
      "#15 1429.9         |                                                                                                   ^\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.9     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.9         |       ^~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.9      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.9     240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.9         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1429.9                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1429.9     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1429.9         |                              ^~~~\n",
      "#15 1429.9   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1429.9                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1429.9     140 |     auto result = mlp_bp<scalar_t>(\n",
      "#15 1429.9         |          ^~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.9     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.9         |       ^~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.9      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:240:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.9     240 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.9         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp: In lambda function:\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#15 1429.9     126 |     for (int i = 0; i < num_layers; i++) {\n",
      "#15 1429.9         |                     ~~^~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.9     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.9         |       ^~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.9      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.9     241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.9         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
      "#15 1429.9     130 |     for (int i = 0; i < inputs.size(); i++) {\n",
      "#15 1429.9         |                     ~~^~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.9     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.9         |       ^~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.9      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.9     241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.9         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1429.9     138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
      "#15 1429.9         |                                                                                                   ^\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.9     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.9         |       ^~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.9      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.9     241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.9         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1429.9                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1429.9     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1429.9         |                              ^~~~\n",
      "#15 1429.9   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1429.9                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1429.9     140 |     auto result = mlp_bp<scalar_t>(\n",
      "#15 1429.9         |          ^~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.9     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.9         |       ^~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.9      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:241:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.9     241 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.9         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp: In lambda function:\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘long unsigned int’ [-Wsign-compare]\n",
      "#15 1429.9     126 |     for (int i = 0; i < num_layers; i++) {\n",
      "#15 1429.9         |                     ~~^~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.9     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.9         |       ^~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.9      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.9     242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.9         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
      "#15 1429.9     130 |     for (int i = 0; i < inputs.size(); i++) {\n",
      "#15 1429.9         |                     ~~^~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.9     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.9         |       ^~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.9      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.9     242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.9         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:138:99: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1429.9     138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
      "#15 1429.9         |                                                                                                   ^\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.9     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.9         |       ^~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.9      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.9     242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.9         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1429.9                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1429.9     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1429.9         |                              ^~~~\n",
      "#15 1429.9   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#15 1429.9                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1429.9                    from /tmp/apex/csrc/mlp.cpp:1:\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1429.9     140 |     auto result = mlp_bp<scalar_t>(\n",
      "#15 1429.9         |          ^~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1429.9     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1429.9         |       ^~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1429.9      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:242:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1429.9     242 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:246:19: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     246 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
      "#15 1429.9         |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1429.9   /tmp/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
      "#15 1429.9     124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].scalar_type(), \"mlp_backward\", [&] {\n",
      "#15 1429.9         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 1584.1   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc/mlp_cuda.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/mlp_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1584.1   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc/mlp.o /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc/mlp_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/mlp_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#14 1584.5   building 'fused_dense_cuda' extension\n",
      "#14 1584.5   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc\n",
      "#14 1584.7   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/build.ninja...\n",
      "#14 1584.7   Compiling objects...\n",
      "#14 1584.7   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1585.6   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc/mlp_cuda.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/mlp_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1585.6   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc/mlp.o /tmp/apex/build/temp.linux-x86_64-cpython-311/mlp_cuda/csrc/mlp_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/mlp_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#15 1586.0   building 'fused_dense_cuda' extension\n",
      "#15 1586.0   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc\n",
      "#15 1586.1   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/build.ninja...\n",
      "#15 1586.1   Compiling objects...\n",
      "#15 1586.1   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 1600.4   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc/fused_dense.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/fused_dense.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc/fused_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In function ‘at::Tensor linear_bias_forward(at::Tensor, at::Tensor, at::Tensor)’:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:30:63: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.4      30 |   auto out = at::empty({batch_size, out_features}, input.type());\n",
      "#14 1600.4         |                                                               ^\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.4         |                              ^~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:33:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.4      33 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
      "#14 1600.4         |                                                       ^\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.4         |                              ^~~~\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
      "#14 1600.4      37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
      "#14 1600.4         |               ^~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#14 1600.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.4      38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
      "#14 1600.4         |          ^~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#14 1600.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
      "#14 1600.4      37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
      "#14 1600.4         |               ^~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#14 1600.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.4      38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
      "#14 1600.4         |          ^~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#14 1600.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
      "#14 1600.4      37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
      "#14 1600.4         |               ^~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.4      38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
      "#14 1600.4         |          ^~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
      "#14 1600.4      37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
      "#14 1600.4         |               ^~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.4      38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
      "#14 1600.4         |          ^~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_bias_backward(at::Tensor, at::Tensor, at::Tensor)’:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:64:69: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.4      64 |   auto d_weight = at::empty({out_features, in_features}, input.type());\n",
      "#14 1600.4         |                                                                     ^\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.4         |                              ^~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:68:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.4      68 |   auto d_bias = at::empty({out_features}, input.type());\n",
      "#14 1600.4         |                                                      ^\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.4         |                              ^~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:70:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.4      70 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n",
      "#14 1600.4         |                                                                  ^\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.4         |                              ^~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:73:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.4      73 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
      "#14 1600.4         |                                                       ^\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.4         |                              ^~~~\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
      "#14 1600.4      77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
      "#14 1600.4         |               ^~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#14 1600.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.4      78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
      "#14 1600.4         |          ^~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#14 1600.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
      "#14 1600.4      77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
      "#14 1600.4         |               ^~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#14 1600.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.4      78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
      "#14 1600.4         |          ^~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#14 1600.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
      "#14 1600.4      77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
      "#14 1600.4         |               ^~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.4      78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
      "#14 1600.4         |          ^~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
      "#14 1600.4      77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
      "#14 1600.4         |               ^~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.4      78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
      "#14 1600.4         |          ^~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:106:70: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.4     106 |   auto output1 = at::empty({batch_size, hidden_features}, input.type());\n",
      "#14 1600.4         |                                                                      ^\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.4         |                              ^~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:107:70: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.4     107 |   auto gelu_in = at::empty({batch_size, hidden_features}, input.type());\n",
      "#14 1600.4         |                                                                      ^\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.4         |                              ^~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:108:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.4     108 |   auto output2 = at::empty({batch_size, out_features}, input.type());\n",
      "#14 1600.4         |                                                                   ^\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.4         |                              ^~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:111:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.4     111 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
      "#14 1600.4         |                                                       ^\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.4         |                              ^~~~\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.4     118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
      "#14 1600.4         |          ^~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#14 1600.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.4     118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
      "#14 1600.4         |          ^~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#14 1600.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.4     118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
      "#14 1600.4         |          ^~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.4     118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
      "#14 1600.4         |          ^~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.4     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.4     269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.4     113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n",
      "#14 1600.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n",
      "#14 1600.4   /tmp/apex/csrc/fused_dense.cpp:149:73: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.4     149 |   auto d_weight1 = at::empty({hidden_features, in_features}, input.type());\n",
      "#14 1600.4         |                                                                         ^\n",
      "#14 1600.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.5         |                              ^~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:150:74: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.5     150 |   auto d_weight2 = at::empty({out_features, hidden_features}, input.type());\n",
      "#14 1600.5         |                                                                          ^\n",
      "#14 1600.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.5         |                              ^~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:151:58: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.5     151 |   auto d_bias1 = at::empty({hidden_features}, input.type());\n",
      "#14 1600.5         |                                                          ^\n",
      "#14 1600.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.5         |                              ^~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:152:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.5     152 |   auto d_bias2 = at::empty({out_features}, input.type());\n",
      "#14 1600.5         |                                                       ^\n",
      "#14 1600.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.5         |                              ^~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:153:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.5     153 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n",
      "#14 1600.5         |                                                                  ^\n",
      "#14 1600.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.5         |                              ^~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:154:72: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.5     154 |   auto d_output1 = at::empty({batch_size, hidden_features}, input.type());\n",
      "#14 1600.5         |                                                                        ^\n",
      "#14 1600.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.5         |                              ^~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:157:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#14 1600.5     157 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
      "#14 1600.5         |                                                       ^\n",
      "#14 1600.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#14 1600.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#14 1600.5         |                              ^~~~\n",
      "#14 1600.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#14 1600.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#14 1600.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.5     163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
      "#14 1600.5         |          ^~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.5     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.5         |       ^~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.5     233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#14 1600.5     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.5     159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.5     163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
      "#14 1600.5         |          ^~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.5     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.5         |       ^~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.5     234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#14 1600.5     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.5     159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.5     163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
      "#14 1600.5         |          ^~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.5     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.5         |       ^~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.5     268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.5     159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#14 1600.5     163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
      "#14 1600.5         |          ^~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#14 1600.5     221 |       __VA_ARGS__                                                           \\\n",
      "#14 1600.5         |       ^~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#14 1600.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#14 1600.5     269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#14 1600.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#14 1600.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 1600.5   /tmp/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#14 1600.5     159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#14 1600.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1602.4   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc/fused_dense.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/fused_dense.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc/fused_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp: In function ‘at::Tensor linear_bias_forward(at::Tensor, at::Tensor, at::Tensor)’:\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:30:63: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.4      30 |   auto out = at::empty({batch_size, out_features}, input.type());\n",
      "#15 1602.4         |                                                               ^\n",
      "#15 1602.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.4         |                              ^~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:33:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.4      33 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
      "#15 1602.4         |                                                       ^\n",
      "#15 1602.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.4         |                              ^~~~\n",
      "#15 1602.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
      "#15 1602.4      37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
      "#15 1602.4         |               ^~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.4     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.4     233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#15 1602.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.4      38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
      "#15 1602.4         |          ^~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.4     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.4     233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#15 1602.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
      "#15 1602.4      37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
      "#15 1602.4         |               ^~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.4     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.4     234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#15 1602.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.4      38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
      "#15 1602.4         |          ^~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.4     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.4     234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#15 1602.4     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
      "#15 1602.4      37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
      "#15 1602.4         |               ^~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.4     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.4     268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.4      38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
      "#15 1602.4         |          ^~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.4     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.4     268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
      "#15 1602.4      37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
      "#15 1602.4         |               ^~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.4     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.4     269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.4      38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
      "#15 1602.4         |          ^~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.4     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.4      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.4     269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.4     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.4         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.4      35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
      "#15 1602.4         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_bias_backward(at::Tensor, at::Tensor, at::Tensor)’:\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:64:69: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.4      64 |   auto d_weight = at::empty({out_features, in_features}, input.type());\n",
      "#15 1602.4         |                                                                     ^\n",
      "#15 1602.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.4                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.4   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.4     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.4         |                              ^~~~\n",
      "#15 1602.4   /tmp/apex/csrc/fused_dense.cpp:68:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.4      68 |   auto d_bias = at::empty({out_features}, input.type());\n",
      "#15 1602.4         |                                                      ^\n",
      "#15 1602.4   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.4                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:70:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5      70 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n",
      "#15 1602.5         |                                                                  ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:73:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5      73 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
      "#15 1602.5         |                                                       ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
      "#15 1602.5      77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
      "#15 1602.5         |               ^~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#15 1602.5     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.5      78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
      "#15 1602.5         |          ^~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#15 1602.5     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
      "#15 1602.5      77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
      "#15 1602.5         |               ^~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#15 1602.5     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.5      78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
      "#15 1602.5         |          ^~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#15 1602.5     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
      "#15 1602.5      77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
      "#15 1602.5         |               ^~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.5      78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
      "#15 1602.5         |          ^~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
      "#15 1602.5      77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
      "#15 1602.5         |               ^~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.5      78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
      "#15 1602.5         |          ^~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5      75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:106:70: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5     106 |   auto output1 = at::empty({batch_size, hidden_features}, input.type());\n",
      "#15 1602.5         |                                                                      ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:107:70: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5     107 |   auto gelu_in = at::empty({batch_size, hidden_features}, input.type());\n",
      "#15 1602.5         |                                                                      ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:108:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5     108 |   auto output2 = at::empty({batch_size, out_features}, input.type());\n",
      "#15 1602.5         |                                                                   ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:111:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5     111 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
      "#15 1602.5         |                                                       ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.5     118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
      "#15 1602.5         |          ^~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#15 1602.5     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.5     118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
      "#15 1602.5         |          ^~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#15 1602.5     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.5     118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
      "#15 1602.5         |          ^~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.5     118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
      "#15 1602.5         |          ^~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:149:73: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5     149 |   auto d_weight1 = at::empty({hidden_features, in_features}, input.type());\n",
      "#15 1602.5         |                                                                         ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:150:74: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5     150 |   auto d_weight2 = at::empty({out_features, hidden_features}, input.type());\n",
      "#15 1602.5         |                                                                          ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:151:58: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5     151 |   auto d_bias1 = at::empty({hidden_features}, input.type());\n",
      "#15 1602.5         |                                                          ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:152:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5     152 |   auto d_bias2 = at::empty({out_features}, input.type());\n",
      "#15 1602.5         |                                                       ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:153:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5     153 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n",
      "#15 1602.5         |                                                                  ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:154:72: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5     154 |   auto d_output1 = at::empty({batch_size, hidden_features}, input.type());\n",
      "#15 1602.5         |                                                                        ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:157:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
      "#15 1602.5     157 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
      "#15 1602.5         |                                                       ^\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Tensor.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/core/TensorBody.h:225:30: note: declared here\n",
      "#15 1602.5     225 |   DeprecatedTypeProperties & type() const {\n",
      "#15 1602.5         |                              ^~~~\n",
      "#15 1602.5   In file included from /opt/conda/lib/python3.11/site-packages/torch/include/ATen/ATen.h:11,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
      "#15 1602.5                    from /opt/conda/lib/python3.11/site-packages/torch/include/torch/extension.h:5,\n",
      "#15 1602.5                    from /tmp/apex/csrc/fused_dense.cpp:1:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.5     163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
      "#15 1602.5         |          ^~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:233:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     233 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#15 1602.5     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.5     163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
      "#15 1602.5         |          ^~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:234:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     234 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:267:3: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES’\n",
      "#15 1602.5     267 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.5     163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
      "#15 1602.5         |          ^~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:268:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     268 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp: In lambda function:\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:163:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
      "#15 1602.5     163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
      "#15 1602.5         |          ^~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:221:7: note: in definition of macro ‘AT_DISPATCH_SWITCH’\n",
      "#15 1602.5     221 |       __VA_ARGS__                                                           \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:74:3: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
      "#15 1602.5      74 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:269:3: note: in expansion of macro ‘AT_DISPATCH_CASE’\n",
      "#15 1602.5     269 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /opt/conda/lib/python3.11/site-packages/torch/include/ATen/Dispatch.h:276:7: note: in expansion of macro ‘AT_DISPATCH_CASE_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     276 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
      "#15 1602.5         |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 1602.5   /tmp/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND2’\n",
      "#15 1602.5     159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
      "#15 1602.5         |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 1755.8   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc/fused_dense_cuda.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/fused_dense_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc/fused_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 1755.8   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc/fused_dense.o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc/fused_dense_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/fused_dense_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#14 1756.2   building 'scaled_upper_triang_masked_softmax_cuda' extension\n",
      "#14 1756.2   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron\n",
      "#14 1756.4   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/build.ninja...\n",
      "#14 1756.4   Compiling objects...\n",
      "#14 1756.4   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1756.0   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc/fused_dense_cuda.o.d -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/fused_dense_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc/fused_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 1756.0   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc/fused_dense.o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_dense_cuda/csrc/fused_dense_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/fused_dense_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#15 1756.4   building 'scaled_upper_triang_masked_softmax_cuda' extension\n",
      "#15 1756.4   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron\n",
      "#15 1756.6   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/build.ninja...\n",
      "#15 1756.6   Compiling objects...\n",
      "#15 1756.6   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 1772.5   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron/scaled_upper_triang_masked_softmax.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/scaled_upper_triang_masked_softmax.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron/scaled_upper_triang_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 1772.6   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron/scaled_upper_triang_masked_softmax.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/scaled_upper_triang_masked_softmax.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron/scaled_upper_triang_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 2042.0   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 2042.0   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron/scaled_upper_triang_masked_softmax.o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 2042.4   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 2042.4   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron/scaled_upper_triang_masked_softmax.o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#14 2042.8   building 'generic_scaled_masked_softmax_cuda' extension\n",
      "#14 2042.8   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron\n",
      "#14 2043.0   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/build.ninja...\n",
      "#14 2043.0   Compiling objects...\n",
      "#14 2043.0   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 2042.4   building 'generic_scaled_masked_softmax_cuda' extension\n",
      "#15 2042.4   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron\n",
      "#15 2042.6   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/build.ninja...\n",
      "#15 2042.6   Compiling objects...\n",
      "#15 2042.6   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#15 2058.2   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron/generic_scaled_masked_softmax.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/generic_scaled_masked_softmax.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron/generic_scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 2058.7   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron/generic_scaled_masked_softmax.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/generic_scaled_masked_softmax.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron/generic_scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 2212.5   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron/generic_scaled_masked_softmax_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/generic_scaled_masked_softmax_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron/generic_scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 2212.5   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron/generic_scaled_masked_softmax.o /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron/generic_scaled_masked_softmax_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#15 2212.9   building 'scaled_masked_softmax_cuda' extension\n",
      "#15 2212.9   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron\n",
      "#15 2213.1   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/build.ninja...\n",
      "#15 2213.1   Compiling objects...\n",
      "#15 2213.1   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 2212.7   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron/generic_scaled_masked_softmax_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/generic_scaled_masked_softmax_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron/generic_scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 2212.8   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron/generic_scaled_masked_softmax.o /tmp/apex/build/temp.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda/csrc/megatron/generic_scaled_masked_softmax_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#14 2213.1   building 'scaled_masked_softmax_cuda' extension\n",
      "#14 2213.1   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron\n",
      "#14 2213.3   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/build.ninja...\n",
      "#14 2213.3   Compiling objects...\n",
      "#14 2213.3   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 2229.0   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron/scaled_masked_softmax.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/scaled_masked_softmax.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron/scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 2229.3   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron/scaled_masked_softmax.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/scaled_masked_softmax.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron/scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 2395.3   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron/scaled_masked_softmax_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/scaled_masked_softmax_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron/scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 2395.3   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron/scaled_masked_softmax.o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron/scaled_masked_softmax_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#15 2395.7   building 'scaled_softmax_cuda' extension\n",
      "#15 2395.7   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron\n",
      "#15 2395.9   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/build.ninja...\n",
      "#15 2395.9   Compiling objects...\n",
      "#15 2395.9   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 2395.5   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron/scaled_masked_softmax_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/scaled_masked_softmax_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron/scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 2395.6   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron/scaled_masked_softmax.o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_masked_softmax_cuda/csrc/megatron/scaled_masked_softmax_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#14 2395.9   building 'scaled_softmax_cuda' extension\n",
      "#14 2395.9   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron\n",
      "#14 2396.1   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/build.ninja...\n",
      "#14 2396.1   Compiling objects...\n",
      "#14 2396.1   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#14 2411.8   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron/scaled_softmax.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/scaled_softmax.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron/scaled_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 2411.8   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron/scaled_softmax.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/scaled_softmax.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron/scaled_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 2628.1   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron/scaled_softmax_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/scaled_softmax_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron/scaled_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 2628.1   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron/scaled_softmax.o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron/scaled_softmax_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/scaled_softmax_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#15 2628.5   building 'fused_rotary_positional_embedding' extension\n",
      "#15 2628.5   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron\n",
      "#15 2628.7   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/build.ninja...\n",
      "#15 2628.7   Compiling objects...\n",
      "#15 2628.7   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 2628.7   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron/scaled_softmax_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/scaled_softmax_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron/scaled_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 2628.7   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron/scaled_softmax.o /tmp/apex/build/temp.linux-x86_64-cpython-311/scaled_softmax_cuda/csrc/megatron/scaled_softmax_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/scaled_softmax_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#14 2629.1   building 'fused_rotary_positional_embedding' extension\n",
      "#14 2629.1   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron\n",
      "#14 2629.3   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/build.ninja...\n",
      "#14 2629.3   Compiling objects...\n",
      "#14 2629.3   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 2645.0   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron/fused_rotary_positional_embedding.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/fused_rotary_positional_embedding.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron/fused_rotary_positional_embedding.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_rotary_positional_embedding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 2645.6   [1/2] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron/fused_rotary_positional_embedding.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/fused_rotary_positional_embedding.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron/fused_rotary_positional_embedding.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_rotary_positional_embedding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 2800.5   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron/fused_rotary_positional_embedding_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/fused_rotary_positional_embedding_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron/fused_rotary_positional_embedding_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_rotary_positional_embedding -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#15 2800.5   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron/fused_rotary_positional_embedding.o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron/fused_rotary_positional_embedding_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/fused_rotary_positional_embedding.cpython-311-x86_64-linux-gnu.so\n",
      "#15 2800.8   building 'fused_weight_gradient_mlp_cuda' extension\n",
      "#15 2800.8   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron\n",
      "#15 2800.9   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/build.ninja...\n",
      "#15 2800.9   Compiling objects...\n",
      "#15 2800.9   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 2800.7   [2/2] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron/fused_rotary_positional_embedding_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/fused_rotary_positional_embedding_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron/fused_rotary_positional_embedding_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_rotary_positional_embedding -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_52,code=sm_52 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_90,code=sm_90 -std=c++17\n",
      "#14 2800.8   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron/fused_rotary_positional_embedding.o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_rotary_positional_embedding/csrc/megatron/fused_rotary_positional_embedding_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/fused_rotary_positional_embedding.cpython-311-x86_64-linux-gnu.so\n",
      "#14 2801.1   building 'fused_weight_gradient_mlp_cuda' extension\n",
      "#14 2801.1   creating /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron\n",
      "#14 2801.3   Emitting ninja build file /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/build.ninja...\n",
      "#14 2801.3   Compiling objects...\n",
      "#14 2801.3   Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 2819.7   [1/3] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/fused_weight_gradient_dense.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 2820.1   [1/3] c++ -MMD -MF /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense.o.d -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/fused_weight_gradient_dense.cpp -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 ...\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 2949.4   [2/3] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 2950.5   [3/3] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/fused_weight_gradient_dense_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#15 2950.5   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense.o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#15 2950.9   installing to build/bdist.linux-x86_64/wheel\n",
      "#15 2950.9   running install\n",
      "#15 2950.9   running install_lib\n",
      "#15 2950.9   creating build/bdist.linux-x86_64/wheel\n",
      "#15 2950.9   copying build/lib.linux-x86_64-cpython-311/fused_layer_norm_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#15 2950.9   copying build/lib.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#15 2950.9   copying build/lib.linux-x86_64-cpython-311/fused_rotary_positional_embedding.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#15 2950.9   copying build/lib.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#15 2950.9   copying build/lib.linux-x86_64-cpython-311/fused_dense_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#15 2950.9   copying build/lib.linux-x86_64-cpython-311/scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#15 2950.9   copying build/lib.linux-x86_64-cpython-311/amp_C.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#15 2950.9   copying build/lib.linux-x86_64-cpython-311/scaled_softmax_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#15 2950.9   copying build/lib.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/mlp_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex_C.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/syncbn.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/_autocast_utils.py -> build/bdist.linux-x86_64/wheel/./apex\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/__init__.py -> build/bdist.linux-x86_64/wheel/./apex\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/amp/lists\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/./apex/amp/lists\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/./apex/amp/lists\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/./apex/amp/lists\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/./apex/RNN\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/RNN\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/./apex/RNN\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/./apex/RNN\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/./apex/mlp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/mlp\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/multi_tensor_apply\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/./apex/multi_tensor_apply\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/conv_bias_relu\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/conv_bias_relu\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/nccl_allocator\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/nccl_allocator/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/nccl_allocator\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/nccl_allocator/nccl_allocator.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/nccl_allocator\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/clip_grad\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad/clip_grad.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/clip_grad\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/conv_bias_relu\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/conv_bias_relu\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/clip_grad\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad/test_clip_grad.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/clip_grad\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/transducer\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer/test_transducer_joint.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/transducer\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer/test_transducer_loss.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/transducer\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/layer_norm\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/layer_norm\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/bottleneck\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/bottleneck\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/group_norm\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/group_norm\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm/test_group_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/group_norm\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha/test_fmha.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/fmha\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/fmha\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/peer_memory\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/peer_memory\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/index_mul_2d\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/index_mul_2d\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/xentropy\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy/test_label_smoothing.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/xentropy\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/cudnn_gbn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/cudnn_gbn\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers/test_dist_adam.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/optimizers\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/focal_loss\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss/test_focal_loss.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/focal_loss\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/transducer\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/transducer\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/transducer/_transducer_ref.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/transducer\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity/permutation_search_kernels\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity/permutation_search_kernels\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity/permutation_search_kernels\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity/permutation_search_kernels\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity/permutation_search_kernels\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/gpu_direct_storage\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/gpu_direct_storage/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/gpu_direct_storage\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/layer_norm\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/layer_norm\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/bottleneck\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/bottleneck\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/bottleneck\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/bottleneck\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/group_norm\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/group_norm\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm/group_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/group_norm\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/fmha\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/fmha\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/groupbn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/groupbn\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/peer_memory\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/peer_memory\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/peer_memory\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/index_mul_2d\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d/index_mul_2d.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/index_mul_2d\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/xentropy\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/xentropy\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/cudnn_gbn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/cudnn_gbn\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_mha_kernel.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_layer_norm_config_hopper.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/fused_adam_swa.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/layer_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_layer_norm_forward_kernels.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/mha.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_layer_norm_backward_kernels.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_layer_norm_config_ampere.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/focal_loss\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/focal_loss\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/fused_dense\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/wheel/./apex/fused_dense\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/normalization\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/./apex/normalization\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/transformer\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/transformer/layers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/layers/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/layers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/layers/layer_norm.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/layers\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/enums.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel/schedules\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel/schedules\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel/schedules\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel/schedules\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel/schedules\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/transformer/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/amp/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/amp\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/utils.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/transformer/_data\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/_data/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/_data\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/_data\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/log_util.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/transformer/functional\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/functional/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/functional\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/functional/fused_rope.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/functional\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/functional\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/parallel_state.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/standalone_transformer_lm.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/commons.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/arguments.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/_ucc_util.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/transformer/microbatches.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#15 2951.0   creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/./apex/fp16_utils\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/fp16_utils\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/./apex/fp16_utils\n",
      "#15 2951.0   copying build/lib.linux-x86_64-cpython-311/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/./apex/fp16_utils\n",
      "#15 2951.0   warning: install_lib: byte-compiling is disabled, skipping.\n",
      "#15 2951.0 \n",
      "#15 2951.0   running install_egg_info\n",
      "#15 2951.0   running egg_info\n",
      "#15 2951.0   creating apex.egg-info\n",
      "#15 2951.0   writing apex.egg-info/PKG-INFO\n",
      "#15 2951.0   writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "#15 2951.0   writing requirements to apex.egg-info/requires.txt\n",
      "#15 2951.0   writing top-level names to apex.egg-info/top_level.txt\n",
      "#15 2951.0   writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "#15 2951.1   reading manifest file 'apex.egg-info/SOURCES.txt'\n",
      "#15 2951.1   adding license file 'LICENSE'\n",
      "#15 2951.1   writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "#15 2951.1   Copying apex.egg-info to build/bdist.linux-x86_64/wheel/./apex-0.1-py3.11.egg-info\n",
      "#15 2951.1   running install_scripts\n",
      "#15 2951.1   creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
      "#15 2951.1   creating '/tmp/pip-wheel-8uzmzfat/.tmp-zc833ybb/apex-0.1-cp311-cp311-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "#15 2951.4   adding 'amp_C.cpython-311-x86_64-linux-gnu.so'\n",
      "#15 2951.4   adding 'apex_C.cpython-311-x86_64-linux-gnu.so'\n",
      "#15 2951.4   adding 'fused_dense_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#15 2951.7   adding 'fused_layer_norm_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#15 2951.8   adding 'fused_rotary_positional_embedding.cpython-311-x86_64-linux-gnu.so'\n",
      "#15 2951.8   adding 'fused_weight_gradient_mlp_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#15 2951.8   adding 'generic_scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#15 2951.8   adding 'mlp_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#15 2952.0   adding 'scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#15 2952.2   adding 'scaled_softmax_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#15 2952.7   adding 'scaled_upper_triang_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#15 2952.8   adding 'syncbn.cpython-311-x86_64-linux-gnu.so'\n",
      "#15 2952.8   adding 'apex/__init__.py'\n",
      "#15 2952.8   adding 'apex/_autocast_utils.py'\n",
      "#15 2952.8   adding 'apex/RNN/RNNBackend.py'\n",
      "#15 2952.8   adding 'apex/RNN/__init__.py'\n",
      "#15 2952.8   adding 'apex/RNN/cells.py'\n",
      "#15 2952.8   adding 'apex/RNN/models.py'\n",
      "#15 2952.8   adding 'apex/amp/__init__.py'\n",
      "#15 2952.8   adding 'apex/amp/__version__.py'\n",
      "#15 2952.8   adding 'apex/amp/_amp_state.py'\n",
      "#15 2952.8   adding 'apex/amp/_initialize.py'\n",
      "#15 2952.8   adding 'apex/amp/_process_optimizer.py'\n",
      "#15 2952.8   adding 'apex/amp/amp.py'\n",
      "#15 2952.8   adding 'apex/amp/compat.py'\n",
      "#15 2952.8   adding 'apex/amp/frontend.py'\n",
      "#15 2952.8   adding 'apex/amp/handle.py'\n",
      "#15 2952.8   adding 'apex/amp/opt.py'\n",
      "#15 2952.8   adding 'apex/amp/rnn_compat.py'\n",
      "#15 2952.8   adding 'apex/amp/scaler.py'\n",
      "#15 2952.8   adding 'apex/amp/utils.py'\n",
      "#15 2952.8   adding 'apex/amp/wrap.py'\n",
      "#15 2952.8   adding 'apex/amp/lists/__init__.py'\n",
      "#15 2952.8   adding 'apex/amp/lists/functional_overrides.py'\n",
      "#15 2952.8   adding 'apex/amp/lists/tensor_overrides.py'\n",
      "#15 2952.8   adding 'apex/amp/lists/torch_overrides.py'\n",
      "#15 2952.8   adding 'apex/contrib/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/bottleneck/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/bottleneck/bottleneck.py'\n",
      "#15 2952.8   adding 'apex/contrib/bottleneck/halo_exchangers.py'\n",
      "#15 2952.8   adding 'apex/contrib/bottleneck/test.py'\n",
      "#15 2952.8   adding 'apex/contrib/clip_grad/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/clip_grad/clip_grad.py'\n",
      "#15 2952.8   adding 'apex/contrib/conv_bias_relu/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/conv_bias_relu/conv_bias_relu.py'\n",
      "#15 2952.8   adding 'apex/contrib/cudnn_gbn/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/cudnn_gbn/batch_norm.py'\n",
      "#15 2952.8   adding 'apex/contrib/fmha/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/fmha/fmha.py'\n",
      "#15 2952.8   adding 'apex/contrib/focal_loss/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/focal_loss/focal_loss.py'\n",
      "#15 2952.8   adding 'apex/contrib/gpu_direct_storage/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/group_norm/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/group_norm/group_norm.py'\n",
      "#15 2952.8   adding 'apex/contrib/groupbn/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/groupbn/batch_norm.py'\n",
      "#15 2952.8   adding 'apex/contrib/index_mul_2d/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/index_mul_2d/index_mul_2d.py'\n",
      "#15 2952.8   adding 'apex/contrib/layer_norm/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/layer_norm/layer_norm.py'\n",
      "#15 2952.8   adding 'apex/contrib/multihead_attn/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
      "#15 2952.8   adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
      "#15 2952.8   adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
      "#15 2952.8   adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
      "#15 2952.8   adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
      "#15 2952.8   adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
      "#15 2952.8   adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
      "#15 2952.8   adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
      "#15 2952.8   adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
      "#15 2952.8   adding 'apex/contrib/nccl_allocator/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/nccl_allocator/nccl_allocator.py'\n",
      "#15 2952.8   adding 'apex/contrib/openfold_triton/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/openfold_triton/_layer_norm_backward_kernels.py'\n",
      "#15 2952.8   adding 'apex/contrib/openfold_triton/_layer_norm_config_ampere.py'\n",
      "#15 2952.8   adding 'apex/contrib/openfold_triton/_layer_norm_config_hopper.py'\n",
      "#15 2952.8   adding 'apex/contrib/openfold_triton/_layer_norm_forward_kernels.py'\n",
      "#15 2952.8   adding 'apex/contrib/openfold_triton/_mha_kernel.py'\n",
      "#15 2952.8   adding 'apex/contrib/openfold_triton/fused_adam_swa.py'\n",
      "#15 2952.8   adding 'apex/contrib/openfold_triton/layer_norm.py'\n",
      "#15 2952.8   adding 'apex/contrib/openfold_triton/mha.py'\n",
      "#15 2952.8   adding 'apex/contrib/optimizers/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
      "#15 2952.8   adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
      "#15 2952.8   adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
      "#15 2952.8   adding 'apex/contrib/optimizers/fused_adam.py'\n",
      "#15 2952.8   adding 'apex/contrib/optimizers/fused_lamb.py'\n",
      "#15 2952.8   adding 'apex/contrib/optimizers/fused_sgd.py'\n",
      "#15 2952.8   adding 'apex/contrib/peer_memory/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/peer_memory/peer_halo_exchanger_1d.py'\n",
      "#15 2952.8   adding 'apex/contrib/peer_memory/peer_memory.py'\n",
      "#15 2952.8   adding 'apex/contrib/sparsity/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/sparsity/asp.py'\n",
      "#15 2952.8   adding 'apex/contrib/sparsity/permutation_lib.py'\n",
      "#15 2952.8   adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
      "#15 2952.8   adding 'apex/contrib/sparsity/permutation_search_kernels/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py'\n",
      "#15 2952.8   adding 'apex/contrib/sparsity/permutation_search_kernels/channel_swap.py'\n",
      "#15 2952.8   adding 'apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py'\n",
      "#15 2952.8   adding 'apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/bottleneck/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/bottleneck/test_bottleneck_module.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/clip_grad/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/clip_grad/test_clip_grad.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/conv_bias_relu/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/cudnn_gbn/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/fmha/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/fmha/test_fmha.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/focal_loss/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/focal_loss/test_focal_loss.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/group_norm/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/group_norm/test_group_norm.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/index_mul_2d/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/index_mul_2d/test_index_mul_2d.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/layer_norm/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/layer_norm/test_fast_layer_norm.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/multihead_attn/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/multihead_attn/test_mha_fused_softmax.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/optimizers/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/optimizers/test_dist_adam.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/optimizers/test_distributed_fused_lamb.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/peer_memory/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/transducer/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/transducer/test_transducer_joint.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/transducer/test_transducer_loss.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/xentropy/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/test/xentropy/test_label_smoothing.py'\n",
      "#15 2952.8   adding 'apex/contrib/transducer/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/transducer/_transducer_ref.py'\n",
      "#15 2952.8   adding 'apex/contrib/transducer/transducer.py'\n",
      "#15 2952.8   adding 'apex/contrib/xentropy/__init__.py'\n",
      "#15 2952.8   adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
      "#15 2952.8   adding 'apex/fp16_utils/__init__.py'\n",
      "#15 2952.8   adding 'apex/fp16_utils/fp16_optimizer.py'\n",
      "#15 2952.8   adding 'apex/fp16_utils/fp16util.py'\n",
      "#15 2952.8   adding 'apex/fp16_utils/loss_scaler.py'\n",
      "#15 2952.8   adding 'apex/fused_dense/__init__.py'\n",
      "#15 2952.8   adding 'apex/fused_dense/fused_dense.py'\n",
      "#15 2952.8   adding 'apex/mlp/__init__.py'\n",
      "#15 2952.8   adding 'apex/mlp/mlp.py'\n",
      "#15 2952.8   adding 'apex/multi_tensor_apply/__init__.py'\n",
      "#15 2952.8   adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
      "#15 2952.8   adding 'apex/normalization/__init__.py'\n",
      "#15 2952.8   adding 'apex/normalization/fused_layer_norm.py'\n",
      "#15 2952.8   adding 'apex/optimizers/__init__.py'\n",
      "#15 2952.8   adding 'apex/optimizers/fused_adagrad.py'\n",
      "#15 2952.8   adding 'apex/optimizers/fused_adam.py'\n",
      "#15 2952.8   adding 'apex/optimizers/fused_lamb.py'\n",
      "#15 2952.8   adding 'apex/optimizers/fused_mixed_precision_lamb.py'\n",
      "#15 2952.8   adding 'apex/optimizers/fused_novograd.py'\n",
      "#15 2952.8   adding 'apex/optimizers/fused_sgd.py'\n",
      "#15 2952.8   adding 'apex/parallel/LARC.py'\n",
      "#15 2952.8   adding 'apex/parallel/__init__.py'\n",
      "#15 2952.8   adding 'apex/parallel/distributed.py'\n",
      "#15 2952.8   adding 'apex/parallel/multiproc.py'\n",
      "#15 2952.8   adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
      "#15 2952.8   adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
      "#15 2952.8   adding 'apex/parallel/sync_batchnorm.py'\n",
      "#15 2952.8   adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
      "#15 2952.8   adding 'apex/transformer/__init__.py'\n",
      "#15 2952.8   adding 'apex/transformer/_ucc_util.py'\n",
      "#15 2952.8   adding 'apex/transformer/enums.py'\n",
      "#15 2952.8   adding 'apex/transformer/log_util.py'\n",
      "#15 2952.8   adding 'apex/transformer/microbatches.py'\n",
      "#15 2952.8   adding 'apex/transformer/parallel_state.py'\n",
      "#15 2952.8   adding 'apex/transformer/utils.py'\n",
      "#15 2952.8   adding 'apex/transformer/_data/__init__.py'\n",
      "#15 2952.8   adding 'apex/transformer/_data/_batchsampler.py'\n",
      "#15 2952.8   adding 'apex/transformer/amp/__init__.py'\n",
      "#15 2952.8   adding 'apex/transformer/amp/grad_scaler.py'\n",
      "#15 2952.8   adding 'apex/transformer/functional/__init__.py'\n",
      "#15 2952.8   adding 'apex/transformer/functional/fused_rope.py'\n",
      "#15 2952.8   adding 'apex/transformer/functional/fused_softmax.py'\n",
      "#15 2952.8   adding 'apex/transformer/layers/__init__.py'\n",
      "#15 2952.8   adding 'apex/transformer/layers/layer_norm.py'\n",
      "#15 2952.8   adding 'apex/transformer/pipeline_parallel/__init__.py'\n",
      "#15 2952.8   adding 'apex/transformer/pipeline_parallel/_timers.py'\n",
      "#15 2952.8   adding 'apex/transformer/pipeline_parallel/p2p_communication.py'\n",
      "#15 2952.8   adding 'apex/transformer/pipeline_parallel/utils.py'\n",
      "#15 2952.8   adding 'apex/transformer/pipeline_parallel/schedules/__init__.py'\n",
      "#15 2952.8   adding 'apex/transformer/pipeline_parallel/schedules/common.py'\n",
      "#15 2952.8   adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py'\n",
      "#15 2952.8   adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py'\n",
      "#15 2952.8   adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py'\n",
      "#15 2952.8   adding 'apex/transformer/tensor_parallel/__init__.py'\n",
      "#15 2952.8   adding 'apex/transformer/tensor_parallel/cross_entropy.py'\n",
      "#15 2952.8   adding 'apex/transformer/tensor_parallel/data.py'\n",
      "#15 2952.8   adding 'apex/transformer/tensor_parallel/layers.py'\n",
      "#15 2952.8   adding 'apex/transformer/tensor_parallel/mappings.py'\n",
      "#15 2952.8   adding 'apex/transformer/tensor_parallel/memory.py'\n",
      "#15 2952.8   adding 'apex/transformer/tensor_parallel/random.py'\n",
      "#15 2952.8   adding 'apex/transformer/tensor_parallel/utils.py'\n",
      "#15 2952.8   adding 'apex/transformer/testing/__init__.py'\n",
      "#15 2952.8   adding 'apex/transformer/testing/arguments.py'\n",
      "#15 2952.8   adding 'apex/transformer/testing/commons.py'\n",
      "#15 2952.8   adding 'apex/transformer/testing/distributed_test_base.py'\n",
      "#15 2952.8   adding 'apex/transformer/testing/global_vars.py'\n",
      "#15 2952.8   adding 'apex/transformer/testing/standalone_bert.py'\n",
      "#15 2952.8   adding 'apex/transformer/testing/standalone_gpt.py'\n",
      "#15 2952.8   adding 'apex/transformer/testing/standalone_transformer_lm.py'\n",
      "#15 2952.8   adding 'apex-0.1.dist-info/LICENSE'\n",
      "#15 2952.8   adding 'apex-0.1.dist-info/METADATA'\n",
      "#15 2952.8   adding 'apex-0.1.dist-info/WHEEL'\n",
      "#15 2952.8   adding 'apex-0.1.dist-info/top_level.txt'\n",
      "#15 2952.8   adding 'apex-0.1.dist-info/RECORD'\n",
      "#15 2952.8   removing build/bdist.linux-x86_64/wheel\n",
      "#15 2953.3   Building wheel for apex (pyproject.toml): finished with status 'done'\n",
      "#15 2953.3   Created wheel for apex: filename=apex-0.1-cp311-cp311-linux_x86_64.whl size=13299395 sha256=bf067d4d453919e6afecdec533b423e961bfde66edeb850bd3d0d3a959419f73\n",
      "#15 2953.3   Stored in directory: /tmp/pip-ephem-wheel-cache-yr8vekhr/wheels/f7/69/cf/3bc006a91e599ccc6dccf4edff04c40b9a17a2eaccf4457eab\n",
      "#15 2953.4 Successfully built apex\n",
      "#15 2953.7 Installing collected packages: apex\n",
      "#15 ...\n",
      "\n",
      "#14 [linux/arm64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#14 2949.9   [2/3] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 2950.0   [3/3] /opt/conda/bin/nvcc --generate-dependencies-with-compile --dependency-output /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense_cuda.o.d -I/tmp/apex/csrc -I/opt/conda/lib/python3.11/site-packages/torch/include -I/opt/conda/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -I/opt/conda/lib/python3.11/site-packages/torch/include/TH -I/opt/conda/lib/python3.11/site-packages/torch/include/THC -I/opt/conda/include -I/opt/conda/include/python3.11 -c -c /tmp/apex/csrc/megatron/fused_weight_gradient_dense_cuda.cu -o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "#14 2950.0   g++ -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -pthread -B /opt/conda/compiler_compat -shared /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense.o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o /tmp/apex/build/temp.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda/csrc/megatron/fused_weight_gradient_dense_cuda.o -L/opt/conda/lib/python3.11/site-packages/torch/lib -L/opt/conda/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda.cpython-311-x86_64-linux-gnu.so\n",
      "#14 2950.5   installing to build/bdist.linux-x86_64/wheel\n",
      "#14 2950.5   running install\n",
      "#14 2950.5   running install_lib\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/fused_layer_norm_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/generic_scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/fused_rotary_positional_embedding.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/fused_weight_gradient_mlp_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/fused_dense_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/amp_C.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/scaled_softmax_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/scaled_upper_triang_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/mlp_cuda.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex_C.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/syncbn.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel/.\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/_autocast_utils.py -> build/bdist.linux-x86_64/wheel/./apex\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/__init__.py -> build/bdist.linux-x86_64/wheel/./apex\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/amp/lists\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/./apex/amp/lists\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/./apex/amp/lists\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/./apex/amp/lists\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/./apex/amp\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/./apex/RNN\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/RNN\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/./apex/RNN\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/./apex/RNN\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/./apex/mlp\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/mlp\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/multi_tensor_apply\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/./apex/multi_tensor_apply\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/conv_bias_relu\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/conv_bias_relu\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/nccl_allocator\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/nccl_allocator/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/nccl_allocator\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/nccl_allocator/nccl_allocator.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/nccl_allocator\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/clip_grad\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/clip_grad/clip_grad.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/clip_grad\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/conv_bias_relu\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/conv_bias_relu\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/clip_grad\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/clip_grad/test_clip_grad.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/clip_grad\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/transducer\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer/test_transducer_joint.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/transducer\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/transducer/test_transducer_loss.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/transducer\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/layer_norm\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/layer_norm\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/bottleneck\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/bottleneck\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/group_norm\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/group_norm\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/group_norm/test_group_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/group_norm\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha/test_fmha.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/fmha\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/fmha\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/peer_memory\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/peer_memory\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/index_mul_2d\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/index_mul_2d\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/xentropy\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/xentropy/test_label_smoothing.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/xentropy\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/cudnn_gbn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/cudnn_gbn\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/optimizers\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/optimizers\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/optimizers/test_dist_adam.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/optimizers\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/focal_loss\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/focal_loss/test_focal_loss.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/focal_loss\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/test/multihead_attn\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/transducer\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/transducer\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/transducer/_transducer_ref.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/transducer\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity/permutation_search_kernels\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity/permutation_search_kernels\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity/permutation_search_kernels\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity/permutation_search_kernels\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity/permutation_search_kernels\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/sparsity\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/gpu_direct_storage\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/gpu_direct_storage/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/gpu_direct_storage\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/layer_norm\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/layer_norm\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/bottleneck\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/bottleneck\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/bottleneck\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/bottleneck\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/group_norm\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/group_norm\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/group_norm/group_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/group_norm\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/fmha\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/fmha\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/groupbn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/groupbn\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/peer_memory\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/peer_memory\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/peer_memory\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/index_mul_2d\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/index_mul_2d/index_mul_2d.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/index_mul_2d\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/xentropy\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/xentropy\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/cudnn_gbn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/cudnn_gbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/cudnn_gbn\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/openfold_triton\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_mha_kernel.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_layer_norm_config_hopper.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/fused_adam_swa.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/layer_norm.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_layer_norm_forward_kernels.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/mha.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_layer_norm_backward_kernels.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/openfold_triton/_layer_norm_config_ampere.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/openfold_triton\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/optimizers\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/focal_loss\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/focal_loss\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/./apex/contrib/multihead_attn\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/fused_dense\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/wheel/./apex/fused_dense\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/normalization\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/./apex/normalization\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/transformer\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/transformer/layers\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/transformer/layers/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/layers\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/transformer/layers/layer_norm.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/layers\n",
      "#14 2950.5   creating build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#14 2950.5   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/tensor_parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/enums.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#14 2950.6   creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel\n",
      "#14 2950.6   creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel/schedules\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel/schedules\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel/schedules\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel/schedules\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/pipeline_parallel/schedules\n",
      "#14 2950.6   creating build/bdist.linux-x86_64/wheel/apex/transformer/amp\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/amp/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/amp\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/amp\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/utils.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#14 2950.6   creating build/bdist.linux-x86_64/wheel/apex/transformer/_data\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/_data/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/_data\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/_data\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/log_util.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#14 2950.6   creating build/bdist.linux-x86_64/wheel/apex/transformer/functional\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/functional/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/functional\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/functional/fused_rope.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/functional\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/functional\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/parallel_state.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#14 2950.6   creating build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/standalone_transformer_lm.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/commons.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/arguments.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/wheel/./apex/transformer/testing\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/_ucc_util.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/transformer/microbatches.py -> build/bdist.linux-x86_64/wheel/./apex/transformer\n",
      "#14 2950.6   creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/./apex/optimizers\n",
      "#14 2950.6   creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/./apex/parallel\n",
      "#14 2950.6   creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/./apex/fp16_utils\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/./apex/fp16_utils\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/./apex/fp16_utils\n",
      "#14 2950.6   copying build/lib.linux-x86_64-cpython-311/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/./apex/fp16_utils\n",
      "#14 2950.6   warning: install_lib: byte-compiling is disabled, skipping.\n",
      "#14 2950.6 \n",
      "#14 2950.6   running install_egg_info\n",
      "#14 2950.6   running egg_info\n",
      "#14 2950.6   creating apex.egg-info\n",
      "#14 2950.6   writing apex.egg-info/PKG-INFO\n",
      "#14 2950.6   writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "#14 2950.6   writing requirements to apex.egg-info/requires.txt\n",
      "#14 2950.6   writing top-level names to apex.egg-info/top_level.txt\n",
      "#14 2950.6   writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "#14 2950.6   reading manifest file 'apex.egg-info/SOURCES.txt'\n",
      "#14 2950.6   adding license file 'LICENSE'\n",
      "#14 2950.6   writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "#14 2950.6   Copying apex.egg-info to build/bdist.linux-x86_64/wheel/./apex-0.1-py3.11.egg-info\n",
      "#14 2950.6   running install_scripts\n",
      "#14 2950.6   creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
      "#14 2950.6   creating '/tmp/pip-wheel-zqhwo2z1/.tmp-5azi5evv/apex-0.1-cp311-cp311-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
      "#14 2950.9   adding 'amp_C.cpython-311-x86_64-linux-gnu.so'\n",
      "#14 2950.9   adding 'apex_C.cpython-311-x86_64-linux-gnu.so'\n",
      "#14 2950.9   adding 'fused_dense_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#14 2951.3   adding 'fused_layer_norm_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#14 2951.3   adding 'fused_rotary_positional_embedding.cpython-311-x86_64-linux-gnu.so'\n",
      "#14 2951.3   adding 'fused_weight_gradient_mlp_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#14 2951.3   adding 'generic_scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#14 2951.4   adding 'mlp_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#14 2951.5   adding 'scaled_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#14 2951.8   adding 'scaled_softmax_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#14 2952.2   adding 'scaled_upper_triang_masked_softmax_cuda.cpython-311-x86_64-linux-gnu.so'\n",
      "#14 2952.3   adding 'syncbn.cpython-311-x86_64-linux-gnu.so'\n",
      "#14 2952.3   adding 'apex/__init__.py'\n",
      "#14 2952.3   adding 'apex/_autocast_utils.py'\n",
      "#14 2952.3   adding 'apex/RNN/RNNBackend.py'\n",
      "#14 2952.3   adding 'apex/RNN/__init__.py'\n",
      "#14 2952.3   adding 'apex/RNN/cells.py'\n",
      "#14 2952.3   adding 'apex/RNN/models.py'\n",
      "#14 2952.3   adding 'apex/amp/__init__.py'\n",
      "#14 2952.3   adding 'apex/amp/__version__.py'\n",
      "#14 2952.3   adding 'apex/amp/_amp_state.py'\n",
      "#14 2952.3   adding 'apex/amp/_initialize.py'\n",
      "#14 2952.3   adding 'apex/amp/_process_optimizer.py'\n",
      "#14 2952.3   adding 'apex/amp/amp.py'\n",
      "#14 2952.3   adding 'apex/amp/compat.py'\n",
      "#14 2952.3   adding 'apex/amp/frontend.py'\n",
      "#14 2952.3   adding 'apex/amp/handle.py'\n",
      "#14 2952.3   adding 'apex/amp/opt.py'\n",
      "#14 2952.3   adding 'apex/amp/rnn_compat.py'\n",
      "#14 2952.3   adding 'apex/amp/scaler.py'\n",
      "#14 2952.3   adding 'apex/amp/utils.py'\n",
      "#14 2952.3   adding 'apex/amp/wrap.py'\n",
      "#14 2952.3   adding 'apex/amp/lists/__init__.py'\n",
      "#14 2952.3   adding 'apex/amp/lists/functional_overrides.py'\n",
      "#14 2952.3   adding 'apex/amp/lists/tensor_overrides.py'\n",
      "#14 2952.3   adding 'apex/amp/lists/torch_overrides.py'\n",
      "#14 2952.3   adding 'apex/contrib/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/bottleneck/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/bottleneck/bottleneck.py'\n",
      "#14 2952.3   adding 'apex/contrib/bottleneck/halo_exchangers.py'\n",
      "#14 2952.3   adding 'apex/contrib/bottleneck/test.py'\n",
      "#14 2952.3   adding 'apex/contrib/clip_grad/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/clip_grad/clip_grad.py'\n",
      "#14 2952.3   adding 'apex/contrib/conv_bias_relu/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/conv_bias_relu/conv_bias_relu.py'\n",
      "#14 2952.3   adding 'apex/contrib/cudnn_gbn/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/cudnn_gbn/batch_norm.py'\n",
      "#14 2952.3   adding 'apex/contrib/fmha/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/fmha/fmha.py'\n",
      "#14 2952.3   adding 'apex/contrib/focal_loss/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/focal_loss/focal_loss.py'\n",
      "#14 2952.3   adding 'apex/contrib/gpu_direct_storage/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/group_norm/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/group_norm/group_norm.py'\n",
      "#14 2952.3   adding 'apex/contrib/groupbn/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/groupbn/batch_norm.py'\n",
      "#14 2952.3   adding 'apex/contrib/index_mul_2d/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/index_mul_2d/index_mul_2d.py'\n",
      "#14 2952.3   adding 'apex/contrib/layer_norm/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/layer_norm/layer_norm.py'\n",
      "#14 2952.3   adding 'apex/contrib/multihead_attn/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
      "#14 2952.3   adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
      "#14 2952.3   adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
      "#14 2952.3   adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
      "#14 2952.3   adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
      "#14 2952.3   adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
      "#14 2952.3   adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
      "#14 2952.3   adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
      "#14 2952.3   adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
      "#14 2952.3   adding 'apex/contrib/nccl_allocator/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/nccl_allocator/nccl_allocator.py'\n",
      "#14 2952.3   adding 'apex/contrib/openfold_triton/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/openfold_triton/_layer_norm_backward_kernels.py'\n",
      "#14 2952.3   adding 'apex/contrib/openfold_triton/_layer_norm_config_ampere.py'\n",
      "#14 2952.3   adding 'apex/contrib/openfold_triton/_layer_norm_config_hopper.py'\n",
      "#14 2952.3   adding 'apex/contrib/openfold_triton/_layer_norm_forward_kernels.py'\n",
      "#14 2952.3   adding 'apex/contrib/openfold_triton/_mha_kernel.py'\n",
      "#14 2952.3   adding 'apex/contrib/openfold_triton/fused_adam_swa.py'\n",
      "#14 2952.3   adding 'apex/contrib/openfold_triton/layer_norm.py'\n",
      "#14 2952.3   adding 'apex/contrib/openfold_triton/mha.py'\n",
      "#14 2952.3   adding 'apex/contrib/optimizers/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
      "#14 2952.3   adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
      "#14 2952.3   adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
      "#14 2952.3   adding 'apex/contrib/optimizers/fused_adam.py'\n",
      "#14 2952.3   adding 'apex/contrib/optimizers/fused_lamb.py'\n",
      "#14 2952.3   adding 'apex/contrib/optimizers/fused_sgd.py'\n",
      "#14 2952.3   adding 'apex/contrib/peer_memory/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/peer_memory/peer_halo_exchanger_1d.py'\n",
      "#14 2952.3   adding 'apex/contrib/peer_memory/peer_memory.py'\n",
      "#14 2952.3   adding 'apex/contrib/sparsity/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/sparsity/asp.py'\n",
      "#14 2952.3   adding 'apex/contrib/sparsity/permutation_lib.py'\n",
      "#14 2952.3   adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
      "#14 2952.3   adding 'apex/contrib/sparsity/permutation_search_kernels/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py'\n",
      "#14 2952.3   adding 'apex/contrib/sparsity/permutation_search_kernels/channel_swap.py'\n",
      "#14 2952.3   adding 'apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py'\n",
      "#14 2952.3   adding 'apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/bottleneck/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/bottleneck/test_bottleneck_module.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/clip_grad/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/clip_grad/test_clip_grad.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/conv_bias_relu/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/cudnn_gbn/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/fmha/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/fmha/test_fmha.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/focal_loss/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/focal_loss/test_focal_loss.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/group_norm/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/group_norm/test_group_norm.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/index_mul_2d/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/index_mul_2d/test_index_mul_2d.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/layer_norm/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/layer_norm/test_fast_layer_norm.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/multihead_attn/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/multihead_attn/test_mha_fused_softmax.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/optimizers/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/optimizers/test_dist_adam.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/optimizers/test_distributed_fused_lamb.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/peer_memory/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/transducer/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/transducer/test_transducer_joint.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/transducer/test_transducer_loss.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/xentropy/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/test/xentropy/test_label_smoothing.py'\n",
      "#14 2952.3   adding 'apex/contrib/transducer/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/transducer/_transducer_ref.py'\n",
      "#14 2952.3   adding 'apex/contrib/transducer/transducer.py'\n",
      "#14 2952.3   adding 'apex/contrib/xentropy/__init__.py'\n",
      "#14 2952.3   adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
      "#14 2952.3   adding 'apex/fp16_utils/__init__.py'\n",
      "#14 2952.3   adding 'apex/fp16_utils/fp16_optimizer.py'\n",
      "#14 2952.3   adding 'apex/fp16_utils/fp16util.py'\n",
      "#14 2952.3   adding 'apex/fp16_utils/loss_scaler.py'\n",
      "#14 2952.3   adding 'apex/fused_dense/__init__.py'\n",
      "#14 2952.3   adding 'apex/fused_dense/fused_dense.py'\n",
      "#14 2952.3   adding 'apex/mlp/__init__.py'\n",
      "#14 2952.3   adding 'apex/mlp/mlp.py'\n",
      "#14 2952.3   adding 'apex/multi_tensor_apply/__init__.py'\n",
      "#14 2952.3   adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
      "#14 2952.3   adding 'apex/normalization/__init__.py'\n",
      "#14 2952.3   adding 'apex/normalization/fused_layer_norm.py'\n",
      "#14 2952.3   adding 'apex/optimizers/__init__.py'\n",
      "#14 2952.3   adding 'apex/optimizers/fused_adagrad.py'\n",
      "#14 2952.3   adding 'apex/optimizers/fused_adam.py'\n",
      "#14 2952.3   adding 'apex/optimizers/fused_lamb.py'\n",
      "#14 2952.3   adding 'apex/optimizers/fused_mixed_precision_lamb.py'\n",
      "#14 2952.3   adding 'apex/optimizers/fused_novograd.py'\n",
      "#14 2952.3   adding 'apex/optimizers/fused_sgd.py'\n",
      "#14 2952.3   adding 'apex/parallel/LARC.py'\n",
      "#14 2952.3   adding 'apex/parallel/__init__.py'\n",
      "#14 2952.3   adding 'apex/parallel/distributed.py'\n",
      "#14 2952.3   adding 'apex/parallel/multiproc.py'\n",
      "#14 2952.3   adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
      "#14 2952.3   adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
      "#14 2952.3   adding 'apex/parallel/sync_batchnorm.py'\n",
      "#14 2952.3   adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
      "#14 2952.3   adding 'apex/transformer/__init__.py'\n",
      "#14 2952.3   adding 'apex/transformer/_ucc_util.py'\n",
      "#14 2952.3   adding 'apex/transformer/enums.py'\n",
      "#14 2952.3   adding 'apex/transformer/log_util.py'\n",
      "#14 2952.3   adding 'apex/transformer/microbatches.py'\n",
      "#14 2952.3   adding 'apex/transformer/parallel_state.py'\n",
      "#14 2952.3   adding 'apex/transformer/utils.py'\n",
      "#14 2952.3   adding 'apex/transformer/_data/__init__.py'\n",
      "#14 2952.3   adding 'apex/transformer/_data/_batchsampler.py'\n",
      "#14 2952.3   adding 'apex/transformer/amp/__init__.py'\n",
      "#14 2952.3   adding 'apex/transformer/amp/grad_scaler.py'\n",
      "#14 2952.3   adding 'apex/transformer/functional/__init__.py'\n",
      "#14 2952.3   adding 'apex/transformer/functional/fused_rope.py'\n",
      "#14 2952.3   adding 'apex/transformer/functional/fused_softmax.py'\n",
      "#14 2952.3   adding 'apex/transformer/layers/__init__.py'\n",
      "#14 2952.3   adding 'apex/transformer/layers/layer_norm.py'\n",
      "#14 2952.3   adding 'apex/transformer/pipeline_parallel/__init__.py'\n",
      "#14 2952.3   adding 'apex/transformer/pipeline_parallel/_timers.py'\n",
      "#14 2952.3   adding 'apex/transformer/pipeline_parallel/p2p_communication.py'\n",
      "#14 2952.3   adding 'apex/transformer/pipeline_parallel/utils.py'\n",
      "#14 2952.3   adding 'apex/transformer/pipeline_parallel/schedules/__init__.py'\n",
      "#14 2952.3   adding 'apex/transformer/pipeline_parallel/schedules/common.py'\n",
      "#14 2952.3   adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py'\n",
      "#14 2952.3   adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py'\n",
      "#14 2952.3   adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py'\n",
      "#14 2952.3   adding 'apex/transformer/tensor_parallel/__init__.py'\n",
      "#14 2952.3   adding 'apex/transformer/tensor_parallel/cross_entropy.py'\n",
      "#14 2952.3   adding 'apex/transformer/tensor_parallel/data.py'\n",
      "#14 2952.3   adding 'apex/transformer/tensor_parallel/layers.py'\n",
      "#14 2952.3   adding 'apex/transformer/tensor_parallel/mappings.py'\n",
      "#14 2952.3   adding 'apex/transformer/tensor_parallel/memory.py'\n",
      "#14 2952.3   adding 'apex/transformer/tensor_parallel/random.py'\n",
      "#14 2952.3   adding 'apex/transformer/tensor_parallel/utils.py'\n",
      "#14 2952.3   adding 'apex/transformer/testing/__init__.py'\n",
      "#14 2952.3   adding 'apex/transformer/testing/arguments.py'\n",
      "#14 2952.3   adding 'apex/transformer/testing/commons.py'\n",
      "#14 2952.3   adding 'apex/transformer/testing/distributed_test_base.py'\n",
      "#14 2952.3   adding 'apex/transformer/testing/global_vars.py'\n",
      "#14 2952.3   adding 'apex/transformer/testing/standalone_bert.py'\n",
      "#14 2952.3   adding 'apex/transformer/testing/standalone_gpt.py'\n",
      "#14 2952.3   adding 'apex/transformer/testing/standalone_transformer_lm.py'\n",
      "#14 2952.3   adding 'apex-0.1.dist-info/LICENSE'\n",
      "#14 2952.3   adding 'apex-0.1.dist-info/METADATA'\n",
      "#14 2952.3   adding 'apex-0.1.dist-info/WHEEL'\n",
      "#14 2952.3   adding 'apex-0.1.dist-info/top_level.txt'\n",
      "#14 2952.3   adding 'apex-0.1.dist-info/RECORD'\n",
      "#14 2952.3   removing build/bdist.linux-x86_64/wheel\n",
      "#14 2953.0   Building wheel for apex (pyproject.toml): finished with status 'done'\n",
      "#14 2953.0   Created wheel for apex: filename=apex-0.1-cp311-cp311-linux_x86_64.whl size=13299385 sha256=a4e4884fd49366902554c188eac1979dc74814873bcf4dad2f131894deec7f2a\n",
      "#14 2953.0   Stored in directory: /tmp/pip-ephem-wheel-cache-3gt2172u/wheels/f7/69/cf/3bc006a91e599ccc6dccf4edff04c40b9a17a2eaccf4457eab\n",
      "#14 2953.0 Successfully built apex\n",
      "#14 2953.4 Installing collected packages: apex\n",
      "#14 2953.8 Successfully installed apex-0.1\n",
      "#14 2953.8 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "#14 DONE 2954.1s\n",
      "\n",
      "#15 [linux/amd64 5/6] RUN git clone https://github.com/NVIDIA/apex.git /tmp/apex     && cd /tmp/apex     && pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation        --config-settings \"--build-option=--cpp_ext\"        --config-settings \"--build-option=--cuda_ext\"        ./     && cd ..     && rm -rf /tmp/apex\n",
      "#15 2954.2 Successfully installed apex-0.1\n",
      "#15 2954.2 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "#15 DONE 2954.3s\n",
      "\n",
      "#16 exporting to image\n",
      "#16 exporting layers\n",
      "#16 exporting layers 8.2s done\n",
      "#16 exporting manifest sha256:4a5b929ea526ec11cc8178ca8733bf75d596a14d8775fb81e1d043260fd4a5c4 done\n",
      "#16 exporting config sha256:5699dea3c1924f075c281105e65fd818e558e1a05fad2a83db1db926c819afe8 done\n",
      "#16 exporting attestation manifest sha256:1c650756a3eebe6c27cd9139786012c8e8182c497dae19c6b002ade7030cbbe3 done\n",
      "#16 exporting manifest sha256:2b60ce57390cd452275eb1264ba103f78eb696dc87df419ac3842484a6e059ed done\n",
      "#16 exporting config sha256:6cdea50980cf0d52776cf2b99cb1cef133d8f5e547b068bbb2a91e4b5cd479b9 done\n",
      "#16 exporting attestation manifest sha256:4e44af354bfdf450287ec59c7c77c90280c825f2fd13d46aef6e516a53b62723 done\n",
      "#16 exporting manifest list sha256:8263575aee1fcd70de5aecb1742c0990e895922d9b7131089dc434949ef627b7 done\n",
      "#16 naming to docker.io/library/pytorch-training:latest done\n",
      "#16 unpacking to docker.io/library/pytorch-training:latest\n",
      "#16 unpacking to docker.io/library/pytorch-training:latest 1.4s done\n",
      "#16 DONE 9.7s\n",
      "\n",
      "View build details: docker-desktop://dashboard/build/desktop-linux/desktop-linux/jy2ggsjfd7xnnzuqszupo7i3y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [783764619792.dkr.ecr.us-east-1.amazonaws.com/pytorch-training]\n",
      "5bc37799e39a: Waiting\n",
      "3534b7fdf5f7: Waiting\n",
      "24ff69e0a1e4: Waiting\n",
      "596fc4dee4de: Waiting\n",
      "974568495310: Waiting\n",
      "1b24adeb3c1b: Waiting\n",
      "ddf22c091a66: Waiting\n",
      "ee8d87462526: Waiting\n",
      "813af4514c4b: Waiting\n",
      "2518b52d49b6: Waiting\n",
      "9fc2b73e5eeb: Waiting\n",
      "76a627ca5e65: Waiting\n",
      "ae33dbb3a55f: Waiting\n",
      "aa3219d64781: Waiting\n",
      "03dd81e371d6: Waiting\n",
      "355e2d5e2f80: Waiting\n",
      "eb7bf46d7693: Waiting\n",
      "c696bac94bf0: Waiting\n",
      "23c4f519318b: Waiting\n",
      "112feee19fa1: Waiting\n",
      "7ccec220b45e: Waiting\n",
      "f146897276ef: Waiting\n",
      "15d7ad785fe7: Waiting\n",
      "c79e9e16e5ac: Waiting\n",
      "3805d1ba40b2: Waiting\n",
      "2e1d0bd18d40: Waiting\n",
      "7a2c55901189: Waiting\n",
      "9d193d3dd589: Waiting\n",
      "67a3cf0e06d5: Waiting\n",
      "ac82fa248a4e: Waiting\n",
      "b4f9cb2f5eba: Waiting\n",
      "a0fe6398ac18: Waiting\n",
      "46db5d6dd998: Waiting\n",
      "359b8c3abf87: Waiting\n",
      "59c5e12f7b5e: Waiting\n",
      "e2c3b6c30e8d: Waiting\n",
      "7faa1993c119: Waiting\n",
      "387d044338c6: Waiting\n",
      "c003784c15fd: Waiting\n",
      "5d14d2bf9f54: Waiting\n",
      "755e535b54a3: Waiting\n",
      "35817692a87e: Waiting\n",
      "08c4e79e2898: Waiting\n",
      "3fb0f0bca4d3: Waiting\n",
      "ac88fda452e6: Waiting\n",
      "3f0574de871c: Waiting\n",
      "d448504d6345: Waiting\n",
      "6f912ec81d7d: Waiting\n",
      "3ec7192813a4: Waiting\n",
      "390a39c6c862: Waiting\n",
      "43c63a98b55f: Waiting\n",
      "c55a860736a9: Waiting\n",
      "f242dee616b8: Waiting\n",
      "387d044338c6: Waiting\n",
      "c003784c15fd: Waiting\n",
      "e2c3b6c30e8d: Waiting\n",
      "7faa1993c119: Waiting\n",
      "35817692a87e: Waiting\n",
      "08c4e79e2898: Waiting\n",
      "3fb0f0bca4d3: Waiting\n",
      "ac88fda452e6: Waiting\n",
      "5d14d2bf9f54: Waiting\n",
      "755e535b54a3: Waiting\n",
      "3f0574de871c: Waiting\n",
      "d448504d6345: Waiting\n",
      "6f912ec81d7d: Waiting\n",
      "3ec7192813a4: Waiting\n",
      "f242dee616b8: Waiting\n",
      "390a39c6c862: Waiting\n",
      "43c63a98b55f: Waiting\n",
      "c55a860736a9: Waiting\n",
      "5bc37799e39a: Waiting\n",
      "3534b7fdf5f7: Waiting\n",
      "1b24adeb3c1b: Waiting\n",
      "ddf22c091a66: Waiting\n",
      "ee8d87462526: Waiting\n",
      "813af4514c4b: Waiting\n",
      "24ff69e0a1e4: Waiting\n",
      "596fc4dee4de: Waiting\n",
      "974568495310: Waiting\n",
      "9fc2b73e5eeb: Waiting\n",
      "2518b52d49b6: Waiting\n",
      "aa3219d64781: Waiting\n",
      "76a627ca5e65: Waiting\n",
      "ae33dbb3a55f: Waiting\n",
      "355e2d5e2f80: Waiting\n",
      "eb7bf46d7693: Waiting\n",
      "c696bac94bf0: Waiting\n",
      "03dd81e371d6: Waiting\n",
      "23c4f519318b: Waiting\n",
      "7ccec220b45e: Waiting\n",
      "112feee19fa1: Waiting\n",
      "f146897276ef: Waiting\n",
      "15d7ad785fe7: Waiting\n",
      "c79e9e16e5ac: Waiting\n",
      "2e1d0bd18d40: Waiting\n",
      "3805d1ba40b2: Waiting\n",
      "ac82fa248a4e: Waiting\n",
      "b4f9cb2f5eba: Waiting\n",
      "7a2c55901189: Waiting\n",
      "9d193d3dd589: Waiting\n",
      "67a3cf0e06d5: Waiting\n",
      "a0fe6398ac18: Waiting\n",
      "46db5d6dd998: Waiting\n",
      "59c5e12f7b5e: Waiting\n",
      "359b8c3abf87: Waiting\n",
      "59c5e12f7b5e: Waiting\n",
      "359b8c3abf87: Waiting\n",
      "387d044338c6: Waiting\n",
      "c003784c15fd: Waiting\n",
      "e2c3b6c30e8d: Waiting\n",
      "7faa1993c119: Waiting\n",
      "35817692a87e: Waiting\n",
      "08c4e79e2898: Waiting\n",
      "3fb0f0bca4d3: Waiting\n",
      "ac88fda452e6: Waiting\n",
      "5d14d2bf9f54: Waiting\n",
      "755e535b54a3: Waiting\n",
      "3f0574de871c: Waiting\n",
      "d448504d6345: Waiting\n",
      "6f912ec81d7d: Waiting\n",
      "3ec7192813a4: Waiting\n",
      "f242dee616b8: Waiting\n",
      "390a39c6c862: Waiting\n",
      "43c63a98b55f: Waiting\n",
      "c55a860736a9: Waiting\n",
      "5bc37799e39a: Waiting\n",
      "3534b7fdf5f7: Waiting\n",
      "1b24adeb3c1b: Waiting\n",
      "ddf22c091a66: Waiting\n",
      "ee8d87462526: Waiting\n",
      "813af4514c4b: Waiting\n",
      "24ff69e0a1e4: Waiting\n",
      "596fc4dee4de: Waiting\n",
      "974568495310: Waiting\n",
      "9fc2b73e5eeb: Waiting\n",
      "2518b52d49b6: Waiting\n",
      "aa3219d64781: Waiting\n",
      "76a627ca5e65: Waiting\n",
      "ae33dbb3a55f: Waiting\n",
      "355e2d5e2f80: Waiting\n",
      "eb7bf46d7693: Waiting\n",
      "c696bac94bf0: Waiting\n",
      "03dd81e371d6: Waiting\n",
      "23c4f519318b: Waiting\n",
      "7ccec220b45e: Waiting\n",
      "112feee19fa1: Waiting\n",
      "f146897276ef: Waiting\n",
      "15d7ad785fe7: Waiting\n",
      "c79e9e16e5ac: Waiting\n",
      "2e1d0bd18d40: Waiting\n",
      "3805d1ba40b2: Waiting\n",
      "ac82fa248a4e: Waiting\n",
      "b4f9cb2f5eba: Waiting\n",
      "7a2c55901189: Waiting\n",
      "9d193d3dd589: Waiting\n",
      "67a3cf0e06d5: Waiting\n",
      "a0fe6398ac18: Waiting\n",
      "46db5d6dd998: Waiting\n",
      "15d7ad785fe7: Waiting\n",
      "c79e9e16e5ac: Waiting\n",
      "3805d1ba40b2: Waiting\n",
      "2e1d0bd18d40: Waiting\n",
      "7a2c55901189: Waiting\n",
      "9d193d3dd589: Waiting\n",
      "67a3cf0e06d5: Waiting\n",
      "ac82fa248a4e: Waiting\n",
      "b4f9cb2f5eba: Waiting\n",
      "a0fe6398ac18: Waiting\n",
      "46db5d6dd998: Waiting\n",
      "359b8c3abf87: Waiting\n",
      "59c5e12f7b5e: Waiting\n",
      "e2c3b6c30e8d: Waiting\n",
      "7faa1993c119: Waiting\n",
      "387d044338c6: Waiting\n",
      "c003784c15fd: Waiting\n",
      "5d14d2bf9f54: Waiting\n",
      "755e535b54a3: Waiting\n",
      "35817692a87e: Waiting\n",
      "08c4e79e2898: Waiting\n",
      "3fb0f0bca4d3: Waiting\n",
      "ac88fda452e6: Waiting\n",
      "3f0574de871c: Waiting\n",
      "d448504d6345: Waiting\n",
      "6f912ec81d7d: Waiting\n",
      "3ec7192813a4: Waiting\n",
      "390a39c6c862: Waiting\n",
      "43c63a98b55f: Waiting\n",
      "c55a860736a9: Waiting\n",
      "f242dee616b8: Waiting\n",
      "5bc37799e39a: Waiting\n",
      "3534b7fdf5f7: Waiting\n",
      "24ff69e0a1e4: Waiting\n",
      "596fc4dee4de: Waiting\n",
      "974568495310: Waiting\n",
      "1b24adeb3c1b: Waiting\n",
      "ddf22c091a66: Waiting\n",
      "ee8d87462526: Waiting\n",
      "813af4514c4b: Waiting\n",
      "2518b52d49b6: Waiting\n",
      "9fc2b73e5eeb: Waiting\n",
      "76a627ca5e65: Waiting\n",
      "ae33dbb3a55f: Waiting\n",
      "aa3219d64781: Waiting\n",
      "c696bac94bf0: Waiting\n",
      "03dd81e371d6: Waiting\n",
      "355e2d5e2f80: Waiting\n",
      "eb7bf46d7693: Waiting\n",
      "23c4f519318b: Waiting\n",
      "7ccec220b45e: Waiting\n",
      "112feee19fa1: Waiting\n",
      "f146897276ef: Waiting\n",
      "359b8c3abf87: Waiting\n",
      "59c5e12f7b5e: Waiting\n",
      "e2c3b6c30e8d: Waiting\n",
      "7faa1993c119: Waiting\n",
      "387d044338c6: Waiting\n",
      "c003784c15fd: Waiting\n",
      "5d14d2bf9f54: Waiting\n",
      "755e535b54a3: Waiting\n",
      "35817692a87e: Waiting\n",
      "08c4e79e2898: Waiting\n",
      "3fb0f0bca4d3: Waiting\n",
      "ac88fda452e6: Waiting\n",
      "3f0574de871c: Waiting\n",
      "d448504d6345: Waiting\n",
      "6f912ec81d7d: Waiting\n",
      "3ec7192813a4: Waiting\n",
      "390a39c6c862: Waiting\n",
      "43c63a98b55f: Waiting\n",
      "c55a860736a9: Waiting\n",
      "f242dee616b8: Waiting\n",
      "5bc37799e39a: Waiting\n",
      "3534b7fdf5f7: Waiting\n",
      "24ff69e0a1e4: Waiting\n",
      "596fc4dee4de: Waiting\n",
      "974568495310: Waiting\n",
      "1b24adeb3c1b: Waiting\n",
      "ddf22c091a66: Waiting\n",
      "ee8d87462526: Waiting\n",
      "813af4514c4b: Waiting\n",
      "2518b52d49b6: Waiting\n",
      "9fc2b73e5eeb: Waiting\n",
      "76a627ca5e65: Waiting\n",
      "ae33dbb3a55f: Waiting\n",
      "aa3219d64781: Waiting\n",
      "c696bac94bf0: Waiting\n",
      "03dd81e371d6: Waiting\n",
      "355e2d5e2f80: Waiting\n",
      "eb7bf46d7693: Waiting\n",
      "23c4f519318b: Waiting\n",
      "7ccec220b45e: Waiting\n",
      "112feee19fa1: Waiting\n",
      "f146897276ef: Waiting\n",
      "15d7ad785fe7: Waiting\n",
      "c79e9e16e5ac: Waiting\n",
      "3805d1ba40b2: Waiting\n",
      "2e1d0bd18d40: Waiting\n",
      "7a2c55901189: Waiting\n",
      "9d193d3dd589: Waiting\n",
      "67a3cf0e06d5: Waiting\n",
      "ac82fa248a4e: Waiting\n",
      "b4f9cb2f5eba: Waiting\n",
      "a0fe6398ac18: Waiting\n",
      "46db5d6dd998: Waiting\n",
      "813af4514c4b: Waiting\n",
      "24ff69e0a1e4: Waiting\n",
      "596fc4dee4de: Waiting\n",
      "974568495310: Waiting\n",
      "1b24adeb3c1b: Waiting\n",
      "ddf22c091a66: Waiting\n",
      "ee8d87462526: Waiting\n",
      "2518b52d49b6: Waiting\n",
      "9fc2b73e5eeb: Waiting\n",
      "76a627ca5e65: Waiting\n",
      "ae33dbb3a55f: Waiting\n",
      "aa3219d64781: Waiting\n",
      "eb7bf46d7693: Waiting\n",
      "c696bac94bf0: Waiting\n",
      "03dd81e371d6: Waiting\n",
      "355e2d5e2f80: Waiting\n",
      "23c4f519318b: Waiting\n",
      "7ccec220b45e: Waiting\n",
      "112feee19fa1: Waiting\n",
      "f146897276ef: Waiting\n",
      "15d7ad785fe7: Waiting\n",
      "c79e9e16e5ac: Waiting\n",
      "3805d1ba40b2: Waiting\n",
      "2e1d0bd18d40: Waiting\n",
      "7a2c55901189: Waiting\n",
      "9d193d3dd589: Waiting\n",
      "67a3cf0e06d5: Waiting\n",
      "ac82fa248a4e: Waiting\n",
      "b4f9cb2f5eba: Waiting\n",
      "a0fe6398ac18: Waiting\n",
      "46db5d6dd998: Waiting\n",
      "359b8c3abf87: Waiting\n",
      "59c5e12f7b5e: Waiting\n",
      "e2c3b6c30e8d: Waiting\n",
      "7faa1993c119: Waiting\n",
      "387d044338c6: Waiting\n",
      "c003784c15fd: Waiting\n",
      "ac88fda452e6: Waiting\n",
      "5d14d2bf9f54: Waiting\n",
      "755e535b54a3: Waiting\n",
      "35817692a87e: Waiting\n",
      "08c4e79e2898: Waiting\n",
      "3fb0f0bca4d3: Waiting\n",
      "3f0574de871c: Waiting\n",
      "d448504d6345: Waiting\n",
      "6f912ec81d7d: Waiting\n",
      "3ec7192813a4: Waiting\n",
      "390a39c6c862: Waiting\n",
      "43c63a98b55f: Waiting\n",
      "c55a860736a9: Waiting\n",
      "f242dee616b8: Waiting\n",
      "5bc37799e39a: Waiting\n",
      "3534b7fdf5f7: Waiting\n",
      "15d7ad785fe7: Waiting\n",
      "c79e9e16e5ac: Waiting\n",
      "3805d1ba40b2: Waiting\n",
      "2e1d0bd18d40: Waiting\n",
      "7a2c55901189: Waiting\n",
      "9d193d3dd589: Waiting\n",
      "67a3cf0e06d5: Waiting\n",
      "ac82fa248a4e: Waiting\n",
      "b4f9cb2f5eba: Waiting\n",
      "a0fe6398ac18: Waiting\n",
      "46db5d6dd998: Waiting\n",
      "359b8c3abf87: Waiting\n",
      "59c5e12f7b5e: Waiting\n",
      "e2c3b6c30e8d: Waiting\n",
      "7faa1993c119: Waiting\n",
      "387d044338c6: Waiting\n",
      "c003784c15fd: Waiting\n",
      "5d14d2bf9f54: Waiting\n",
      "755e535b54a3: Waiting\n",
      "35817692a87e: Waiting\n",
      "08c4e79e2898: Waiting\n",
      "3fb0f0bca4d3: Waiting\n",
      "ac88fda452e6: Waiting\n",
      "3f0574de871c: Waiting\n",
      "d448504d6345: Waiting\n",
      "6f912ec81d7d: Waiting\n",
      "3ec7192813a4: Waiting\n",
      "390a39c6c862: Waiting\n",
      "43c63a98b55f: Waiting\n",
      "c55a860736a9: Waiting\n",
      "f242dee616b8: Waiting\n",
      "5bc37799e39a: Waiting\n",
      "3534b7fdf5f7: Waiting\n",
      "24ff69e0a1e4: Waiting\n",
      "596fc4dee4de: Waiting\n",
      "974568495310: Waiting\n",
      "1b24adeb3c1b: Waiting\n",
      "ddf22c091a66: Waiting\n",
      "ee8d87462526: Waiting\n",
      "813af4514c4b: Waiting\n",
      "2518b52d49b6: Waiting\n",
      "9fc2b73e5eeb: Waiting\n",
      "76a627ca5e65: Waiting\n",
      "ae33dbb3a55f: Waiting\n",
      "aa3219d64781: Waiting\n",
      "03dd81e371d6: Waiting\n",
      "355e2d5e2f80: Waiting\n",
      "eb7bf46d7693: Waiting\n",
      "c696bac94bf0: Waiting\n",
      "23c4f519318b: Waiting\n",
      "112feee19fa1: Waiting\n",
      "7ccec220b45e: Waiting\n",
      "f146897276ef: Waiting\n",
      "3ec7192813a4: Waiting\n",
      "c55a860736a9: Waiting\n",
      "f242dee616b8: Waiting\n",
      "390a39c6c862: Waiting\n",
      "43c63a98b55f: Waiting\n",
      "3534b7fdf5f7: Waiting\n",
      "5bc37799e39a: Waiting\n",
      "974568495310: Waiting\n",
      "1b24adeb3c1b: Waiting\n",
      "ddf22c091a66: Waiting\n",
      "ee8d87462526: Waiting\n",
      "813af4514c4b: Waiting\n",
      "24ff69e0a1e4: Waiting\n",
      "596fc4dee4de: Waiting\n",
      "9fc2b73e5eeb: Waiting\n",
      "2518b52d49b6: Waiting\n",
      "ae33dbb3a55f: Waiting\n",
      "aa3219d64781: Waiting\n",
      "76a627ca5e65: Waiting\n",
      "355e2d5e2f80: Waiting\n",
      "eb7bf46d7693: Waiting\n",
      "c696bac94bf0: Waiting\n",
      "03dd81e371d6: Waiting\n",
      "23c4f519318b: Waiting\n",
      "112feee19fa1: Waiting\n",
      "7ccec220b45e: Waiting\n",
      "f146897276ef: Waiting\n",
      "15d7ad785fe7: Waiting\n",
      "c79e9e16e5ac: Waiting\n",
      "2e1d0bd18d40: Waiting\n",
      "3805d1ba40b2: Waiting\n",
      "67a3cf0e06d5: Waiting\n",
      "ac82fa248a4e: Waiting\n",
      "b4f9cb2f5eba: Waiting\n",
      "7a2c55901189: Waiting\n",
      "9d193d3dd589: Waiting\n",
      "46db5d6dd998: Waiting\n",
      "a0fe6398ac18: Waiting\n",
      "59c5e12f7b5e: Waiting\n",
      "359b8c3abf87: Waiting\n",
      "7faa1993c119: Waiting\n",
      "387d044338c6: Waiting\n",
      "c003784c15fd: Waiting\n",
      "e2c3b6c30e8d: Waiting\n",
      "35817692a87e: Waiting\n",
      "08c4e79e2898: Waiting\n",
      "3fb0f0bca4d3: Waiting\n",
      "ac88fda452e6: Waiting\n",
      "5d14d2bf9f54: Waiting\n",
      "755e535b54a3: Waiting\n",
      "6f912ec81d7d: Waiting\n",
      "3f0574de871c: Waiting\n",
      "d448504d6345: Waiting\n",
      "1b24adeb3c1b: Waiting\n",
      "ddf22c091a66: Waiting\n",
      "ee8d87462526: Waiting\n",
      "813af4514c4b: Waiting\n",
      "24ff69e0a1e4: Waiting\n",
      "596fc4dee4de: Waiting\n",
      "974568495310: Waiting\n",
      "9fc2b73e5eeb: Waiting\n",
      "2518b52d49b6: Waiting\n",
      "aa3219d64781: Waiting\n",
      "76a627ca5e65: Waiting\n",
      "ae33dbb3a55f: Waiting\n",
      "355e2d5e2f80: Waiting\n",
      "eb7bf46d7693: Waiting\n",
      "c696bac94bf0: Waiting\n",
      "03dd81e371d6: Waiting\n",
      "23c4f519318b: Waiting\n",
      "7ccec220b45e: Waiting\n",
      "112feee19fa1: Waiting\n",
      "f146897276ef: Waiting\n",
      "15d7ad785fe7: Waiting\n",
      "c79e9e16e5ac: Waiting\n",
      "2e1d0bd18d40: Waiting\n",
      "3805d1ba40b2: Waiting\n",
      "ac82fa248a4e: Waiting\n",
      "b4f9cb2f5eba: Waiting\n",
      "7a2c55901189: Waiting\n",
      "9d193d3dd589: Waiting\n",
      "67a3cf0e06d5: Waiting\n",
      "a0fe6398ac18: Waiting\n",
      "46db5d6dd998: Waiting\n",
      "59c5e12f7b5e: Waiting\n",
      "359b8c3abf87: Waiting\n",
      "387d044338c6: Waiting\n",
      "c003784c15fd: Waiting\n",
      "e2c3b6c30e8d: Waiting\n",
      "7faa1993c119: Waiting\n",
      "35817692a87e: Waiting\n",
      "08c4e79e2898: Waiting\n",
      "3fb0f0bca4d3: Waiting\n",
      "ac88fda452e6: Waiting\n",
      "5d14d2bf9f54: Waiting\n",
      "755e535b54a3: Waiting\n",
      "3f0574de871c: Waiting\n",
      "d448504d6345: Waiting\n",
      "6f912ec81d7d: Waiting\n",
      "3ec7192813a4: Waiting\n",
      "f242dee616b8: Waiting\n",
      "390a39c6c862: Waiting\n",
      "43c63a98b55f: Waiting\n",
      "c55a860736a9: Waiting\n",
      "5bc37799e39a: Waiting\n",
      "3534b7fdf5f7: Waiting\n",
      "3ec7192813a4: Waiting\n",
      "43c63a98b55f: Layer already exists\n",
      "c55a860736a9: Layer already exists\n",
      "f242dee616b8: Waiting\n",
      "390a39c6c862: Layer already exists\n",
      "3534b7fdf5f7: Layer already exists\n",
      "5bc37799e39a: Layer already exists\n",
      "596fc4dee4de: Layer already exists\n",
      "974568495310: Waiting\n",
      "1b24adeb3c1b: Layer already exists\n",
      "ddf22c091a66: Layer already exists\n",
      "ee8d87462526: Layer already exists\n",
      "813af4514c4b: Waiting\n",
      "24ff69e0a1e4: Layer already exists\n",
      "9fc2b73e5eeb: Layer already exists\n",
      "2518b52d49b6: Waiting\n",
      "ae33dbb3a55f: Layer already exists\n",
      "aa3219d64781: Layer already exists\n",
      "76a627ca5e65: Waiting\n",
      "355e2d5e2f80: Layer already exists\n",
      "eb7bf46d7693: Waiting\n",
      "c696bac94bf0: Layer already exists\n",
      "03dd81e371d6: Waiting\n",
      "23c4f519318b: Waiting\n",
      "112feee19fa1: Waiting\n",
      "7ccec220b45e: Layer already exists\n",
      "f146897276ef: Layer already exists\n",
      "c79e9e16e5ac: Layer already exists\n",
      "15d7ad785fe7: Waiting\n",
      "3805d1ba40b2: Layer already exists\n",
      "2e1d0bd18d40: Waiting\n",
      "9d193d3dd589: Layer already exists\n",
      "67a3cf0e06d5: Layer already exists\n",
      "ac82fa248a4e: Waiting\n",
      "b4f9cb2f5eba: Layer already exists\n",
      "7a2c55901189: Waiting\n",
      "a0fe6398ac18: Waiting\n",
      "46db5d6dd998: Layer already exists\n",
      "359b8c3abf87: Waiting\n",
      "59c5e12f7b5e: Waiting\n",
      "e2c3b6c30e8d: Layer already exists\n",
      "7faa1993c119: Layer already exists\n",
      "387d044338c6: Layer already exists\n",
      "c003784c15fd: Layer already exists\n",
      "755e535b54a3: Layer already exists\n",
      "35817692a87e: Layer already exists\n",
      "08c4e79e2898: Layer already exists\n",
      "3fb0f0bca4d3: Waiting\n",
      "ac88fda452e6: Layer already exists\n",
      "5d14d2bf9f54: Waiting\n",
      "d448504d6345: Waiting\n",
      "6f912ec81d7d: Waiting\n",
      "3f0574de871c: Waiting\n",
      "359b8c3abf87: Layer already exists\n",
      "59c5e12f7b5e: Waiting\n",
      "3fb0f0bca4d3: Layer already exists\n",
      "3f0574de871c: Waiting\n",
      "d448504d6345: Waiting\n",
      "5d14d2bf9f54: Waiting\n",
      "6f912ec81d7d: Waiting\n",
      "3ec7192813a4: Waiting\n",
      "f242dee616b8: Waiting\n",
      "813af4514c4b: Waiting\n",
      "974568495310: Layer already exists\n",
      "2518b52d49b6: Waiting\n",
      "76a627ca5e65: Waiting\n",
      "23c4f519318b: Layer already exists\n",
      "03dd81e371d6: Waiting\n",
      "eb7bf46d7693: Layer already exists\n",
      "112feee19fa1: Layer already exists\n",
      "15d7ad785fe7: Waiting\n",
      "2e1d0bd18d40: Waiting\n",
      "7a2c55901189: Layer already exists\n",
      "ac82fa248a4e: Layer already exists\n",
      "a0fe6398ac18: Waiting\n",
      "813af4514c4b: Waiting\n",
      "2518b52d49b6: Layer already exists\n",
      "76a627ca5e65: Layer already exists\n",
      "03dd81e371d6: Waiting\n",
      "15d7ad785fe7: Layer already exists\n",
      "2e1d0bd18d40: Waiting\n",
      "a0fe6398ac18: Waiting\n",
      "59c5e12f7b5e: Layer already exists\n",
      "5d14d2bf9f54: Waiting\n",
      "3f0574de871c: Waiting\n",
      "d448504d6345: Layer already exists\n",
      "6f912ec81d7d: Waiting\n",
      "813af4514c4b: Waiting\n",
      "5d14d2bf9f54: Pushed\n",
      "3ec7192813a4: Pushed\n",
      "3f0574de871c: Pushed\n",
      "a0fe6398ac18: Pushed\n",
      "6f912ec81d7d: Pushed\n",
      "03dd81e371d6: Pushed\n",
      "2e1d0bd18d40: Pushed\n",
      "813af4514c4b: Pushed\n",
      "f242dee616b8: Pushed\n",
      "latest: digest: sha256:8263575aee1fcd70de5aecb1742c0990e895922d9b7131089dc434949ef627b7 size: 1609\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=pytorch-training\n",
    "\n",
    "cd 'docker'\n",
    "\n",
    "#account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "#region=${region:-us-east-1}\n",
    "\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "#login to public sagemaker repo to get container\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 783764619792.dkr.ecr.us-east-1.amazonaws.com\n",
    "\n",
    "export DOCKER_BUILDKIT=1\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -f Dockerfile -t pytorch-training . --platform 'linux/amd64,linux/arm64'\n",
    "docker tag pytorch-training 783764619792.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:latest\n",
    "docker push 783764619792.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/megatron-lm'\n",
    "\n",
    "#role = sagemaker.get_execution_role()\n",
    "role = \"arn:aws:iam::783764619792:role/Sagemaker_execution_role\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.240.0'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python Megatron-LM/tools/preprocess_data.py \\\n",
    "       --input codeparrot_data.json \\\n",
    "       --output-prefix tiktok_codeparrot \\\n",
    "       --tokenizer-type TikTokenizer \\\n",
    "       --tiktoken-pattern v2 \\\n",
    "       --tokenizer-model list_vocab.json \\\n",
    "       --merge-file merges.txt \\\n",
    "       --json-keys content \\\n",
    "       --workers 32 \\\n",
    "       --append-eod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Putting /Users/minsup/Documents/lion/Megatron/codeparrot_content_document.bin as qwen_codeparrot_content_document.bin\n",
      "Putting /Users/minsup/Documents/lion/Megatron/codeparrot_content_document.idx as qwen_codeparrot_content_document.idx\n",
      "All_Done\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "BUCKET_NAME = 'code-parrot-sample-data'\n",
    "\n",
    "session = boto3.Session()\n",
    "s3 = session.client('s3')\n",
    "\n",
    "filename = os.getcwd()+\"/codeparrot_content_document.bin\"\n",
    "key = \"qwen_codeparrot_content_document.bin\"\n",
    "print(\"Putting %s as %s\" % (filename,key))\n",
    "s3.upload_file(filename, BUCKET_NAME, key)\n",
    "\n",
    "filename = os.getcwd()+\"/codeparrot_content_document.idx\"\n",
    "key = \"qwen_codeparrot_content_document.idx\"\n",
    "print(\"Putting %s as %s\" % (filename,key))\n",
    "s3.upload_file(filename, BUCKET_NAME, key)\n",
    "\n",
    "print(\"All_Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:   2%|▋                           | 1/43 [06:23<4:28:19, 383.32s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/model-00004-of-00004.safetensors -> s3://code-parrot-sample-data/model-00004-of-00004.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:   5%|█▎                          | 2/43 [13:04<4:29:10, 393.91s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/model-00001-of-00004.safetensors -> s3://code-parrot-sample-data/model-00001-of-00004.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:   7%|█▉                          | 3/43 [13:04<2:22:47, 214.20s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/LICENSE -> s3://code-parrot-sample-data/LICENSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:   9%|██▌                         | 4/43 [13:05<1:24:21, 129.78s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/tokenizer_config.json -> s3://code-parrot-sample-data/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  12%|███▌                           | 5/43 [13:05<52:38, 83.11s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/config.json -> s3://code-parrot-sample-data/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  14%|████▎                          | 6/43 [13:11<35:03, 56.84s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/tokenizer.json -> s3://code-parrot-sample-data/tokenizer.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  16%|█████                          | 7/43 [13:11<23:01, 38.38s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/generation_config.json -> s3://code-parrot-sample-data/generation_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  19%|█████▊                         | 8/43 [13:12<15:19, 26.27s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/README.md -> s3://code-parrot-sample-data/README.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  21%|██████▍                        | 9/43 [13:14<10:32, 18.60s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/merges.txt -> s3://code-parrot-sample-data/merges.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  23%|██████▎                    | 10/43 [19:50<1:14:26, 135.36s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/model-00003-of-00004.safetensors -> s3://code-parrot-sample-data/model-00003-of-00004.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  26%|███████▋                      | 11/43 [19:51<50:09, 94.04s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.gitattributes -> s3://code-parrot-sample-data/.gitattributes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  28%|████████▎                     | 12/43 [19:53<34:12, 66.20s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/vocab.json -> s3://code-parrot-sample-data/vocab.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  30%|█████████                     | 13/43 [19:54<23:07, 46.26s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/model.safetensors.index.json -> s3://code-parrot-sample-data/model.safetensors.index.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  33%|████████▊                  | 14/43 [26:35<1:14:10, 153.47s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/model-00002-of-00004.safetensors -> s3://code-parrot-sample-data/model-00002-of-00004.safetensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  35%|██████████                   | 15/43 [26:35<50:04, 107.31s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/.gitignore -> s3://code-parrot-sample-data/.cache/huggingface/.gitignore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  37%|███████████▏                  | 16/43 [26:35<33:48, 75.12s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/model.safetensors.index.json.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/model.safetensors.index.json.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  40%|███████████▊                  | 17/43 [26:36<22:48, 52.63s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/.gitattributes.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/.gitattributes.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  42%|████████████▌                 | 18/43 [26:36<15:23, 36.92s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/model.safetensors.index.json.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/model.safetensors.index.json.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  44%|█████████████▎                | 19/43 [26:37<10:22, 25.94s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/vocab.json.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/vocab.json.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  47%|█████████████▉                | 20/43 [26:37<06:59, 18.26s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/tokenizer.json.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/tokenizer.json.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  49%|██████████████▋               | 21/43 [26:37<04:43, 12.88s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/merges.txt.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/merges.txt.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  51%|███████████████▎              | 22/43 [26:38<03:11,  9.12s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/tokenizer_config.json.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/tokenizer_config.json.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  53%|████████████████              | 23/43 [26:38<02:09,  6.49s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/model-00002-of-00004.safetensors.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/model-00002-of-00004.safetensors.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  56%|████████████████▋             | 24/43 [26:38<01:28,  4.64s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/tokenizer_config.json.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/tokenizer_config.json.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  58%|█████████████████▍            | 25/43 [26:39<01:00,  3.35s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/LICENSE.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/LICENSE.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  60%|██████████████████▏           | 26/43 [26:39<00:41,  2.45s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/model-00004-of-00004.safetensors.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/model-00004-of-00004.safetensors.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  63%|██████████████████▊           | 27/43 [26:39<00:29,  1.82s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/model-00002-of-00004.safetensors.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/model-00002-of-00004.safetensors.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  65%|███████████████████▌          | 28/43 [26:40<00:20,  1.37s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/config.json.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/config.json.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  67%|████████████████████▏         | 29/43 [26:40<00:14,  1.06s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/config.json.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/config.json.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  70%|████████████████████▉         | 30/43 [26:40<00:10,  1.18file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/merges.txt.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/merges.txt.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  72%|█████████████████████▋        | 31/43 [26:41<00:08,  1.44file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/model-00003-of-00004.safetensors.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/model-00003-of-00004.safetensors.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  74%|██████████████████████▎       | 32/43 [26:41<00:06,  1.69file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/generation_config.json.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/generation_config.json.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  77%|███████████████████████       | 33/43 [26:41<00:05,  1.94file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/tokenizer.json.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/tokenizer.json.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  79%|███████████████████████▋      | 34/43 [26:42<00:04,  2.15file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/model-00004-of-00004.safetensors.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/model-00004-of-00004.safetensors.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  81%|████████████████████████▍     | 35/43 [26:42<00:03,  2.33file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/.gitattributes.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/.gitattributes.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  84%|█████████████████████████     | 36/43 [26:42<00:02,  2.47file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/generation_config.json.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/generation_config.json.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  86%|█████████████████████████▊    | 37/43 [26:43<00:02,  2.58file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/model-00003-of-00004.safetensors.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/model-00003-of-00004.safetensors.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  88%|██████████████████████████▌   | 38/43 [26:43<00:01,  2.68file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/LICENSE.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/LICENSE.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  91%|███████████████████████████▏  | 39/43 [26:43<00:01,  2.72file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/model-00001-of-00004.safetensors.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/model-00001-of-00004.safetensors.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  93%|███████████████████████████▉  | 40/43 [26:44<00:01,  2.77file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/vocab.json.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/vocab.json.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  95%|████████████████████████████▌ | 41/43 [26:44<00:00,  2.80file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/README.md.metadata -> s3://code-parrot-sample-data/.cache/huggingface/download/README.md.metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  98%|█████████████████████████████▎| 42/43 [26:44<00:00,  2.84file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/README.md.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/README.md.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████████████████████████| 43/43 [26:45<00:00, 37.33s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen2.5-7B/.cache/huggingface/download/model-00001-of-00004.safetensors.lock -> s3://code-parrot-sample-data/.cache/huggingface/download/model-00001-of-00004.safetensors.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "from tqdm import tqdm\n",
    "\n",
    "BUCKET_NAME = 'code-parrot-sample-data'\n",
    "def upload_folder_to_s3(local_folder, bucket_name, s3_folder=\"\"):\n",
    "    \"\"\"\n",
    "    Uploads a folder and all its contents to an S3 bucket with a progress bar.\n",
    "    \n",
    "    :param local_folder: Path to the local folder to upload.\n",
    "    :param bucket_name: The target S3 bucket name.\n",
    "    :param s3_folder: The target folder in S3 (optional).\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # Collect all file paths\n",
    "    file_list = []\n",
    "    for root, _, files in os.walk(local_folder):\n",
    "        for file in files:\n",
    "            local_file_path = os.path.join(root, file)\n",
    "            file_list.append(local_file_path)\n",
    "\n",
    "    # Upload files with progress bar\n",
    "    with tqdm(total=len(file_list), desc=\"Uploading\", unit=\"file\") as pbar:\n",
    "        for local_file_path in file_list:\n",
    "            relative_path = os.path.relpath(local_file_path, local_folder)\n",
    "            s3_path = os.path.join(s3_folder, relative_path) if s3_folder else relative_path\n",
    "            s3_path = s3_path.replace(\"\\\\\", \"/\")  # Ensure S3 compatibility\n",
    "\n",
    "            s3_client.upload_file(local_file_path, bucket_name, s3_path)\n",
    "            pbar.update(1)  # Update progress bar\n",
    "            print(f\"Uploaded: {local_file_path} -> s3://{bucket_name}/{s3_path}\")\n",
    "\n",
    "# Example Usage\n",
    "upload_folder_to_s3(\"qwen2.5-7B\", BUCKET_NAME, \"qwen2.5-7B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading Tokenizer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/genai/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/anaconda3/envs/genai/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./qwen_tokenizer/tokenizer_config.json',\n",
       " './qwen_tokenizer/special_tokens_map.json',\n",
       " './qwen_tokenizer/vocab.json',\n",
       " './qwen_tokenizer/merges.txt',\n",
       " './qwen_tokenizer/added_tokens.json',\n",
       " './qwen_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B\")\n",
    "tokenizer.save_pretrained(\"./qwen_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  17%|█████                         | 1/6 [00:00<00:04,  1.19file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen_tokenizer/added_tokens.json -> s3://code-parrot-sample-data/megatron-qwen2.5-7B/release/mp_rank_00/added_tokens.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  33%|██████████                    | 2/6 [00:01<00:02,  1.54file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen_tokenizer/tokenizer_config.json -> s3://code-parrot-sample-data/megatron-qwen2.5-7B/release/mp_rank_00/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  50%|███████████████               | 3/6 [00:01<00:01,  1.94file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen_tokenizer/special_tokens_map.json -> s3://code-parrot-sample-data/megatron-qwen2.5-7B/release/mp_rank_00/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  67%|████████████████████          | 4/6 [00:11<00:08,  4.25s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen_tokenizer/tokenizer.json -> s3://code-parrot-sample-data/megatron-qwen2.5-7B/release/mp_rank_00/tokenizer.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading:  83%|█████████████████████████     | 5/6 [00:12<00:03,  3.05s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen_tokenizer/merges.txt -> s3://code-parrot-sample-data/megatron-qwen2.5-7B/release/mp_rank_00/merges.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100%|██████████████████████████████| 6/6 [00:13<00:00,  2.29s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: qwen_tokenizer/vocab.json -> s3://code-parrot-sample-data/megatron-qwen2.5-7B/release/mp_rank_00/vocab.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "upload_folder_to_s3(\"qwen_tokenizer\", BUCKET_NAME, \"megatron-qwen2.5-7B/release/mp_rank_00/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Putting /Users/minsup/Documents/lion/vocab.json as vocab.json\n",
      "Putting /Users/minsup/Documents/lion/merges.txt as merges.txt\n"
     ]
    }
   ],
   "source": [
    "filename = os.path.dirname(os.getcwd())+\"/vocab.json\"\n",
    "key = \"vocab.json\"\n",
    "print(\"Putting %s as %s\" % (filename,key))\n",
    "s3.upload_file(filename, BUCKET_NAME, key)\n",
    "\n",
    "filename = os.path.dirname(os.getcwd())+\"/merges.txt\"\n",
    "key = \"merges.txt\"\n",
    "print(\"Putting %s as %s\" % (filename,key))\n",
    "s3.upload_file(filename, BUCKET_NAME, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure FSx Input for your SageMaker Training job\n",
    "from sagemaker.inputs import FileSystemInput\n",
    "\n",
    "file_system_directory_path= '/wjk6tb4v' #\n",
    "file_system_id='fs-093b1c9f0849de55a'         # \n",
    "file_system_access_mode='rw'\n",
    "file_system_type='FSxLustre'\n",
    "train_fs=FileSystemInput(file_system_id=file_system_id,\n",
    "                         file_system_type=file_system_type,\n",
    "                         directory_path=file_system_directory_path,\n",
    "                         file_system_access_mode=file_system_access_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_hp = {\n",
    "    #\"load\": \"/opt/ml/input/data/dataset/dataset/qwen2.5-7B\",  # Source Hugging Face model path\n",
    "    \"load\": \"Qwen/Qwen2.5-7B\",\n",
    "    \"save\": \"/opt/ml/code/qwen2.5-7B-mcore\",  # Target Megatron-Core model path\n",
    "    \"tensor-model-parallel-size\": 1,  # Tensor Parallelism\n",
    "    \"pipeline-model-parallel-size\": 1,  # Pipeline Parallelism\n",
    "    \"micro-batch-size\": 1,\n",
    "    \"save-interval\": 1,\n",
    "    \"swiglu\": None,  # Flags don't take values, use None\n",
    "    \"num-layers\": 28,\n",
    "    \"hidden-size\": 3584,\n",
    "    \"ffn-hidden-size\": 18944,\n",
    "    \"num-attention-heads\": 28,\n",
    "    \"max-position-embeddings\": 131072,\n",
    "    \"seq-length\": 1,\n",
    "    \"patch-tokenizer-type\": \"Qwen2Tokenizer\",\n",
    "    \"extra-vocab-size\": 421,\n",
    "    \"normalization\": \"RMSNorm\",\n",
    "    \"attention-dropout\": 0.0,\n",
    "    \"hidden-dropout\": 0.0,\n",
    "    \"rotary-base\": 1000000,\n",
    "    \"transformer-impl\": \"transformer_engine\",  # Transformer Engine support\n",
    "    \"bf16\": None,  # Flags should not have values\n",
    "    \"intermediate-size\": 18944,\n",
    "    \"group-query-attention\": None,  # Flags should not have values\n",
    "    \"norm-epsilon\": 1e-6,\n",
    "    \"num-query-groups\": 4,\n",
    "    \"untie-embeddings-and-output-weights\": None,  # Flags should not have values\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training with Distributed Data Parallel\n",
    "\n",
    "\n",
    "The training script provides the code you need for distributed data parallel (DDP) training. The training script is very similar to a PyTorch training script you might run outside of SageMaker.\n",
    "\n",
    "In the following code block, you can update the estimator function to use a different instance type, instance count, and distrubtion strategy. You're also passing in the training script you reviewed in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hyperparameters for qwen 7B\n",
    "hyperparameters = {\n",
    "    # 'huggingface_model_name_or_path':'Qwen/Qwen2.5-7B',\n",
    "    # #'language-model':'Qwen/Qwen2.5-7B',\n",
    "    'load': '/opt/ml/input/data/dataset/dataset/megatron-qwen2.5-7B/release/mp_rank_00/',\n",
    "    'patch-tokenizer-type': 'Qwen2Tokenizer',\n",
    "    \"hidden-size\":3584,\n",
    "    \"num-layers\":28,\n",
    "    \"seq-length\": 4096, #determines the maximum length of sequences that your model can process in one forward pass (watch OOM)\n",
    "    \"intermediate-size\":18944,\n",
    "    \"max-position-embeddings\":131072,\n",
    "    \"num-query-groups\": 4,\n",
    "    \"group-query-attention\":None,\n",
    "    \"untie-embeddings-and-output-weights\":None,\n",
    "    \"num-attention-heads\":28,\n",
    "    \"norm-epsilon\":1e-6,\n",
    "    \"extra-vocab-size\":421,\n",
    "    'micro-batch-size': 1,\n",
    "    'global-batch-size': 64,\n",
    "    'lr': 0.0005,\n",
    "    'train-iters': 100000,\n",
    "    'lr-decay-iters': 10000,\n",
    "    'lr-decay-style': 'cosine',\n",
    "    'lr-warmup-iters': 1000,\n",
    "    'bf16' : None,\n",
    "    'log-interval': 10,\n",
    "    'save-interval': 2000,\n",
    "    'eval-interval': 200,\n",
    "    'eval-iters': 10,\n",
    "    'data-path':'/opt/ml/input/data/dataset/dataset/qwen_codeparrot_content_document',\n",
    "    'vocab-file':'/opt/ml/input/data/dataset/dataset/vocab.json',\n",
    "    'merge-file':'/opt/ml/input/data/dataset/dataset/merges.txt',\n",
    "    'save' : '/opt/ml/model/',\n",
    "    'tensor-model-parallel-size' : 2,\n",
    "    'pipeline-model-parallel-size' : 1,\n",
    "    'context-parallel-size' : 1,\n",
    "    'weight-decay': 0.1,\n",
    "    'adam-beta1': 0.9,\n",
    "    'adam-beta2': 0.95,\n",
    "    'clip-grad': 1.0,\n",
    "    'init-method-std': 0.008,\n",
    "    'attention-dropout': 0.0,\n",
    "    'hidden-dropout': 0.0,\n",
    "    'log-throughput': None,\n",
    "    'no-load-optim': None,\n",
    "    'no-load-rng': None,\n",
    "    'num-workers': 8,\n",
    "    'use-rotary-position-embeddings': None,\n",
    "    'position-embedding-type': 'rope',\n",
    "    'disable-bias-linear': None,\n",
    "    'add-qkv-bias': None,\n",
    "    'rotary-percent': 1.0,\n",
    "    'rotary-base': 1000000,\n",
    "    'rotary-seq-len-interpolation-factor': 1,\n",
    "    'no-save-optim': None,\n",
    "    'train-mode':'pretrain',\n",
    "    'log-progress':None,\n",
    "    \n",
    "    #'distributed-timeout-minutes': 60,\n",
    "    'use-flash-attn': None,  # Enable Flash Attention for better performance\n",
    "    #'use-ring-exchange-p2p': None,  # More efficient P2P communication\n",
    "    #'tp-comm-overlap-rs-dgrad': None,  # Enable overlap for reduce-scatter in backward pass\n",
    "    #'use-cpu-initialization': None,\n",
    "    \n",
    "    #'data-cache-path': '/opt/ml/input/data/cache'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP_COMM_OVERLAP = 1 if hyperparameters['tensor-model-parallel-size'] > 1 else 0\n",
    "# if TP_COMM_OVERLAP:\n",
    "#     hyperparameters['tp-comm-overlap']=None\n",
    "#     hyperparameters['overlap-grad-reduce']=None\n",
    "#     hyperparameters['overlap-param-gather']=None\n",
    "# else:\n",
    "#     hyperparameters['overlap-grad-reduce']=None\n",
    "#     hyperparameters['overlap-param-gather']=None\n",
    "\n",
    "# Precision options (based on bf16 setting)\n",
    "if 'bf16' not in hyperparameters.keys():\n",
    "    hyperparameters.update({\n",
    "        'fp16': None,\n",
    "        'apply-query-key-layer-scaling': None\n",
    "    })\n",
    "    hyperparameters[\"nvte-apply-qk-layer-scaling\"] = 1\n",
    "\n",
    "# Sequence Parallel options (if TP > 1)\n",
    "if hyperparameters['tensor-model-parallel-size'] > 1:\n",
    "    hyperparameters['sequence-parallel'] = None\n",
    "\n",
    "# Dataset options (assuming MMAP type)       \n",
    "hyperparameters.update({\n",
    "    'split': '99,1,0',\n",
    "    'dataset': 'MMAP'\n",
    "})\n",
    "\n",
    "# #Activation Checkpointing\n",
    "# hyperparameters.update({\n",
    "#     'recompute-method': 'uniform',\n",
    "#     'recompute-num-layers': 4,  # Default is 1\n",
    "#     'recompute-granularity': 'full'\n",
    "# })\n",
    "\n",
    "# # Add CPU offloading\n",
    "# hyperparameters.update({\n",
    "#     'cpu-offloading': True,\n",
    "#     'cpu-offloading-num-layers': 4\n",
    "# })\n",
    "\n",
    "# Make sure optimizer settings are correct\n",
    "hyperparameters.update({\n",
    "    'use-distributed-optimizer': None,\n",
    "    'optimizer': 'hybridadam',\n",
    "    'optimizer-offload-policy': 'static',\n",
    "    'optimizer-offload-fraction': 1.0,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distribution = {}\n",
    "distribution = {\n",
    "    \"mpi\": {\n",
    "        \"enabled\": True\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Pytorch` estimator를 이용한 training job 생성하기\n",
    "\n",
    "\n",
    "<p><strong><code>sagemaker.pytorch.PyTorch</code></strong> estimator는 처음 실행하는 스크립트 위치와 다양한 연계 코드들이 위치한 디렉토리 정보를 찾아서 스크립트를 S3에 upload하고 SageMaker의 training job을 수행하게 됩니다. training job은 학습을 수행한 단위입니다. 학습을 1번 돌리면 training job이 1개 생성됩니다. 몇 가지 중요 파라미터를 아래와 같이 설명드립니다. </p>\n",
    "\n",
    "- **entry_point** : 학습을 처음 실행하는 Python 소스 파일의 절대 또는 상대 경로이며, source_dir이 지정된 경우 entry_point는 source_dir 내 파일이 됩니다.\n",
    "- **source_dir** : 학습에 연계되는 다양한 소스코드 파일이 들어 있는 디렉토리 위치이며, 절대, 상대 경로 또는 S3 URI가 모두 가능하며,source_dir이 S3 URI 인 경우 tar.gz 파일이 됩니다.\n",
    "- **role** : Amazon SageMaker가 사용자를 대신해 작업(예: S3 버킷에서 모델 결과물이라고 하는 훈련 결과 읽기 및 Amazon S3에 훈련 결과 쓰기)을 수행하는 AWS Identity and Access Management(IAM) 역할입니다.\n",
    "- **train_instance_count** : 학습을 수행하는 instance 개수를 정의할 수 있습니다.\n",
    "- **train_instance_type** : 학습을 수행하는 instance 타입을 정의할 수 있습니다.\n",
    "- **train_volume_size** : 학습 인스턴스에 연결할 Amazon Elastic Block Store(Amazon EBS) 스토리지 볼륨의 크기(GB)입니다. File 모드를 사용할 경우 이 값이 훈련 데이터를 충분히 저장할 수 있는 크기여야 합니다(File 모드가 기본값)\n",
    "- **train_max_run** : 최대 학습 시간을 설정할 수 있으며, 이 시간이 지나면 Amazon SageMaker는 현재 상태에 관계없이 작업을 종료합니다. (기본값 : 24 * 60 * 60)\n",
    "- **framework_version** : 학습에 사용될 특정 Pytorch 버전을 정의할 수 있습니다.\n",
    "- **py_version** : 컨테이너 환경이 python3일 경우 py3, python2일 경우 py2로 설정하면 됩니다. python2는 지원이 중단되었지만 기존 python2로 구성된 파일들을 지원하기 위해 현재 계속 사용할 수 있습니다. 없을 경우에는 기본적으로 py3 입니다.\n",
    "- **hyperparameters** : 학습에 사용할 하이퍼 파라미터를 정의할 수 있으며, 정의된 하이퍼 파라미터 값들은 모두 학습 컨테이너로 전송이 됩니다.\n",
    "- **distribution** : 분산과 관련된 값들을 학습 컨테이너로 전송합니다.\n",
    "\n",
    "<p> 추가적으로 분산/ 멀티 GPU 학습도 가능합니다. SageMaker는 <strong><a href=\"https://github.com/horovod/horovod\" target=\"_blank\" class ='btn-default'>Horovod</a></strong>에 최적화된 환경을 제공하고 있으며, Pytorch의 경우 1.5.0부터 기본 docker에서 apex를 지원합니다.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'783764619792.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:latest'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "account_id = \"783764619792\"\n",
    "region_name = \"us-east-1\"\n",
    "image_uri = f'{account_id}.dkr.ecr.{region_name}.amazonaws.com/pytorch-training:latest'\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = {\n",
    "    'CUDA_DEVICE_MAX_CONNECTIONS':'1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instance_type = 'ml.p3.16xlarge'  # 'ml.p3.16xlarge', 'ml.p3dn.24xlarge', 'ml.p4d.24xlarge', 'local_gpu'\n",
    "#instance_type = 'ml.p4d.24xlarge'\n",
    "instance_type = 'ml.g5.48xlarge'\n",
    "#instance_type = 'local_gpu'\n",
    "instance_count = 2\n",
    "max_run = 4*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.inputs.FileSystemInput at 0x317f16a20>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if instance_type =='local_gpu':\n",
    "    from sagemaker.local import LocalSession\n",
    "\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    s3_data_path = f'file://{Path.cwd().parent}/codeparrot'\n",
    "    instance_count = 1\n",
    "else:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    #s3_data_path = \"s3://bucket-name-XXXXXXXX/megatron-lm/codeparrot/\"\n",
    "    s3_data_path = train_fs\n",
    "s3_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.network import NetworkConfig\n",
    "from pathlib import Path\n",
    "\n",
    "estimator = PyTorch(\n",
    "                    entry_point='debug.py',\n",
    "                    source_dir=f'{Path.cwd()}',\n",
    "                    role=role,\n",
    "                    image_uri=image_uri,\n",
    "                    framework_version='2.3.0',\n",
    "                    py_version='py311',\n",
    "                    instance_count=instance_count,\n",
    "                    instance_type=instance_type,\n",
    "                    distribution=distribution,\n",
    "                    disable_profiler=True,\n",
    "                    debugger_hook_config=False,\n",
    "                    max_run=max_run,\n",
    "                    hyperparameters=hyperparameters,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    subnets=['subnet-0bacb66e54e14ffe8'],\n",
    "                    security_group_ids=['sg-006609bebf68f39d8'],\n",
    "                    environment=env\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our `PyTorch` object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/17/25 16:12:31] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> SageMaker Python SDK will collect telemetry to help us better  <a href=\"file:///opt/anaconda3/envs/genai/lib/python3.12/site-packages/sagemaker/telemetry/telemetry_logging.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">telemetry_logging.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/genai/lib/python3.12/site-packages/sagemaker/telemetry/telemetry_logging.py#91\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         understand our user's needs, diagnose issues, and deliver      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         additional features.                                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To opt out of telemetry, please disable via TelemetryOptOut    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         parameter in SDK defaults config. For more information, refer  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         to                                                             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">https://sagemaker.readthedocs.io/en/stable/overview.html#confi</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #0069ff; text-decoration-color: #0069ff; text-decoration: underline\">guring-and-using-defaults-with-the-sagemaker-python-sdk.</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/17/25 16:12:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m SageMaker Python SDK will collect telemetry to help us better  \u001b]8;id=309250;file:///opt/anaconda3/envs/genai/lib/python3.12/site-packages/sagemaker/telemetry/telemetry_logging.py\u001b\\\u001b[2mtelemetry_logging.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=703425;file:///opt/anaconda3/envs/genai/lib/python3.12/site-packages/sagemaker/telemetry/telemetry_logging.py#91\u001b\\\u001b[2m91\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         understand our user's needs, diagnose issues, and deliver      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         additional features.                                           \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To opt out of telemetry, please disable via TelemetryOptOut    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         parameter in SDK defaults config. For more information, refer  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         to                                                             \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mhttps://sagemaker.readthedocs.io/en/stable/overview.html#confi\u001b[0m \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[4;38;2;0;105;255mguring-and-using-defaults-with-the-sagemaker-python-sdk.\u001b[0m       \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[03/17/25 16:13:10] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating training-job with name:                                       <a href=\"file:///opt/anaconda3/envs/genai/lib/python3.12/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/genai/lib/python3.12/site-packages/sagemaker/session.py#1042\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         megatron-lm-ml-g5-48xlarge-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0317</span>-04H12M31secPM                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[03/17/25 16:13:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating training-job with name:                                       \u001b]8;id=55335;file:///opt/anaconda3/envs/genai/lib/python3.12/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=409490;file:///opt/anaconda3/envs/genai/lib/python3.12/site-packages/sagemaker/session.py#1042\u001b\\\u001b[2m1042\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         megatron-lm-ml-g5-48xlarge-\u001b[1;36m0317\u001b[0m-04H12M31secPM                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_time = strftime(\"%m%d-%IH%MM%Ssec%p\")\n",
    "i_type = instance_type.replace('.','-')\n",
    "job_name = f'megatron-lm-{i_type}-{current_time}'\n",
    "\n",
    "estimator.fit(\n",
    "    inputs={'dataset': s3_data_path}, \n",
    "    job_name=job_name,\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-17 07:13:11 Starting - Starting the training job...\n",
      ".........7 07:13:19 Pending - Training job waiting for capacity\n",
      ".........7 07:15:24 Pending - Preparing the instances for training\n",
      "...............6:55 Downloading - Downloading the training image\n",
      "....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34mCUDA compat package should be installed for NVIDIA driver smaller than 530.30.02\u001b[0m\n",
      "\u001b[34mCurrent installed NVIDIA driver version is 550.144.03\u001b[0m\n",
      "\u001b[34mSkipping CUDA compat setup as newer NVIDIA driver is installed\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.11/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:27,639 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:27,705 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:27,714 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:27,716 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35mCUDA compat package should be installed for NVIDIA driver smaller than 530.30.02\u001b[0m\n",
      "\u001b[35mCurrent installed NVIDIA driver version is 550.144.03\u001b[0m\n",
      "\u001b[35mSkipping CUDA compat setup as newer NVIDIA driver is installed\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.11/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[35m/opt/conda/lib/python3.11/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from cryptography.hazmat.primitives.ciphers.algorithms in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:27,762 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:27,875 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:27,885 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:27,887 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:32,997 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:33,074 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:33,085 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:33,085 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:33,097 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:32,969 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:33,046 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:33,056 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:33,056 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:33,057 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:33,059 sagemaker-training-toolkit INFO     Cannot connect to host algo-2\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:33,059 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 172.31.26.212.              Can be ignored for worker when master completes and exits.\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:33,241 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:33,241 sagemaker-training-toolkit INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:33,241 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:33,241 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:33,274 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,085 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,231 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,232 sagemaker-training-toolkit INFO     Can connect to host algo-2\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,232 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,232 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1', 'algo-2'] Hosts: ['algo-1:8', 'algo-2:8'] process_per_hosts: 8 num_processes: 16\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,232 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,317 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,393 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,404 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_mpi_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"dataset\": \"/opt/ml/input/data/dataset\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.48xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"adam-beta1\": 0.9,\n",
      "        \"adam-beta2\": 0.95,\n",
      "        \"add-qkv-bias\": null,\n",
      "        \"attention-dropout\": 0.0,\n",
      "        \"bf16\": null,\n",
      "        \"clip-grad\": 1.0,\n",
      "        \"context-parallel-size\": 1,\n",
      "        \"data-path\": \"/opt/ml/input/data/dataset/dataset/qwen_codeparrot_content_document\",\n",
      "        \"dataset\": \"MMAP\",\n",
      "        \"disable-bias-linear\": null,\n",
      "        \"eval-interval\": 200,\n",
      "        \"eval-iters\": 10,\n",
      "        \"extra-vocab-size\": 421,\n",
      "        \"global-batch-size\": 64,\n",
      "        \"group-query-attention\": null,\n",
      "        \"hidden-dropout\": 0.0,\n",
      "        \"hidden-size\": 3584,\n",
      "        \"init-method-std\": 0.008,\n",
      "        \"intermediate-size\": 18944,\n",
      "        \"load\": \"/opt/ml/input/data/dataset/dataset/megatron-qwen2.5-7B/release/mp_rank_00/\",\n",
      "        \"log-interval\": 10,\n",
      "        \"log-progress\": null,\n",
      "        \"log-throughput\": null,\n",
      "        \"lr\": 0.0005,\n",
      "        \"lr-decay-iters\": 10000,\n",
      "        \"lr-decay-style\": \"cosine\",\n",
      "        \"lr-warmup-iters\": 1000,\n",
      "        \"max-position-embeddings\": 131072,\n",
      "        \"merge-file\": \"/opt/ml/input/data/dataset/dataset/merges.txt\",\n",
      "        \"micro-batch-size\": 1,\n",
      "        \"no-load-optim\": null,\n",
      "        \"no-load-rng\": null,\n",
      "        \"no-save-optim\": null,\n",
      "        \"norm-epsilon\": 1e-06,\n",
      "        \"num-attention-heads\": 28,\n",
      "        \"num-layers\": 28,\n",
      "        \"num-query-groups\": 4,\n",
      "        \"num-workers\": 8,\n",
      "        \"optimizer\": \"hybridadam\",\n",
      "        \"optimizer-offload-fraction\": 1.0,\n",
      "        \"optimizer-offload-policy\": \"static\",\n",
      "        \"patch-tokenizer-type\": \"Qwen2Tokenizer\",\n",
      "        \"pipeline-model-parallel-size\": 1,\n",
      "        \"position-embedding-type\": \"rope\",\n",
      "        \"rotary-base\": 1000000,\n",
      "        \"rotary-percent\": 1.0,\n",
      "        \"rotary-seq-len-interpolation-factor\": 1,\n",
      "        \"save\": \"/opt/ml/model/\",\n",
      "        \"save-interval\": 2000,\n",
      "        \"seq-length\": 4096,\n",
      "        \"sequence-parallel\": null,\n",
      "        \"split\": \"99,1,0\",\n",
      "        \"tensor-model-parallel-size\": 2,\n",
      "        \"train-iters\": 100000,\n",
      "        \"train-mode\": \"pretrain\",\n",
      "        \"untie-embeddings-and-output-weights\": null,\n",
      "        \"use-distributed-optimizer\": null,\n",
      "        \"use-flash-attn\": null,\n",
      "        \"use-rotary-position-embeddings\": null,\n",
      "        \"vocab-file\": \"/opt/ml/input/data/dataset/dataset/vocab.json\",\n",
      "        \"weight-decay\": 0.1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"dataset\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.48xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"megatron-lm-ml-g5-48xlarge-0317-04H12M31secPM\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-783764619792/megatron-lm-ml-g5-48xlarge-0317-04H12M31secPM/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"debug\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 192,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.48xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.48xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"debug.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"adam-beta1\":0.9,\"adam-beta2\":0.95,\"add-qkv-bias\":null,\"attention-dropout\":0.0,\"bf16\":null,\"clip-grad\":1.0,\"context-parallel-size\":1,\"data-path\":\"/opt/ml/input/data/dataset/dataset/qwen_codeparrot_content_document\",\"dataset\":\"MMAP\",\"disable-bias-linear\":null,\"eval-interval\":200,\"eval-iters\":10,\"extra-vocab-size\":421,\"global-batch-size\":64,\"group-query-attention\":null,\"hidden-dropout\":0.0,\"hidden-size\":3584,\"init-method-std\":0.008,\"intermediate-size\":18944,\"load\":\"/opt/ml/input/data/dataset/dataset/megatron-qwen2.5-7B/release/mp_rank_00/\",\"log-interval\":10,\"log-progress\":null,\"log-throughput\":null,\"lr\":0.0005,\"lr-decay-iters\":10000,\"lr-decay-style\":\"cosine\",\"lr-warmup-iters\":1000,\"max-position-embeddings\":131072,\"merge-file\":\"/opt/ml/input/data/dataset/dataset/merges.txt\",\"micro-batch-size\":1,\"no-load-optim\":null,\"no-load-rng\":null,\"no-save-optim\":null,\"norm-epsilon\":1e-06,\"num-attention-heads\":28,\"num-layers\":28,\"num-query-groups\":4,\"num-workers\":8,\"optimizer\":\"hybridadam\",\"optimizer-offload-fraction\":1.0,\"optimizer-offload-policy\":\"static\",\"patch-tokenizer-type\":\"Qwen2Tokenizer\",\"pipeline-model-parallel-size\":1,\"position-embedding-type\":\"rope\",\"rotary-base\":1000000,\"rotary-percent\":1.0,\"rotary-seq-len-interpolation-factor\":1,\"save\":\"/opt/ml/model/\",\"save-interval\":2000,\"seq-length\":4096,\"sequence-parallel\":null,\"split\":\"99,1,0\",\"tensor-model-parallel-size\":2,\"train-iters\":100000,\"train-mode\":\"pretrain\",\"untie-embeddings-and-output-weights\":null,\"use-distributed-optimizer\":null,\"use-flash-attn\":null,\"use-rotary-position-embeddings\":null,\"vocab-file\":\"/opt/ml/input/data/dataset/dataset/vocab.json\",\"weight-decay\":0.1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=debug.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.48xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"dataset\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.48xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=debug\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=192\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-783764619792/megatron-lm-ml-g5-48xlarge-0317-04H12M31secPM/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_mpi_custom_mpi_options\":\"\",\"sagemaker_mpi_enabled\":true},\"channel_input_dirs\":{\"dataset\":\"/opt/ml/input/data/dataset\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.g5.48xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"adam-beta1\":0.9,\"adam-beta2\":0.95,\"add-qkv-bias\":null,\"attention-dropout\":0.0,\"bf16\":null,\"clip-grad\":1.0,\"context-parallel-size\":1,\"data-path\":\"/opt/ml/input/data/dataset/dataset/qwen_codeparrot_content_document\",\"dataset\":\"MMAP\",\"disable-bias-linear\":null,\"eval-interval\":200,\"eval-iters\":10,\"extra-vocab-size\":421,\"global-batch-size\":64,\"group-query-attention\":null,\"hidden-dropout\":0.0,\"hidden-size\":3584,\"init-method-std\":0.008,\"intermediate-size\":18944,\"load\":\"/opt/ml/input/data/dataset/dataset/megatron-qwen2.5-7B/release/mp_rank_00/\",\"log-interval\":10,\"log-progress\":null,\"log-throughput\":null,\"lr\":0.0005,\"lr-decay-iters\":10000,\"lr-decay-style\":\"cosine\",\"lr-warmup-iters\":1000,\"max-position-embeddings\":131072,\"merge-file\":\"/opt/ml/input/data/dataset/dataset/merges.txt\",\"micro-batch-size\":1,\"no-load-optim\":null,\"no-load-rng\":null,\"no-save-optim\":null,\"norm-epsilon\":1e-06,\"num-attention-heads\":28,\"num-layers\":28,\"num-query-groups\":4,\"num-workers\":8,\"optimizer\":\"hybridadam\",\"optimizer-offload-fraction\":1.0,\"optimizer-offload-policy\":\"static\",\"patch-tokenizer-type\":\"Qwen2Tokenizer\",\"pipeline-model-parallel-size\":1,\"position-embedding-type\":\"rope\",\"rotary-base\":1000000,\"rotary-percent\":1.0,\"rotary-seq-len-interpolation-factor\":1,\"save\":\"/opt/ml/model/\",\"save-interval\":2000,\"seq-length\":4096,\"sequence-parallel\":null,\"split\":\"99,1,0\",\"tensor-model-parallel-size\":2,\"train-iters\":100000,\"train-mode\":\"pretrain\",\"untie-embeddings-and-output-weights\":null,\"use-distributed-optimizer\":null,\"use-flash-attn\":null,\"use-rotary-position-embeddings\":null,\"vocab-file\":\"/opt/ml/input/data/dataset/dataset/vocab.json\",\"weight-decay\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"dataset\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"megatron-lm-ml-g5-48xlarge-0317-04H12M31secPM\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-783764619792/megatron-lm-ml-g5-48xlarge-0317-04H12M31secPM/source/sourcedir.tar.gz\",\"module_name\":\"debug\",\"network_interface_name\":\"eth0\",\"num_cpus\":192,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.48xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"debug.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--adam-beta1\",\"0.9\",\"--adam-beta2\",\"0.95\",\"--add-qkv-bias\",\"\",\"--attention-dropout\",\"0.0\",\"--bf16\",\"\",\"--clip-grad\",\"1.0\",\"--context-parallel-size\",\"1\",\"--data-path\",\"/opt/ml/input/data/dataset/dataset/qwen_codeparrot_content_document\",\"--dataset\",\"MMAP\",\"--disable-bias-linear\",\"\",\"--eval-interval\",\"200\",\"--eval-iters\",\"10\",\"--extra-vocab-size\",\"421\",\"--global-batch-size\",\"64\",\"--group-query-attention\",\"\",\"--hidden-dropout\",\"0.0\",\"--hidden-size\",\"3584\",\"--init-method-std\",\"0.008\",\"--intermediate-size\",\"18944\",\"--load\",\"/opt/ml/input/data/dataset/dataset/megatron-qwen2.5-7B/release/mp_rank_00/\",\"--log-interval\",\"10\",\"--log-progress\",\"\",\"--log-throughput\",\"\",\"--lr\",\"0.0005\",\"--lr-decay-iters\",\"10000\",\"--lr-decay-style\",\"cosine\",\"--lr-warmup-iters\",\"1000\",\"--max-position-embeddings\",\"131072\",\"--merge-file\",\"/opt/ml/input/data/dataset/dataset/merges.txt\",\"--micro-batch-size\",\"1\",\"--no-load-optim\",\"\",\"--no-load-rng\",\"\",\"--no-save-optim\",\"\",\"--norm-epsilon\",\"1e-06\",\"--num-attention-heads\",\"28\",\"--num-layers\",\"28\",\"--num-query-groups\",\"4\",\"--num-workers\",\"8\",\"--optimizer\",\"hybridadam\",\"--optimizer-offload-fraction\",\"1.0\",\"--optimizer-offload-policy\",\"static\",\"--patch-tokenizer-type\",\"Qwen2Tokenizer\",\"--pipeline-model-parallel-size\",\"1\",\"--position-embedding-type\",\"rope\",\"--rotary-base\",\"1000000\",\"--rotary-percent\",\"1.0\",\"--rotary-seq-len-interpolation-factor\",\"1\",\"--save\",\"/opt/ml/model/\",\"--save-interval\",\"2000\",\"--seq-length\",\"4096\",\"--sequence-parallel\",\"\",\"--split\",\"99,1,0\",\"--tensor-model-parallel-size\",\"2\",\"--train-iters\",\"100000\",\"--train-mode\",\"pretrain\",\"--untie-embeddings-and-output-weights\",\"\",\"--use-distributed-optimizer\",\"\",\"--use-flash-attn\",\"\",\"--use-rotary-position-embeddings\",\"\",\"--vocab-file\",\"/opt/ml/input/data/dataset/dataset/vocab.json\",\"--weight-decay\",\"0.1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_DATASET=/opt/ml/input/data/dataset\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM-BETA1=0.9\u001b[0m\n",
      "\u001b[34mSM_HP_ADAM-BETA2=0.95\u001b[0m\n",
      "\u001b[34mSM_HP_ADD-QKV-BIAS=\u001b[0m\n",
      "\u001b[34mSM_HP_ATTENTION-DROPOUT=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=\u001b[0m\n",
      "\u001b[34mSM_HP_CLIP-GRAD=1.0\u001b[0m\n",
      "\u001b[34mSM_HP_CONTEXT-PARALLEL-SIZE=1\u001b[0m\n",
      "\u001b[34mSM_HP_DATA-PATH=/opt/ml/input/data/dataset/dataset/qwen_codeparrot_content_document\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET=MMAP\u001b[0m\n",
      "\u001b[34mSM_HP_DISABLE-BIAS-LINEAR=\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL-INTERVAL=200\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL-ITERS=10\u001b[0m\n",
      "\u001b[34mSM_HP_EXTRA-VOCAB-SIZE=421\u001b[0m\n",
      "\u001b[34mSM_HP_GLOBAL-BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_GROUP-QUERY-ATTENTION=\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN-DROPOUT=0.0\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN-SIZE=3584\u001b[0m\n",
      "\u001b[34mSM_HP_INIT-METHOD-STD=0.008\u001b[0m\n",
      "\u001b[34mSM_HP_INTERMEDIATE-SIZE=18944\u001b[0m\n",
      "\u001b[34mSM_HP_LOAD=/opt/ml/input/data/dataset/dataset/megatron-qwen2.5-7B/release/mp_rank_00/\u001b[0m\n",
      "\u001b[34mSM_HP_LOG-INTERVAL=10\u001b[0m\n",
      "\u001b[34mSM_HP_LOG-PROGRESS=\u001b[0m\n",
      "\u001b[34mSM_HP_LOG-THROUGHPUT=\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.0005\u001b[0m\n",
      "\u001b[34mSM_HP_LR-DECAY-ITERS=10000\u001b[0m\n",
      "\u001b[34mSM_HP_LR-DECAY-STYLE=cosine\u001b[0m\n",
      "\u001b[34mSM_HP_LR-WARMUP-ITERS=1000\u001b[0m\n",
      "\u001b[34mSM_HP_MAX-POSITION-EMBEDDINGS=131072\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE-FILE=/opt/ml/input/data/dataset/dataset/merges.txt\u001b[0m\n",
      "\u001b[34mSM_HP_MICRO-BATCH-SIZE=1\u001b[0m\n",
      "\u001b[34mSM_HP_NO-LOAD-OPTIM=\u001b[0m\n",
      "\u001b[34mSM_HP_NO-LOAD-RNG=\u001b[0m\n",
      "\u001b[34mSM_HP_NO-SAVE-OPTIM=\u001b[0m\n",
      "\u001b[34mSM_HP_NORM-EPSILON=1e-06\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-ATTENTION-HEADS=28\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-LAYERS=28\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-QUERY-GROUPS=4\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-WORKERS=8\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=hybridadam\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER-OFFLOAD-FRACTION=1.0\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER-OFFLOAD-POLICY=static\u001b[0m\n",
      "\u001b[34mSM_HP_PATCH-TOKENIZER-TYPE=Qwen2Tokenizer\u001b[0m\n",
      "\u001b[34mSM_HP_PIPELINE-MODEL-PARALLEL-SIZE=1\u001b[0m\n",
      "\u001b[34mSM_HP_POSITION-EMBEDDING-TYPE=rope\u001b[0m\n",
      "\u001b[34mSM_HP_ROTARY-BASE=1000000\u001b[0m\n",
      "\u001b[34mSM_HP_ROTARY-PERCENT=1.0\u001b[0m\n",
      "\u001b[34mSM_HP_ROTARY-SEQ-LEN-INTERPOLATION-FACTOR=1\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE=/opt/ml/model/\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE-INTERVAL=2000\u001b[0m\n",
      "\u001b[34mSM_HP_SEQ-LENGTH=4096\u001b[0m\n",
      "\u001b[34mSM_HP_SEQUENCE-PARALLEL=\u001b[0m\n",
      "\u001b[34mSM_HP_SPLIT=99,1,0\u001b[0m\n",
      "\u001b[34mSM_HP_TENSOR-MODEL-PARALLEL-SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN-ITERS=100000\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN-MODE=pretrain\u001b[0m\n",
      "\u001b[34mSM_HP_UNTIE-EMBEDDINGS-AND-OUTPUT-WEIGHTS=\u001b[0m\n",
      "\u001b[34mSM_HP_USE-DISTRIBUTED-OPTIMIZER=\u001b[0m\n",
      "\u001b[34mSM_HP_USE-FLASH-ATTN=\u001b[0m\n",
      "\u001b[34mSM_HP_USE-ROTARY-POSITION-EMBEDDINGS=\u001b[0m\n",
      "\u001b[34mSM_HP_VOCAB-FILE=/opt/ml/input/data/dataset/dataset/vocab.json\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT-DECAY=0.1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python311.zip:/opt/conda/lib/python3.11:/opt/conda/lib/python3.11/lib-dynload:/opt/conda/lib/python3.11/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:8,algo-2:8 -np 16 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/opt/conda/lib/python3.11/site-packages/gethostname.cpython-311-x86_64-linux-gnu.so -x FI_PROVIDER=efa -x NCCL_PROTO=simple -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_CURRENT_INSTANCE_TYPE -x SM_CURRENT_INSTANCE_GROUP -x SM_CURRENT_INSTANCE_GROUP_HOSTS -x SM_INSTANCE_GROUPS -x SM_INSTANCE_GROUPS_DICT -x SM_DISTRIBUTION_INSTANCE_GROUPS -x SM_IS_HETERO -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_NUM_NEURONS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_DATASET -x SM_HP_ADAM-BETA1 -x SM_HP_ADAM-BETA2 -x SM_HP_ADD-QKV-BIAS -x SM_HP_ATTENTION-DROPOUT -x SM_HP_BF16 -x SM_HP_CLIP-GRAD -x SM_HP_CONTEXT-PARALLEL-SIZE -x SM_HP_DATA-PATH -x SM_HP_DATASET -x SM_HP_DISABLE-BIAS-LINEAR -x SM_HP_EVAL-INTERVAL -x SM_HP_EVAL-ITERS -x SM_HP_EXTRA-VOCAB-SIZE -x SM_HP_GLOBAL-BATCH-SIZE -x SM_HP_GROUP-QUERY-ATTENTION -x SM_HP_HIDDEN-DROPOUT -x SM_HP_HIDDEN-SIZE -x SM_HP_INIT-METHOD-STD -x SM_HP_INTERMEDIATE-SIZE -x SM_HP_LOAD -x SM_HP_LOG-INTERVAL -x SM_HP_LOG-PROGRESS -x SM_HP_LOG-THROUGHPUT -x SM_HP_LR -x SM_HP_LR-DECAY-ITERS -x SM_HP_LR-DECAY-STYLE -x SM_HP_LR-WARMUP-ITERS -x SM_HP_MAX-POSITION-EMBEDDINGS -x SM_HP_MERGE-FILE -x SM_HP_MICRO-BATCH-SIZE -x SM_HP_NO-LOAD-OPTIM -x SM_HP_NO-LOAD-RNG -x SM_HP_NO-SAVE-OPTIM -x SM_HP_NORM-EPSILON -x SM_HP_NUM-ATTENTION-HEADS -x SM_HP_NUM-LAYERS -x SM_HP_NUM-QUERY-GROUPS -x SM_HP_NUM-WORKERS -x SM_HP_OPTIMIZER -x SM_HP_OPTIMIZER-OFFLOAD-FRACTION -x SM_HP_OPTIMIZER-OFFLOAD-POLICY -x SM_HP_PATCH-TOKENIZER-TYPE -x SM_HP_PIPELINE-MODEL-PARALLEL-SIZE -x SM_HP_POSITION-EMBEDDING-TYPE -x SM_HP_ROTARY-BASE -x SM_HP_ROTARY-PERCENT -x SM_HP_ROTARY-SEQ-LEN-INTERPOLATION-FACTOR -x SM_HP_SAVE -x SM_HP_SAVE-INTERVAL -x SM_HP_SEQ-LENGTH -x SM_HP_SEQUENCE-PARALLEL -x SM_HP_SPLIT -x SM_HP_TENSOR-MODEL-PARALLEL-SIZE -x SM_HP_TRAIN-ITERS -x SM_HP_TRAIN-MODE -x SM_HP_UNTIE-EMBEDDINGS-AND-OUTPUT-WEIGHTS -x SM_HP_USE-DISTRIBUTED-OPTIMIZER -x SM_HP_USE-FLASH-ATTN -x SM_HP_USE-ROTARY-POSITION-EMBEDDINGS -x SM_HP_VOCAB-FILE -x SM_HP_WEIGHT-DECAY -x PYTHONPATH /opt/conda/bin/python3.11 -m mpi4py debug.py --adam-beta1 0.9 --adam-beta2 0.95 --add-qkv-bias  --attention-dropout 0.0 --bf16  --clip-grad 1.0 --context-parallel-size 1 --data-path /opt/ml/input/data/dataset/dataset/qwen_codeparrot_content_document --dataset MMAP --disable-bias-linear  --eval-interval 200 --eval-iters 10 --extra-vocab-size 421 --global-batch-size 64 --group-query-attention  --hidden-dropout 0.0 --hidden-size 3584 --init-method-std 0.008 --intermediate-size 18944 --load /opt/ml/input/data/dataset/dataset/megatron-qwen2.5-7B/release/mp_rank_00/ --log-interval 10 --log-progress  --log-throughput  --lr 0.0005 --lr-decay-iters 10000 --lr-decay-style cosine --lr-warmup-iters 1000 --max-position-embeddings 131072 --merge-file /opt/ml/input/data/dataset/dataset/merges.txt --micro-batch-size 1 --no-load-optim  --no-load-rng  --no-save-optim  --norm-epsilon 1e-06 --num-attention-heads 28 --num-layers 28 --num-query-groups 4 --num-workers 8 --optimizer hybridadam --optimizer-offload-fraction 1.0 --optimizer-offload-policy static --patch-tokenizer-type Qwen2Tokenizer --pipeline-model-parallel-size 1 --position-embedding-type rope --rotary-base 1000000 --rotary-percent 1.0 --rotary-seq-len-interpolation-factor 1 --save /opt/ml/model/ --save-interval 2000 --seq-length 4096 --sequence-parallel  --split 99,1,0 --tensor-model-parallel-size 2 --train-iters 100000 --train-mode pretrain --untie-embeddings-and-output-weights  --use-distributed-optimizer  --use-flash-attn  --use-rotary-position-embeddings  --vocab-file /opt/ml/input/data/dataset/dataset/vocab.json --weight-decay 0.1\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,469 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,480 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,480 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:34,480 sagemaker-training-toolkit INFO     smdistributed.dataparallel not found or using an older version without custom exceptions.SM training toolkit will track user script error only\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_ADAM-BETA1\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_ADAM-BETA2\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_ADD-QKV-BIAS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_ATTENTION-DROPOUT\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_CLIP-GRAD\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_CONTEXT-PARALLEL-SIZE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_DATA-PATH\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_DISABLE-BIAS-LINEAR\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_EVAL-INTERVAL\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_EVAL-ITERS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_EXTRA-VOCAB-SIZE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_GLOBAL-BATCH-SIZE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_GROUP-QUERY-ATTENTION\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_HIDDEN-DROPOUT\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_HIDDEN-SIZE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_INIT-METHOD-STD\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_INTERMEDIATE-SIZE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_LOG-INTERVAL\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_LOG-PROGRESS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_LOG-THROUGHPUT\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_LR-DECAY-ITERS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_LR-DECAY-STYLE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_LR-WARMUP-ITERS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_MAX-POSITION-EMBEDDINGS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_MERGE-FILE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_MICRO-BATCH-SIZE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_NO-LOAD-OPTIM\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_NO-LOAD-RNG\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_NO-SAVE-OPTIM\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_NORM-EPSILON\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_NUM-ATTENTION-HEADS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_NUM-LAYERS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_NUM-QUERY-GROUPS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_NUM-WORKERS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_OPTIMIZER-OFFLOAD-FRACTION\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_OPTIMIZER-OFFLOAD-POLICY\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_PATCH-TOKENIZER-TYPE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_PIPELINE-MODEL-PARALLEL-SIZE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_POSITION-EMBEDDING-TYPE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_ROTARY-BASE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_ROTARY-PERCENT\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_ROTARY-SEQ-LEN-INTERPOLATION-FACTOR\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_SAVE-INTERVAL\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_SEQ-LENGTH\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_SEQUENCE-PARALLEL\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_TENSOR-MODEL-PARALLEL-SIZE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_TRAIN-ITERS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_TRAIN-MODE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_UNTIE-EMBEDDINGS-AND-OUTPUT-WEIGHTS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_USE-DISTRIBUTED-OPTIMIZER\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_USE-FLASH-ATTN\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_USE-ROTARY-POSITION-EMBEDDINGS\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_VOCAB-FILE\"\u001b[0m\n",
      "\u001b[34m[algo-1:00102] Warning: could not find environment variable \"SM_HP_WEIGHT-DECAY\"\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-2,172.31.26.212' (ECDSA) to the list of known hosts.\u001b[0m\n",
      "\u001b[34mData for JOB [41088,1] offset 0 Total slots allocated 16\n",
      " ========================   JOB MAP   ========================\n",
      " Data for node: algo-1#011Num slots: 8#011Max slots: 0#011Num procs: 8\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 0 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 1 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 2 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 3 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 4 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 5 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 6 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 7 Bound: N/A\n",
      " Data for node: algo-2#011Num slots: 8#011Max slots: 0#011Num procs: 8\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 8 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 9 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 10 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 11 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 12 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 13 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 14 Bound: N/A\n",
      " #011Process OMPI jobid: [41088,1] App: 0 Process rank: 15 Bound: N/A\n",
      " =============================================================\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:35,277 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=100, name='orted', status='sleeping', started='07:20:34')]\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:35,277 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=100, name='orted', status='sleeping', started='07:20:34')]\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:35,277 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=100, name='orted', status='sleeping', started='07:20:34')]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Rank 0: Hostname: algo-1, IP: 172.31.29.168\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Rank 0 on node 0 with IP 172.31.29.168 is ready\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Rank 0: Found available port 12086 for testing\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Rank 0: Successfully tested socket binding on port 12086\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Starting initialization with increased timeout...\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Rank 0: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Rank 6: Hostname: algo-1, IP: 172.31.29.168\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Rank 6: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Rank 3: Hostname: algo-1, IP: 172.31.29.168\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Rank 3: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Rank 2: Hostname: algo-1, IP: 172.31.29.168\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Rank 2: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Rank 5: Hostname: algo-1, IP: 172.31.29.168\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Rank 5: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Rank 1: Hostname: algo-1, IP: 172.31.29.168\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Rank 1: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Rank 7: Hostname: algo-1, IP: 172.31.29.168\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Rank 7: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Rank 4: Hostname: algo-1, IP: 172.31.29.168\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Rank 4: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Rank 9: Hostname: algo-2, IP: 172.31.26.212\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Rank 9: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Rank 8: Hostname: algo-2, IP: 172.31.26.212\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Rank 8 on node 1 with IP 172.31.26.212 is ready\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Rank 8: Found available port 12396 for testing\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Rank 8: Successfully tested socket binding on port 12396\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Rank 8: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Rank 15: Hostname: algo-2, IP: 172.31.26.212\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Rank 15: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Rank 10: Hostname: algo-2, IP: 172.31.26.212\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Rank 10: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Rank 11: Hostname: algo-2, IP: 172.31.26.212\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Rank 11: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Rank 12: Hostname: algo-2, IP: 172.31.26.212\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Rank 12: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Rank 13: Hostname: algo-2, IP: 172.31.26.212\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Rank 13: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Rank 14: Hostname: algo-2, IP: 172.31.26.212\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Rank 14: Attempting to initialize process group\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Rank 6: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Rank 6: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Rank 3: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Rank 3: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Rank 2: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Rank 2: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Rank 1: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Rank 1: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Rank 9: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Rank 9: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Rank 8: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Rank 8: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Rank 15: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Rank 15: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Rank 10: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Rank 10: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Rank 4: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Rank 4: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Rank 7: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Rank 7: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Rank 5: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Rank 5: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Rank 0: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Rank 0: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Rank 14: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Rank 14: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Rank 13: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Rank 13: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Rank 12: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Rank 12: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:[W Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Rank 11: Process group initialized successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Rank 11: Starting all-reduce test\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Rank 3: Tensor device: cuda:3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Rank 2: Tensor device: cuda:2\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Rank 5: Tensor device: cuda:5\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Rank 1: Tensor device: cuda:1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Rank 6: Tensor device: cuda:6\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Rank 4: Tensor device: cuda:4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Rank 0: Tensor device: cuda:0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:107 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:107 [0] NCCL INFO Bootstrap : Using eth0:172.31.29.168<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:107 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:107 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:107 [0] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:NCCL version 2.21.5+cuda12.1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Rank 7: Tensor device: cuda:7\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Rank 9: Tensor device: cuda:1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Rank 8: Tensor device: cuda:0\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Rank 15: Tensor device: cuda:7\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Rank 10: Tensor device: cuda:2\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:103 [0] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:103 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:103 [0] NCCL INFO Bootstrap : Using eth0:172.31.26.212<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Rank 13: Tensor device: cuda:5\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Rank 11: Tensor device: cuda:3\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:103 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:103 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Rank 12: Tensor device: cuda:4\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Rank 14: Tensor device: cuda:6\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:112 [5] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:112 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:112 [5] NCCL INFO Bootstrap : Using eth0:172.31.29.168<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:113 [6] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:113 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:113 [6] NCCL INFO Bootstrap : Using eth0:172.31.29.168<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:112 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:112 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:110 [3] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:110 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:110 [3] NCCL INFO Bootstrap : Using eth0:172.31.29.168<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:113 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:113 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:110 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:110 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:111 [4] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:111 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:111 [4] NCCL INFO Bootstrap : Using eth0:172.31.29.168<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:108 [1] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:108 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:111 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:111 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:108 [1] NCCL INFO Bootstrap : Using eth0:172.31.29.168<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:114 [7] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:114 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:109 [2] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:109 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:109 [2] NCCL INFO Bootstrap : Using eth0:172.31.29.168<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:114 [7] NCCL INFO Bootstrap : Using eth0:172.31.29.168<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:108 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:108 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:114 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:114 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:109 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:109 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:110 [7] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:110 [7] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:110 [7] NCCL INFO Bootstrap : Using eth0:172.31.26.212<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:106 [3] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:106 [3] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:106 [3] NCCL INFO Bootstrap : Using eth0:172.31.26.212<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:110 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:110 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:108 [5] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:108 [5] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:106 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:106 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:108 [5] NCCL INFO Bootstrap : Using eth0:172.31.26.212<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:108 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:108 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:105 [2] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:105 [2] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:105 [2] NCCL INFO Bootstrap : Using eth0:172.31.26.212<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:104 [1] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:104 [1] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:104 [1] NCCL INFO Bootstrap : Using eth0:172.31.26.212<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:105 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:105 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:104 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:104 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:107 [4] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:107 [4] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:107 [4] NCCL INFO Bootstrap : Using eth0:172.31.26.212<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:107 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:107 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:109 [6] NCCL INFO cudaDriverVersion 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:109 [6] NCCL INFO NCCL_SOCKET_IFNAME set by environment to eth0\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:109 [6] NCCL INFO Bootstrap : Using eth0:172.31.26.212<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:109 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v8 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:109 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (>= v5). ncclCollNetPlugin symbols v4 and lower are not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Initializing aws-ofi-nccl 1.9.1-aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Using Libfabric version 1.21\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Using CUDA driver version 12040\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Configuring AWS-specific options\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Setting NCCL_NVLSTREE_MAX_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Setting NCCL_NVLS_CHUNKSIZE to 512KiB\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Running on g5.48xlarge platform, Setting NCCL_TOPO_FILE environment variable to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Internode latency set at 0.0 us\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Using transport protocol SENDRECV\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Selected Provider is efa (found 1 nics)\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Could not disable CUDA API usage for HMEM, disabling GDR\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Setting FI_OPT_EFA_SENDRECV_IN_ORDER_ALIGNED_128_BYTES not supported.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Using non-device net plugin version 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Using network AWS Libfabric\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO ncclCommInitRank comm 0x55f3e56fd9e0 rank 6 nranks 16 cudaDev 6 nvmlDev 6 busId 1c0 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO ncclCommInitRank comm 0x55dea5a127f0 rank 2 nranks 16 cudaDev 2 nvmlDev 2 busId 180 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO ncclCommInitRank comm 0x560c100e5fe0 rank 3 nranks 16 cudaDev 3 nvmlDev 3 busId 190 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO ncclCommInitRank comm 0x5583606883b0 rank 1 nranks 16 cudaDev 1 nvmlDev 1 busId 170 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO ncclCommInitRank comm 0x555b2d3427d0 rank 7 nranks 16 cudaDev 7 nvmlDev 7 busId 1d0 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO ncclCommInitRank comm 0x562c710e1990 rank 5 nranks 16 cudaDev 5 nvmlDev 5 busId 1b0 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO ncclCommInitRank comm 0x5615fa442840 rank 4 nranks 16 cudaDev 4 nvmlDev 4 busId 1a0 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO ncclCommInitRank comm 0x560b00923d10 rank 0 nranks 16 cudaDev 0 nvmlDev 0 busId 160 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO ncclCommInitRank comm 0x55dfe1ffe1f0 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId 190 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO ncclCommInitRank comm 0x55b23f1eaf40 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 180 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO ncclCommInitRank comm 0x5581f3ae2050 rank 12 nranks 16 cudaDev 4 nvmlDev 4 busId 1a0 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO ncclCommInitRank comm 0x5612a39e0c40 rank 15 nranks 16 cudaDev 7 nvmlDev 7 busId 1d0 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO ncclCommInitRank comm 0x5591a95d9d20 rank 14 nranks 16 cudaDev 6 nvmlDev 6 busId 1c0 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO ncclCommInitRank comm 0x55d3dcf458d0 rank 13 nranks 16 cudaDev 5 nvmlDev 5 busId 1b0 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO ncclCommInitRank comm 0x55c3d31900e0 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 170 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO ncclCommInitRank comm 0x5579d08b7fb0 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 160 commId 0x2d2cf568e2e69f0d - Init START\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NCCL_TOPO_FILE set by environment to /opt/conda/share/aws-ofi-nccl/xml/g5.48xl-topo.xml\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NVLS multicast support is not available on dev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NVLS multicast support is not available on dev 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Setting affinity for GPU 2 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NVLS multicast support is not available on dev 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Setting affinity for GPU 3 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NVLS multicast support is not available on dev 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NVLS multicast support is not available on dev 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Setting affinity for GPU 3 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NVLS multicast support is not available on dev 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NVLS multicast support is not available on dev 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NVLS multicast support is not available on dev 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Setting affinity for GPU 2 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NVLS multicast support is not available on dev 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Setting affinity for GPU 6 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NVLS multicast support is not available on dev 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Setting affinity for GPU 0 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NVLS multicast support is not available on dev 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Setting affinity for GPU 4 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NVLS multicast support is not available on dev 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NVLS multicast support is not available on dev 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Setting affinity for GPU 1 to ffff,ffffffff,00000000,0000ffff,ffffffff\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NVLS multicast support is not available on dev 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NCCL_P2P_LEVEL set by environment to LOC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Setting affinity for GPU 7 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NVLS multicast support is not available on dev 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Setting affinity for GPU 5 to ffffffff,ffff0000,00000000,ffffffff,ffff0000,00000000\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NVLS multicast support is not available on dev 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO comm 0x55f3e56fd9e0 rank 6 nRanks 16 nNodes 2 localRanks 8 localRank 6 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO comm 0x560c100e5fe0 rank 3 nRanks 16 nNodes 2 localRanks 8 localRank 3 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO comm 0x55dea5a127f0 rank 2 nRanks 16 nNodes 2 localRanks 8 localRank 2 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO comm 0x555b2d3427d0 rank 7 nRanks 16 nNodes 2 localRanks 8 localRank 7 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6 [2] -1/-1/-1->7->6 [3] -1/-1/-1->7->6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO comm 0x560b00923d10 rank 0 nRanks 16 nNodes 2 localRanks 8 localRank 0 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 00/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 01/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 02/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO comm 0x562c710e1990 rank 5 nRanks 16 nNodes 2 localRanks 8 localRank 5 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO comm 0x5615fa442840 rank 4 nRanks 16 nNodes 2 localRanks 8 localRank 4 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO comm 0x5583606883b0 rank 1 nRanks 16 nNodes 2 localRanks 8 localRank 1 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/-1/-1->3->2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 03/04 :    0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Trees [0] 1/8/-1->0->-1 [1] 1/-1/-1->0->8 [2] 1/8/-1->0->-1 [3] 1/-1/-1->0->8\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO comm 0x5612a39e0c40 rank 15 nRanks 16 nNodes 2 localRanks 8 localRank 7 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] -1/-1/-1->15->14 [2] -1/-1/-1->15->14 [3] -1/-1/-1->15->14\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO comm 0x5591a95d9d20 rank 14 nRanks 16 nNodes 2 localRanks 8 localRank 6 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO comm 0x5581f3ae2050 rank 12 nRanks 16 nNodes 2 localRanks 8 localRank 4 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Trees [0] 13/-1/-1->12->11 [1] 13/-1/-1->12->11 [2] 13/-1/-1->12->11 [3] 13/-1/-1->12->11\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO comm 0x55dfe1ffe1f0 rank 11 nRanks 16 nNodes 2 localRanks 8 localRank 3 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Trees [0] 12/-1/-1->11->10 [1] 12/-1/-1->11->10 [2] 12/-1/-1->11->10 [3] 12/-1/-1->11->10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO comm 0x55b23f1eaf40 rank 10 nRanks 16 nNodes 2 localRanks 8 localRank 2 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9 [2] 11/-1/-1->10->9 [3] 11/-1/-1->10->9\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO comm 0x55d3dcf458d0 rank 13 nRanks 16 nNodes 2 localRanks 8 localRank 5 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12 [2] 14/-1/-1->13->12 [3] 14/-1/-1->13->12\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO comm 0x5579d08b7fb0 rank 8 nRanks 16 nNodes 2 localRanks 8 localRank 0 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Trees [0] 9/-1/-1->8->0 [1] 9/0/-1->8->-1 [2] 9/-1/-1->8->0 [3] 9/0/-1->8->-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO comm 0x55c3d31900e0 rank 9 nRanks 16 nNodes 2 localRanks 8 localRank 1 MNNVL 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Trees [0] 10/-1/-1->9->8 [1] 10/-1/-1->9->8 [2] 10/-1/-1->9->8 [3] 10/-1/-1->9->8\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NCCL_MIN_NRINGS set by environment to 4.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13 [2] 15/-1/-1->14->13 [3] 15/-1/-1->14->13\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO P2P Chunksize set to 131072\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 00/0 : 15[7] -> 0[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 01/0 : 15[7] -> 0[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 02/0 : 15[7] -> 0[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 03/0 : 15[7] -> 0[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 00/0 : 7[7] -> 8[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 01/0 : 7[7] -> 8[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 02/0 : 7[7] -> 8[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 03/0 : 7[7] -> 8[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 00 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 00 : 8[0] -> 9[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 01 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 02 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 03 : 0[0] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 01 : 8[0] -> 9[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Channel 00 : 5[5] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Channel 00 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 02 : 8[0] -> 9[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Channel 01 : 5[5] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 03 : 8[0] -> 9[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:205 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Channel 00/0 : 7[7] -> 8[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:205 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Channel 01/0 : 7[7] -> 8[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:205 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Channel 02/0 : 7[7] -> 8[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Channel 01 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:205 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Channel 03/0 : 7[7] -> 8[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Channel 00 : 13[5] -> 14[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Channel 02 : 5[5] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Channel 02 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Channel 03 : 5[5] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Channel 00 : 4[4] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Channel 00 : 3[3] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Channel 00 : 6[6] -> 7[7] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Channel 00 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Channel 01 : 13[5] -> 14[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Channel 03 : 1[1] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Channel 01 : 4[4] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Channel 01 : 3[3] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Channel 01 : 6[6] -> 7[7] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Channel 01 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Channel 00 : 9[1] -> 10[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Channel 00 : 12[4] -> 13[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Channel 02 : 13[5] -> 14[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Channel 00 : 14[6] -> 15[7] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Channel 02 : 4[4] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Channel 02 : 3[3] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Channel 02 : 6[6] -> 7[7] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Channel 02 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Channel 01 : 12[4] -> 13[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Channel 01 : 9[1] -> 10[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Channel 03 : 13[5] -> 14[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Channel 03 : 4[4] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Channel 03 : 3[3] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Channel 03 : 6[6] -> 7[7] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Channel 03 : 2[2] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Channel 01 : 14[6] -> 15[7] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Channel 00 : 11[3] -> 12[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Channel 02 : 12[4] -> 13[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Channel 02 : 9[1] -> 10[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Channel 00 : 10[2] -> 11[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Channel 02 : 14[6] -> 15[7] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Channel 01 : 11[3] -> 12[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:199 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Channel 03 : 12[4] -> 13[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Channel 00/0 : 15[7] -> 0[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Channel 03 : 9[1] -> 10[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:199 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Channel 01/0 : 15[7] -> 0[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:199 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Channel 02/0 : 15[7] -> 0[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:199 [7] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Channel 03/0 : 15[7] -> 0[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Channel 01 : 10[2] -> 11[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Channel 03 : 14[6] -> 15[7] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Channel 02 : 11[3] -> 12[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Channel 02 : 10[2] -> 11[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Channel 03 : 11[3] -> 12[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Channel 03 : 10[2] -> 11[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 01/0 : 0[0] -> 8[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 02/0 : 0[0] -> 8[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Channel 00 : 7[7] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 03/0 : 0[0] -> 8[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 01/0 : 8[0] -> 0[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 02/0 : 8[0] -> 0[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Channel 03/0 : 8[0] -> 0[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Channel 01 : 7[7] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 01/0 : 8[0] -> 0[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 02/0 : 8[0] -> 0[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 03/0 : 8[0] -> 0[0] [receive] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 01/0 : 0[0] -> 8[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 02/0 : 0[0] -> 8[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO NET/OFI Libfabric provider associates MRs with domains\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Channel 03/0 : 0[0] -> 8[0] [send] via NET/AWS Libfabric/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Channel 00 : 15[7] -> 14[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Channel 01 : 15[7] -> 14[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Channel 00 : 4[4] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Channel 01 : 4[4] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Channel 02 : 4[4] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Channel 02 : 15[7] -> 14[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Channel 03 : 15[7] -> 14[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Channel 03 : 4[4] -> 3[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Channel 00 : 5[5] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Channel 00 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Channel 00 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Channel 01 : 5[5] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Channel 01 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Channel 01 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Channel 02 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Channel 00 : 12[4] -> 11[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Channel 02 : 5[5] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Channel 00 : 11[3] -> 10[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Channel 00 : 10[2] -> 9[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Channel 02 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Channel 00 : 13[5] -> 12[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Channel 03 : 3[3] -> 2[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Channel 01 : 12[4] -> 11[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Channel 03 : 5[5] -> 4[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Channel 03 : 2[2] -> 1[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Channel 01 : 11[3] -> 10[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Channel 01 : 10[2] -> 9[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Channel 01 : 13[5] -> 12[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Channel 02 : 12[4] -> 11[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Channel 02 : 11[3] -> 10[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Channel 02 : 10[2] -> 9[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Channel 02 : 13[5] -> 12[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Channel 03 : 12[4] -> 11[3] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Channel 03 : 11[3] -> 10[2] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Channel 03 : 10[2] -> 9[1] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Channel 00 : 9[1] -> 8[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Channel 03 : 13[5] -> 12[4] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Channel 00 : 6[6] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Channel 01 : 9[1] -> 8[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Channel 00 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Channel 01 : 6[6] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Channel 02 : 9[1] -> 8[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Channel 01 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Channel 00 : 14[6] -> 13[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Channel 02 : 6[6] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Channel 03 : 9[1] -> 8[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Channel 02 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Channel 01 : 14[6] -> 13[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Channel 03 : 6[6] -> 5[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Channel 03 : 1[1] -> 0[0] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Channel 02 : 14[6] -> 13[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Channel 03 : 14[6] -> 13[5] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Channel 02 : 7[7] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Channel 03 : 7[7] -> 6[6] via SHM/direct/direct\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO NCCL_PROTO set by environment to simple\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO 4 coll channels, 4 collnet channels, 0 nvls channels, 4 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:192 [3] NCCL INFO ncclCommInitRank comm 0x55dfe1ffe1f0 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId 190 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:193 [7] NCCL INFO ncclCommInitRank comm 0x5612a39e0c40 rank 15 nranks 16 cudaDev 7 nvmlDev 7 busId 1d0 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:196 [2] NCCL INFO ncclCommInitRank comm 0x55b23f1eaf40 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 180 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:198 [6] NCCL INFO ncclCommInitRank comm 0x5591a95d9d20 rank 14 nranks 16 cudaDev 6 nvmlDev 6 busId 1c0 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:195 [1] NCCL INFO ncclCommInitRank comm 0x55c3d31900e0 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 170 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:191 [0] NCCL INFO ncclCommInitRank comm 0x5579d08b7fb0 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 160 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:197 [4] NCCL INFO ncclCommInitRank comm 0x5581f3ae2050 rank 12 nranks 16 cudaDev 4 nvmlDev 4 busId 1a0 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:194 [5] NCCL INFO ncclCommInitRank comm 0x55d3dcf458d0 rank 13 nranks 16 cudaDev 5 nvmlDev 5 busId 1b0 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:201 [4] NCCL INFO ncclCommInitRank comm 0x5615fa442840 rank 4 nranks 16 cudaDev 4 nvmlDev 4 busId 1a0 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:203 [2] NCCL INFO ncclCommInitRank comm 0x55dea5a127f0 rank 2 nranks 16 cudaDev 2 nvmlDev 2 busId 180 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:204 [7] NCCL INFO ncclCommInitRank comm 0x555b2d3427d0 rank 7 nranks 16 cudaDev 7 nvmlDev 7 busId 1d0 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:202 [1] NCCL INFO ncclCommInitRank comm 0x5583606883b0 rank 1 nranks 16 cudaDev 1 nvmlDev 1 busId 170 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:200 [3] NCCL INFO ncclCommInitRank comm 0x560c100e5fe0 rank 3 nranks 16 cudaDev 3 nvmlDev 3 busId 190 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:198 [5] NCCL INFO ncclCommInitRank comm 0x562c710e1990 rank 5 nranks 16 cudaDev 5 nvmlDev 5 busId 1b0 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:199 [6] NCCL INFO ncclCommInitRank comm 0x55f3e56fd9e0 rank 6 nranks 16 cudaDev 6 nvmlDev 6 busId 1c0 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO TUNER/Plugin: Failed to find ncclTunerPlugin_v2, using internal tuner instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:197 [0] NCCL INFO ncclCommInitRank comm 0x560b00923d10 rank 0 nranks 16 cudaDev 0 nvmlDev 0 busId 160 commId 0x2d2cf568e2e69f0d - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Rank 1: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Rank 1: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Rank 2: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Rank 2: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Rank 0: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Rank 0: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Rank 3: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Rank 3: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Rank 5: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Rank 5: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Rank 4: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Rank 4: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Rank 14: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Rank 14: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Rank 6: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Rank 6: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Rank 7: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Rank 7: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Rank 15: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Rank 15: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Rank 12: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Rank 12: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Rank 13: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Rank 13: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Rank 11: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Rank 11: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Rank 10: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Rank 10: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Rank 9: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Rank 9: Attempting barrier with timeout[1,mpirank:9,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Rank 8: All-reduce test successful: 16.0 (should be 16)\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Rank 8: Attempting barrier with timeout\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Rank 1: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Rank 1: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Rank 3: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Rank 3: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Rank 15: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Rank 15: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Rank 2: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Rank 2: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Rank 14: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Rank 14: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Rank 13: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Rank 13: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Rank 4: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Rank 4: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Rank 12: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Rank 12: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Rank 5: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Rank 5: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Rank 6: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Rank 6: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Rank 10: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Rank 10: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Rank 7: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Rank 7: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Rank 11: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Rank 11: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Rank 9: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Rank 9: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Rank 0: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Rank 0: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Rank 8: Passed barrier\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Rank 8: Test completed successfully\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:213 [3] NCCL INFO [Service thread] Connection closed by localRank 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:212 [0] NCCL INFO [Service thread] Connection closed by localRank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:205 [5] NCCL INFO [Service thread] Connection closed by localRank 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:199 [7] NCCL INFO [Service thread] Connection closed by localRank 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:208 [1] NCCL INFO [Service thread] Connection closed by localRank 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:209 [0] NCCL INFO [Service thread] Connection closed by localRank 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:206 [4] NCCL INFO [Service thread] Connection closed by localRank 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:203 [4] NCCL INFO [Service thread] Connection closed by localRank 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:200 [2] NCCL INFO [Service thread] Connection closed by localRank 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:202 [6] NCCL INFO [Service thread] Connection closed by localRank 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:201 [3] NCCL INFO [Service thread] Connection closed by localRank 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:207 [6] NCCL INFO [Service thread] Connection closed by localRank 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:205 [7] NCCL INFO [Service thread] Connection closed by localRank 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:209 [2] NCCL INFO [Service thread] Connection closed by localRank 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:210 [1] NCCL INFO [Service thread] Connection closed by localRank 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:208 [5] NCCL INFO [Service thread] Connection closed by localRank 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:110:229 [0] NCCL INFO comm 0x560c100e5fe0 rank 3 nranks 16 cudaDev 3 busId 190 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:108:223 [0] NCCL INFO comm 0x55d3dcf458d0 rank 13 nranks 16 cudaDev 5 busId 1b0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:104:225 [0] NCCL INFO comm 0x55c3d31900e0 rank 9 nranks 16 cudaDev 1 busId 170 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:110:224 [0] NCCL INFO comm 0x5612a39e0c40 rank 15 nranks 16 cudaDev 7 busId 1d0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:107:230 [0] NCCL INFO comm 0x560b00923d10 rank 0 nranks 16 cudaDev 0 busId 160 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:111:231 [0] NCCL INFO comm 0x5615fa442840 rank 4 nranks 16 cudaDev 4 busId 1a0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:103:226 [0] NCCL INFO comm 0x5579d08b7fb0 rank 8 nranks 16 cudaDev 0 busId 160 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:113:232 [0] NCCL INFO comm 0x55f3e56fd9e0 rank 6 nranks 16 cudaDev 6 busId 1c0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:107:227 [0] NCCL INFO comm 0x5581f3ae2050 rank 12 nranks 16 cudaDev 4 busId 1a0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:106:230 [0] NCCL INFO comm 0x55dfe1ffe1f0 rank 11 nranks 16 cudaDev 3 busId 190 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:105:228 [0] NCCL INFO comm 0x55b23f1eaf40 rank 10 nranks 16 cudaDev 2 busId 180 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:109:234 [0] NCCL INFO comm 0x55dea5a127f0 rank 2 nranks 16 cudaDev 2 busId 180 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:109:229 [0] NCCL INFO comm 0x5591a95d9d20 rank 14 nranks 16 cudaDev 6 busId 1c0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:114:233 [0] NCCL INFO comm 0x555b2d3427d0 rank 7 nranks 16 cudaDev 7 busId 1d0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:108:235 [0] NCCL INFO comm 0x5583606883b0 rank 1 nranks 16 cudaDev 1 busId 170 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:112:236 [0] NCCL INFO comm 0x562c710e1990 rank 5 nranks 16 cudaDev 5 busId 1b0 - Abort COMPLETE\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:45,787 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:45,787 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:45,788 sagemaker-training-toolkit INFO     Begin writing status file from leader node to worker nodes (if any)\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:45,788 sagemaker-training-toolkit INFO     Start writing mpirun finished status to algo-2\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:45,785 sagemaker-training-toolkit INFO     Invoked on_terminate from psutil.wait_for_procs\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:45,785 sagemaker-training-toolkit INFO     process psutil.Process(pid=100, name='orted', status='terminated', started='07:20:34') terminated with exit code None\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:45,786 sagemaker-training-toolkit INFO     Reporting status for ORTEd process. gone: [psutil.Process(pid=100, name='orted', status='terminated', started='07:20:34')] alive: []\u001b[0m\n",
      "\u001b[35m2025-03-17 07:20:45,786 sagemaker-training-toolkit INFO     Orted process exited\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:45,949 sagemaker-training-toolkit INFO     output from subprocess run CompletedProcess(args=['ssh', 'algo-2', 'touch', '/tmp/done.algo-1'], returncode=0, stdout='', stderr='')\u001b[0m\n",
      "\u001b[34m2025-03-17 07:20:45,949 sagemaker-training-toolkit INFO     Finished writing status file\u001b[0m\n",
      "\u001b[35m2025-03-17 07:21:15,786 sagemaker-training-toolkit INFO     Begin looking for status file on algo-2\u001b[0m\n",
      "\u001b[35m2025-03-17 07:21:15,786 sagemaker-training-toolkit INFO     MPI training job status file found. Exit gracefully\u001b[0m\n",
      "\u001b[35m2025-03-17 07:21:15,786 sagemaker-training-toolkit INFO     End looking for status file\u001b[0m\n",
      "\u001b[35m2025-03-17 07:21:15,786 sagemaker-training-toolkit INFO     MPI process finished.\u001b[0m\n",
      "\u001b[35m2025-03-17 07:21:15,786 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34m2025-03-17 07:21:15,949 sagemaker-training-toolkit INFO     Finished writing status file from leader node to worker nodes (if any)\u001b[0m\n",
      "\u001b[34m2025-03-17 07:21:15,949 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-03-17 07:21:30 Uploading - Uploading generated training model\n",
      "2025-03-17 07:21:30 Completed - Training job completed\n",
      "Training seconds: 592\n",
      "Billable seconds: 592\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
